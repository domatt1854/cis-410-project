,created_utc,title,text,author,score,upvote_ratio,num_comments,url
0,1701645510.0,ML Engineer vs Data Scientist,"As far as I know :  


MLE = ML + SDE  
DS = ML + Data Analytics

Feel free to correct me/add more",Snoo_72181,14,0.86,10,https://www.reddit.com/r/learnmachinelearning/comments/18a6cpw/ml_engineer_vs_data_scientist/
1,1701648866.0,Introduction to Symbol Grounding,,Neurosymbolic,5,0.86,0,https://youtube.com/watch?v=wP8EyQaC_uY&si=oEZEioIFpwNNmVCI
2,1701614305.0,This week in AI - all the Major AI developments in a nutshell,"1. **Meta AI** introduced a suite of AI language translation models that preserve expression and improve streaming \[[*Details*](https://ai.meta.com/blog/seamless-communication) *|* [*GitHub*](https://github.com/facebookresearch/seamless_communication)\]:
   1. ***SeamlessExpressive*** enables the transfer of tones, emotional expression and vocal styles in speech translation. You can try a demo of SeamlessExpressive using your own voice as an input [***here***](https://seamless.metademolab.com/expressive)***.***
   2. ***SeamlessStreaming***, a new model that enables streaming speech-to-speech and speech-to-text translations with <2 seconds of latency and nearly the same accuracy as an offline model. In contrast to conventional systems which translate when the speaker has finished their sentence, SeamlessStreaming translates while the speaker is still talking. t intelligently decides when it has enough context to output the next translated segment.
   3. ***SeamlessM4T v2***, a foundational multilingual & multitask model for both speech & text. It's the successor to SeamlessM4T, demonstrating performance improvements across ASR, speech-to-speech, speech-to-text & text-to-speech tasks.
   4. ***Seamless***, a model that merges capabilities from SeamlessExpressive, SeamlessStreaming and SeamlessM4T v2 into one.
2. **Stability AI** released ***SDXL Turbo***: a real-time Text-to-Image generation model. SDXL Turbo is based on a a new distillation technology, which enables the model to synthesize image outputs in a single step and generate real-time text-to-image outputs while maintaining high sampling fidelity.
3. **Mozilla’s** innovation group and Justine Tunney released ***llamafile*** that lets you distribute and run LLMs with a single file. llamafiles can run on six OSes (macOS, Windows, Linux, FreeBSD, OpenBSD, and NetBSD) and on multiple CPU architectures.
4. **Perplexity** released two new PPLX models: ***pplx-7b-online and pplx-70b-online***. These *online LLMs* can leverage the most up-to-date information using the internet when forming a response..
5. **Google DeepMind** presented ***GNoME*** (Graph Networks for Materials Exploration): an AI tool that discovered *2.2 million new crystal structures*, with 380,000 being highly stable and promising for breakthroughs in superconductors, supercomputers, and advanced batteries for electric vehicles.
6. **Amazon** introduced two new Amazon Titan multimodal foundation models (FMs): ***Amazon Titan Image Generator*** (preview) and ***Amazon Titan Multimodal Embeddings***. All images generated by Amazon Titan contain an invisible watermark.
7. Researchers present ***Animatable Gaussians***, a new avatar representation method that can create lifelike human avatars from multi-view RGB videos.
8. **Pika Labs** released a major product upgrade of their generative AI video tool, ***Pika 1.0***, which includes a new AI model capable of generating and editing videos in diverse styles such as 3D animation, anime, cartoon and cinematic using text, image or existing video.
9. **Eleven Labs** announced a ***grant*** program offering 11M text characters of content per month for the first 3 months to solo-preneurs and startups.
10. Researchers from **UC Berkeley** introduced ***Starling-7B***, an open large language model trained using Reinforcement Learning from AI Feedback (RLAIF). It utilizes the GPT-4 labeled ranking dataset, Nectar, and a new reward training pipeline. Starling-7B outperforms every model to date on MT-Bench except for OpenAI’s GPT-4 and GPT-4 Turbo .
11. **XTX Markets** is launching a new $10mn challenge fund, the **Artificial Intelligence Mathematical Olympiad Prize** (AI-MO Prize) The grand prize of $5mn will be awarded to the first publicly-shared AI model to enter an AI-MO approved competition and perform at a standard equivalent to a gold medal in the in the International Mathematical Olympiad (IMO) .
12. **Microsoft Research** evaluated GPT-4 for processing ***radiology reports***, focusing on tasks like disease classification and findings summarization. The study found GPT-4 has a sufficient level of radiology knowledge with only occasional errors in complex context that require nuanced domain knowledge. The radiology report summaries generated by GPT-4 were found to be comparable and, in some cases, even *preferred* over those written by experienced radiologists.
13. **AWS** announced ***Amazon Q***, a new generative AI–powered assistant for businesses. It enables employees to query and obtain answers from various content repositories, summarize reports, write articles, perform tasks, and more, all within their company's integrated content systems. Amazon Q offers over 40 built-in connectors to popular enterprise systems.
14. 18 countries including the US, Britain signed a detailed international agreement on how to keep artificial intelligence safe from rogue actors, pushing for companies to create AI systems that are ‘secure by design’ .

**Source**: AI Brews - you can subscribe [here](https://aibrews.com/). it's free to join, sent only once a week with ***bite-sized news, learning resources and selected tools.*** I didn't add links to news sources here because of auto-mod, but they are included in the newsletter. Thanks.",wyem,37,0.91,1,https://www.reddit.com/r/learnmachinelearning/comments/189ustx/this_week_in_ai_all_the_major_ai_developments_in/
3,1701654134.0,About Reinforcement Learning: Four seminal AI breakthroughs,,AvvYaa,3,0.72,0,https://youtu.be/zOXcNFM8dt4
4,1701653376.0,Educational Transformer without Autograd,"I have been learning NLP for a little while, and always found it hard to find full implementations of Transformers with **explicit forward and backprop**. This project was my attempt at building that, while learning how to better understand optimization in Transformers.

It is as well-documented as I could make it, and can be trained or fine-tuned easily by editing the **config.py** file and running the **run.py** script. Get the code with:

    git clone https://github.com/eduardoleao052/Transformer-from-scratch.git

I managed to generate some really nice text training this model on Jules Verne's and Shakespeare's works. Hope you enjoy!

GitHub repository [here](https://github.com/eduardoleao052/Transformer-from-scratch.git)!",suspicious_beam,5,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/18a8zhr/educational_transformer_without_autograd/
5,1701661245.0,Best Machine Learning Books for beginners & Advanced to learn,,Lakshmireddys,1,0.67,0,https://codingvidya.com/best-machine-learning-books/
6,1701661139.0,Are decision trees considered artificial intelligence?,Follow up from my previous question. Are decision trees considered artificial intelligence or is that term reserved for neural networks?,Traditional_Soil5753,0,0.5,4,https://www.reddit.com/r/learnmachinelearning/comments/18abemh/are_decision_trees_considered_artificial/
7,1701659203.0,Input text way bigger than max length tokens for embeddings.,"Hi, this is my first time trying to make semantic search. In my case its asymetric semantic search and I am using msmarco-MiniLM-L-6-v3 to create embeddings. I have about 400k elements to embed 
The problem: my input text is way longer than the 512 tokens. Text is on average 3000 words (so even more tokens) From what I understand these could be a solution?
- chunking (with overlap?) the text for each vector to embed and then do a mean pooling on the result? The problem is I have no idea how to do this. I am a beginner and this is my first time doing this so is there any code example /tutorial/steps to follow? 
- run a summarizer model like facebook/bart-large-cnn to sum up the text into the correct size of 512 tokens or less. But this I feel would cost more in computation/time and would loose context and granularity(?)
Any tips is appreciated. This is really confusing to me, especially because the only to know you did it wrong is to test the results.",HistorianOwn9933,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/18aatjn/input_text_way_bigger_than_max_length_tokens_for/
8,1701656895.0,What is the best way to visualize 2D data as 3D data?,"I got data (1503, 38697)  (cell(datapoint), genes(features)), each elements has integer values (gene expression).  


so something like  
   
gene 1           gene 2          gene 3  
cell 1        10                    0                   20  
cell 2        20                 10                    50  


I plotted some datapoints as histogram for each cell (x axis for gene (features), y axis for value ), but it takes too much time with matplotlib.   


One of my colleague said I should make this plot as 3D, recommend to split x-axis (which for gene (features)). How should I split x-axis?  


&#x200B;

&#x200B;",poemfordumbs,1,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/18aa3go/what_is_the_best_way_to_visualize_2d_data_as_3d/
9,1701605738.0,"Are decision trees considered ""deep learning""?",Or is deep learning only for neural networks?,Traditional_Soil5753,12,0.71,16,https://www.reddit.com/r/learnmachinelearning/comments/189sbzi/are_decision_trees_considered_deep_learning/
10,1701564556.0,Please roast my ML study plan,"Hello,

Background: I am a Software Engineer with four years of experience in a traditional SWE background, and I am eager to gain some skills so that I can perform well in a team that focuses on ML/AI. My goal is to be able to work with ML/AI scientists and researchers and help the team to productionize the technology by applying my SWE knowledge (pretty much becoming a SWE + MLE).

In my understanding, a Machine Learning Engineer (MLE) is essentially a Software Engineer who integrates ML functionalities or models developed by ML scientists or researchers into a product. To facilitate this transition, I believe that while I don't need an overly math-intensive approach, I want to ensure I cover all the necessary skills to thrive in a SWE role within an AI/ML team. To achieve this, I am in the process of building a roadmap and would greatly appreciate your insights and guidance to make it more focused and effective. 

### 1. ML Knowledge Brush-up

**- Learn ML Problems (Google ML Crash Course)**

* My goal here is to refresh my understanding of ML problems, and I've chosen the Google ML Crash Course for its comprehensive content. Any thoughts on this choice?

### 2. Hands-on ML Coding

\- **ML for Software Engineers course on educative.io**

* I've selected this course despite some feedback about its shallow depth. The decision is based on its coding exercises and coverage of various topics. What are your opinions on this course, and do you recommend any alternatives for hands-on ML coding?

### 3. Basic ML Math (Brushing Up as Needed)

* My plan is to refresh my knowledge of essential mathematical concepts when required during coding. The topics include:
   * A. Linear Algebra
   * B. Matrix Manipulation
   * C. Multivariate Calc
   * D. The Chain Rule
   * E. Probability + Distributions
   * F. Optimization
* Any suggestions on additional resources or specific areas to focus on within these topics?

### 4. Productionizing ML

\- **Full Stack Deep Learning Course**

* Recognizing the significance of productionizing ML, I've identified the Full Stack Deep Learning course ([https://fullstackdeeplearning.com/](https://fullstackdeeplearning.com/)) as a key resource. Building an AI-powered product involves more than just model training or coding. What are your thoughts on this course, and do you have any alternative recommendations for understanding ML infrastructure, operations, and lifecycle?

These won't necessarily be in this order, but I plan to do 1, 2, and 3 in parallel and do 4 after.

I genuinely value your expertise and opinions. Please feel free to roast my guide and provide constructive criticism. Your insights will undoubtedly help me refine my approach and ensure a more effective transition into the ML domain.

Thank you in advance for your time and feedback!

Best regards,",czechrepublic,76,0.97,27,https://www.reddit.com/r/learnmachinelearning/comments/189hlxu/please_roast_my_ml_study_plan/
11,1701645886.0,Please help,"Already posted before but i’ve gotten nowhere 
In my previous post i said i was using langchain and OpenAi api to diagnose Alzheimer’s (Got serious roasting for that) but i learned from that and i tried studying actual machine learning but i’m still very clueless. I know i’ll get it eventually but time is not on my side, my supervisor insists that this is the topic i must work on.
All i need is for the model to 
-Provide suggestions on diagnosis and treatment based on user input in text of their symptoms 
-Generate a list of hospitals near them that has the facilities to provide the services 

I’d really appreciate any help",boscrew3,1,1.0,7,https://www.reddit.com/r/learnmachinelearning/comments/18a6hew/please_help/
12,1701643235.0,Image Generator AI,"Hello all, I'm looking for good image generator AI to implement on my website, I have two requirements:

1.I need to be able to train that AI on my artworks and designs so when an user gives it a promt it generates image based/styled on my designs.

2. Should have API or something to be able to add it as feature on my website.

Thanks in advance, I couldn't find that specific thing online otherwise I wouldn't be posting here.",Graf_Alexandrius,0,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/18a5iky/image_generator_ai/
13,1701615668.0,Intro to Machine Learning in Production: How to clone a directory using git?,"Regardng the course: Introduction to Machine Learning in Production ([DeepLearning.AI](https://DeepLearning.AI))

Week 1 Ungraded Lab : Deploying a Deep Learning model (local setup) [https://github.com/https-deeplearning-ai/machine-learning-engineering-for-production-public/blob/main/course1/week1-ungraded-lab/README.md](https://github.com/https-deeplearning-ai/machine-learning-engineering-for-production-public/blob/main/course1/week1-ungraded-lab/README.md)

I am unsure where to type the following `git` command to clone the repo. I tried using the CMD from my Anaconda environment, but it's not working.

`git clone https://github.com/https-deeplearning-ai/machine-learning-engineering-for-production-public.git`

I am sure that I am missing something basic...Any help is appreciated.",deeznutzareout,4,0.7,4,https://www.reddit.com/r/learnmachinelearning/comments/189v9vn/intro_to_machine_learning_in_production_how_to/
14,1701638642.0,I'm training to use jais model embedding,I'm training to use jais model embedding. I'm curious to know if any one used it before,ahsaor8,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/18a3q7v/im_training_to_use_jais_model_embedding/
15,1701637811.0,How to capture interaction effects with pca,Is there any pca method (or just feature engineering method in general) that allows me to capture interaction effects and store them in a separate variable by itself.,Traditional_Soil5753,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/18a3eog/how_to_capture_interaction_effects_with_pca/
16,1701624217.0,Data Scientist/ML Engineer,"Hello guys! Is it worth to be a self-taught Data Scientist/Machine Learning Engineer? I have gathered some experience in IT, I was programming in Python for a certain time but I couldnt really make a decision as a beginner like which path to choose in IT (Im kinda interested in Backend Development, Machine Learning and now Data Science). Before I dived deeply into job listings (just because of curiosity) I watched large amount of YT videos where they explained what is data science/what does a data scientist really do (from Joma Tech whos is senior DS), what is it like to be a data scientist etc. I was kinda curious about the current job positions in EU as well, especially in Data Science and after researching at IT jobs I came across a specific job listing where they wanted to hire a Data Scientist and there was no degree requirement only experience and solid knowledge. I searched and spent more time on these these types of job listing websites and I found a decent amount of Data Scientist positions (in my area - EU) where degree was not required. So it turned out that it is not impossible to land a job as a Data Scientist without degree. What do you guys think about Data scientists nowadays and also is it worth putting lot of effort and time to become one?",Nacs0sz,2,0.75,1,https://www.reddit.com/r/learnmachinelearning/comments/189y9mg/data_scientistml_engineer/
17,1701634066.0,Advent of Code - Open-source challenge,"I've just found this code advent: [https://zilliz.com/blog/advent-of-code-for-open-source](https://zilliz.com/blog/advent-of-code-for-open-source)

Seems like something fun and a way to learn more about AI open-source projects. I'm looking into doing something with ydata-profiling ([https://github.com/ydataai/ydata-profiling](https://github.com/ydataai/ydata-profiling)), as it is a package that I use regularly!

What do you think about this type of initiatives? Have you been part of something similar before, like the [Hacktober fest](https://hacktoberfest.com/)?",Dry_Cattle9399,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/18a1zkz/advent_of_code_opensource_challenge/
18,1701631158.0,Need advice,"Disclaimer: Please read this post if you have moved to USA to persue master degree 

Hey there !!
I am too much confused about what to do. Pardon me I know this is not the correct sub, but due to 2 reasons I consider it as an appropriate sub to post this query: 

1. My field is aligned with ML/AI
2. Many of you might have experienced cases like this while deciding for masters in USA. if not what would be your realistic advice for newbies like me 

My overview: 
I have completed BE in CSE in the same year (2023). During this year I did 3 months internship as an ML Engineer starting from February 2023 to May 2023. Then I took time to work on my self simultaneously I was preparing for IELTS (non native) and scored 7.5. I took IELTS in October. Up till now I was in a myth that I can apply without GRE in good Universities like USC and other similar since I had checked websites of some universities and it was mentioned that GRE has been either waived off/optional. 

In my profile I have one aforementioned internship, few development and ML projects, and some contribution in college clubs, gpa 3.4, IELTS 7.5


Now when I started doing research during application time I came to know that universities like UT Austin have made GRE optional but along with this it has also mentioned that ""if you think that you can strengthen your profile by GRE score, you can send GRE score and admission committee will consider that score"". So finally I decided to take GRE exam, but I think its too late now since I will require 2 months to prepare for it. And finally I will take this exam in February and uptil this time max universities like ASU and other similar are done with their deadline.

Now the only option I am left with is to either wait for spring 2025 intake or for fall 2025. But some ppl are saying that spring intake is not recommended since you wil have less opportunities for on campus jobs and even for internship. So finally I will have to apply for fall 2025. 

The problem is it will create 2 years gap in my resume. And since I am aligned with ML/AI field I am unable to get any job right now which can fill my resume gap. 

Please let me know my this decision for fall 2025 intake is good meanwhile definitely I will work on my skills until I find a job. Or should I apply to any low ranked university like Pace or Texas A&M - corpus Christi. To go with the flow. Because utimate goal is to get the job upon completion of 2 years of masters.


Please let me know what should I do. I know I have done some mistakes by not researching early and depending on other's research. But please help me overcoming this situation from your experience.",JordaarAce,0,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/18a0v46/need_advice/
19,1701624583.0,"How is morfessor algorithm works and how ot differs from algorithms like bpe, word piece and sentence piece",,GullibleTrust5682,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/189ye9x/how_is_morfessor_algorithm_works_and_how_ot/
20,1701624296.0,Explain this chart to me (scatterplot of US elections),"Hi,   


I perfectly understand that the hypothesis is ""Support for Cannabis Exceeds/Outperforms that for Democratic Candidates in Recent Years"". But how is this scatterplot establishing this?  


&#x200B;

https://preview.redd.it/2cqwawqk644c1.png?width=2840&format=png&auto=webp&s=15644e1dec59fcb29e294fec2d63d308f01536d2",Substantial-House-28,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/189yamh/explain_this_chart_to_me_scatterplot_of_us/
21,1701609395.0,Pre-trained model," hey everyone, i am an absolute beginner on machine learning and i got a project that i should try a pre-trained model for NLP (i have to transfer image to text), so i need a pre-trained model for that so i can try it. Your help means a lot to me. Thanks!",Less-Combination-180,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/189tap0/pretrained_model/
22,1701615477.0,Learn AI Object detection with examples: Table detection from document using YOLO,,lordwiz360,1,1.0,0,https://journal.hexmos.com/yolo-object-detection/
23,1701614108.0,"Can't get my head around timesteps, and if I need them or not","I have a RNN that is trained to predict lap time given a laps worth of telemetry data. It works well but I'm wondering if I could/should/need to add timesteps to increase the predictive accuracy.   
  
  My data points are collected 200 times a second, because the individual segments within a lap dictate the lap time, I believe I want to split the lap up in to several segments to feed as the timesteps, rather than using a single lap as a timesteps. Due to the variability of lap lengths, the length of different tracks and the fact I want to isolate data points to individual laps, I have a function that  splits a given lap in to x number of sequences, and then pads all sequences to the length of the longest.  
  This is where I'm stuck. I not sure if I need to do the same with the y (output) data.   Are my timesteps going to be the total amount of sequences, or the length of each segment?   
  And finally, is this the right approach for my type of data, or is timestep=1 enough?",Drogen24,1,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/189uqjb/cant_get_my_head_around_timesteps_and_if_i_need/
24,1701600033.0,"what does it mean when two algorithms have same accuracy, but different kappa"," 

i used the same algorithm on two datasets, both have accuracy 62%, but intersm of kappa, first has kappa score of 15 and the other score of 25, which is a big difference.

what does this imply about my agorithm? or is it perhaps i should look at it in a different perspective ?

thanks",qhelspil,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/189qzlx/what_does_it_mean_when_two_algorithms_have_same/
25,1701599447.0,Weather data and Machine/Deep Learning,"We're making a portable automatic weather station but we don't know where were gonna use it for. 

What is some good research topic regarding the utilization of weather data observed? 

Currently, I'm looking into precise agriculture. But it seems like a lot has done it already.",Funny_Shoe1772,2,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/189quth/weather_data_and_machinedeep_learning/
26,1701612169.0,Kv cache doubt,"Hi,

I have learned recently that in kv cache we can cache the k and v matrixes for n-1 tokens. 
And for token n we just add one column/row to k and v and compute soft Max and multiply attention matrix with v. 

Although I understand this doesn't change for first layer. Since the token emb and positional emb will be same for tokens . But shouldn't the embeddings going to next layer change ?

When n tokens is being processed. For QK^T matrix  n-1 tokens will have same values as last generative step.
But since the softmax scores will change the output features of each token after layer 1 which will be fed to layer 2 will change right?so how will be the caching still be valid for layer 2 to layer n?

I am sorry if I could not explain the question properly.",EmergencyStomach8580,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/189u4ib/kv_cache_doubt/
27,1701609557.0,"Differences Between Simple Parameters, Tuning Parameters, and Hyperparameters",,FCFAN44,1,1.0,0,https://medium.com/@awaleedpk/differences-between-simple-parameters-tuning-parameters-and-hyperparameters-da4825f4fa6c
28,1701529257.0,Hey whats the best roadmap to AI/ML in 2024 ??," 

Hey everyone,

So, I'm a Python (Django) dev , and I'm not too shabby with Python itself. I did the whole AI/ML intro thing back in my bachelor's, but honestly, it's all a blur now. Looking for a fresh start?

Any ideas on the best way to jump into the AI engineer scene or related post? Like, where do I begin? What should I brush up on? I'd love some real-talk advice.",khandu_don6969,57,0.91,20,https://www.reddit.com/r/learnmachinelearning/comments/1895id2/hey_whats_the_best_roadmap_to_aiml_in_2024/
29,1701596582.0,20 Best Online Courses On Machine Learning [Bestseller Courses in 2023],,Aqsa81,0,0.5,0,https://www.mltut.com/best-online-courses-on-machine-learning-you-must-know/
30,1701595420.0,How to perform customer segmentation?,"I have two tables - user info and user spend. 

user\_info has columns like user id, gender, education and income. There is only 1 row for each user.  
user\_spend has columns like user id, payment type, category and spend amount. There are many rows for a single customer because a customer can spend multiple times. I want to segment to specifically identify users to advertise a new debit card to(this is one of the values in payment type). 

To do this I am supposed to create a new feature spending score : (spend/income). I have created this and to identify users to advertise a new debit card to specifically grouped it for every user in the user info table. However, how to include the other columns from the spend table. I can't group the category and payment type columns because I need all the values.

How can I do this? Am I on the right path? I want to basically combine the two tables, but I'll end up losing the values.  
",tondlilover,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/189pyq7/how_to_perform_customer_segmentation/
31,1701591364.0,Help. Need to create a model using SIFT.,"I am currently working on a mobile application that recognises various currency denominations using the SIFT algorithm. All the surfing I've done so far, I've found no clue about how to do it. 
I'm using Flutter framework for the app. And I need to process the images locally(offline), on the mobile.
Please help me understand how to do it. Thank you.",thatvoid_,1,1.0,6,https://www.reddit.com/r/learnmachinelearning/comments/189p21p/help_need_to_create_a_model_using_sift/
32,1701586725.0,Help coming up with plan to create AI to play imperfect information card game,"Full disclosure, I don’t have much experience in machine learning. I’ve done some basic stuff at university but that’s it. 

I want to create an AI that gets better by itself at playing the card game 500. ChatGPT has been asked but it gives a different answer every time and it is confusing. I’d really appreciate any solid plans to get me from A, not knowing what to do at all or where to start, to B, where I have an agent which kicks my ass in the game. 

Thank you for any help you amazing people can render. 😊",RamboCambo15,0,0.33,3,https://www.reddit.com/r/learnmachinelearning/comments/189ny5b/help_coming_up_with_plan_to_create_ai_to_play/
33,1701586599.0,"Best Machine Learning Courses for Beginners, Advanced",,Lakshmireddys,0,0.5,0,https://codingvidya.com/best-machine-learning-courses/
34,1701586329.0,seed image classification,"Hello, can someone please help me. I have a project at school and I want to create a website that sells different kinds of seeds for planting as well as make a section for machine language. 

Machine language that has a classification model that detects what kind of seed is captured. 

I tried researching, For a classification model but all I can find is it will show in the terminal. Can someone please help.",capricornhera,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/189nunm/seed_image_classification/
35,1701569966.0,Cluster consolidation methods?,"Hello, I was wondering if cluster consolidation methods exist.

For example:

I do a cluster analysis 
Then I do a DIFFERENT cluster analysis

So now I have 2 separate cluster analysis.
Do methods exist where I one can bring together (consolidate) the clusters from these 2 seperate analysis into just one?",Grand_Comparison2081,2,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/189j8im/cluster_consolidation_methods/
36,1701576908.0,Reverse-time diffusion equation models,"Anyone have idea how to derive equations (3.10) and (4.2) in [Reverse-time diffusion equation models](https://www.sciencedirect.com/science/article/pii/0304414982900515) ?

https://preview.redd.it/1ow0z3rj904c1.png?width=1000&format=png&auto=webp&s=8b6e083ca528a4cd8ba864b4ba7a776c9f6d3be5

https://preview.redd.it/07o7tekk904c1.png?width=1000&format=png&auto=webp&s=79fd387278dc77a60cb04cef31e6e8014e8e3d8a",Lemon_Salmon,0,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/189ld16/reversetime_diffusion_equation_models/
37,1701536341.0,"Classification with three classes (good, neutral, bad). How do I alter my network to represent tiers of categories?","To explain what I mean, I want to give a few examples:

* If the network predicted good, but the true label is neutral, I'm not too concerned.
* If the network predicted good or neutral, but the true label is bad, this is a really bad scenario and want to give extra priority towards fixing this (especially if the prediction was good)
* If the network predicted bad but the true label was neutral or good, I am also not too concerned

I've been thinking of maybe making this a regression problem with good, neutral, bad having the integer values 1, 2, and 3 respectively, but am not sure if this is a good idea. Any suggestions on how to modify my loss function or any other part of the network to reflect these tiered categories? Just as an additional note, I'm doing this for a modified version of LSTMs and Transformers. Thanks!",K_is_for_Karma,6,0.88,6,https://www.reddit.com/r/learnmachinelearning/comments/1897x42/classification_with_three_classes_good_neutral/
38,1701560495.0,Can decision trees handle interactions,"Can decision trees detect and adjust for interaction effects between two or more variables? If not, is there any well-known way to add a helper variable to detect or measure a possible interaction between two or more variables that I can place in the tree? Any response is appreciated.",Traditional_Soil5753,2,1.0,6,https://www.reddit.com/r/learnmachinelearning/comments/189gb7r/can_decision_trees_handle_interactions/
39,1701568406.0,Need help with a machine learning project I am working on.,"I am starting a machine learning project and I want to gain insight on how I might go about building it.

It involves using Variational Autoencoders as a building block for Graph Neural Networks.

Help would be most appreciated

Thank you.",GenerXXL,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/189iryt/need_help_with_a_machine_learning_project_i_am/
40,1701536060.0,[D] How Transformers rewrote the rules of an age old tradition in ML,,Smallpaul,3,0.81,0,https://youtu.be/0P6-6KhBmZM
41,1701560621.0,machine video editor tutorial,,bungalowshlop,1,1.0,0,https://youtu.be/L_dJzHG_Mlk?si=CNSm7HQKpkCV9Oxb
42,1701519657.0,Loan default prediction using automated feature engineering; conduct feature engineering in less than 1 second.,"In this [notebook](https://nbviewer.org/github/getml/getml-community/blob/main/demo-notebooks/loans.ipynb), I have used [getML](https://github.com/getml/getml-community/tree/main) to predict loan default of bank customers.

This is a classic dataset in the relational learning literature and is often used to demonstrate feature engineering on relational data. In this particular example, training the entire pipeline, which includes the entire feature engineering process, takes less than one second. The predictive accuracy compares very well to the state-of-the-art in the related literature.

It turns out that the most important feature is what the lowest balance on the customer's bank account was before they took out the loan. It makes sense if you think about it: People who always have a lot of money on their bank account are less likely to default on their debt.

The notebook is 100% reproducible.

getML ([https://github.com/getml/getml-community/tree/main](https://github.com/getml/getml-community/tree/main)) is the fastest open-source tool for automated feature engineering on relational data and time series.  


https://preview.redd.it/8kihzek1jv3c1.png?width=1196&format=png&auto=webp&s=18de088b43870835f75c933bc935315abb965ca2",liuzicheng1987,5,0.86,0,https://www.reddit.com/r/learnmachinelearning/comments/1892lr1/loan_default_prediction_using_automated_feature/
43,1701514420.0,Which videos are a must-see?,"Can you recommend any videos on the topics of artificial intelligence, machine learning and the math behind it that you think are a must-see to build a deep (visual-intuitive) understanding of the topics?",AngelinaMatov,7,0.89,12,https://www.reddit.com/r/learnmachinelearning/comments/1891alc/which_videos_are_a_mustsee/
44,1701417695.0,New to Deep Learning - Hyper parameter selection is insane,"Seriously, how is this a serious engineering solution much less a science? I change the learning rate slightly and suddenly no learning takes place. I add a layer and now need to run the net through thousands more training iterations. Change weight initialization and training is faster but it’s way over fit. If I change the activation function forget everything else. God forbid there’s an actual bug in the code. Then there’s analyzing if any of the above tiny deviations that led to wildly different outcomes is a bias issue, variance issue, or both. 

When I look up how to make sense of any of this all the literature is basically just a big fucking shrug. Even Andrew Ng’s course specifically on this is just “here’s all the things you can change. Keep tweaking it and see what happens.” 

Is this just something I need to get over / gain intuition for / help research wtf is going on?",Creature1124,643,0.99,74,https://i.redd.it/7w21ytcc4n3c1.jpg
45,1701512141.0,What is the depth of coding knowledge?,"Hello,  


I'm a developer wanting to learn more ML and put it into practice at the company I work at as well as personal projects. I learn best diving in the deep end and learning as I go, so from my research the best course on that is [fast.ai](https://fast.ai), which I had a brief look at the first lesson and it seemed really good. I have also briefly used HuggingFace transformers libraries and played around with some of the tweaking for models + fine-tuning an LLM with some of my own data, which was really fun and I got some fairly accurate results.   


I was more curious as to what extent does only coding knowledge reach its peak and then the mathematics knowledge is needed to go further. I'm not keen to go into the maths heavy areas of ML research etc and I just like the idea of being able to use Hugging Face libraries and PyTorch to build applications. From reading the HuggingFace documentation it seems that there are a lot of high-level libraries which do most of the functionality needed to get simple applications working in areas like NLP, they just require tweaking and fine-tuning (this may be a very simplified view of it). So if i'm not interested in ML research and just using libraries/tweaking them with my own data, how far can you really get in creating projects? I know that ML has so much depth to it, but I'm not interested in the academia and mathematics formulas etc just utilizing ML in real world applications.  


I am very keen to understand more about the field in a conceptual way, but I am also happy to learn some mathematics if I need to. If there are any more courses, documents or videos that provide a nice explanation, I would greatly appreciate it.",DontKnowAGoodNames,4,0.7,2,https://www.reddit.com/r/learnmachinelearning/comments/1890r93/what_is_the_depth_of_coding_knowledge/
46,1701556437.0,"How to make an app which can take users image and apply filters like age, gender etc like on tiktok, snapchat etc?","I want to make an app which can take an image of a person and apply filters like making them younger, older, masculine, feminine, adding beard, makeup etc. I have seen such filters on tiktok and snapchat.

&#x200B;

1. Does anyone know if there are any famous ML models that I can use as is to do this? Or do I need to train and create a model from scratch? If so, any special architecture that you would suggest?
2. Do I need multiple models(one for gender, one for age etc)? Or is this something that can be done by a single ML model?",shadowknight094,0,0.25,0,https://www.reddit.com/r/learnmachinelearning/comments/189exsg/how_to_make_an_app_which_can_take_users_image_and/
47,1701592686.0,I need help with learning about sentient AI,"Hey people. I am new to machine learning. AI, particularly sentient AI has always fasinated me. I am very much interested in developing sentient machines. Despite searching comprehensively on google, I could not find much about research in the field. I seek help with following queries when it comes to developing sentient machines

1. What all are the subjects (including specialized subjects) I need to learn, if I want to become a master in sentient AI?

2. Which books should I read to become gain knowledge on sentient AI?

3. Who are the leading persons in the field of sentient AI?

4. Are there any online resources, websites, videos, courses (both online and offline), universities, which are teaching subjects related to sentient AI?

5. What research is going on in this field, where can I find more about it and how can I become part of it in future?

&#x200B;

Lot of questions I know, any help will be much appreciated. Thank.

&#x200B;",the-great-life,0,0.17,9,https://www.reddit.com/r/learnmachinelearning/comments/189pcux/i_need_help_with_learning_about_sentient_ai/
48,1701520606.0,Where do I start?,I'm a self taught developer. I'm really into machine learning and want to learn and practice on the side. I know that I have to learn the prerequisites before getting into the buzzword libraries...So where should I start Mathematically? I'm no stranger to reading books and do not have a time limit. I plant to spend multiple years to get good at this. Kindly give me some of the best sources I can start at.,sathyajithps,3,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/1892um1/where_do_i_start/
49,1701513816.0,Help understanding latent spaces,"I'm not an actual ML researcher, just someone with a passing interest and I've been trying to get some sort of high-level understanding of ML concepts.

One that I'm having difficulty understanding is what exactly a latent space is, how do they come to be?",epiphanyseeker1,3,0.8,9,https://www.reddit.com/r/learnmachinelearning/comments/18915ju/help_understanding_latent_spaces/
50,1701532863.0,"The blog covers machine learning courses, boot camps, books, tools, interview questions, cheat sheets, MLOps platforms, and more to master ML and secure your dream job.",,kingabzpro,1,1.0,0,https://www.kdnuggets.com/10-github-repositories-to-master-machine-learning
51,1701517609.0,Please fix my understanding of this tutorial on word embeddings for the ngrams model.,"Hi everyone, 

I recently started learning neural networks in the context of NLP. An an exercise, I am trying to follow the [PyTorch tutorial on word embeddings for the Ngrams model](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html).

I am not sure if my understanding of the tutorial is correct. I would really appreciate if someone experienced could take some time to go through the article I linked above and then tell me how much I followed it correctly and  what I understood wrong. 

Thanks so much! 

These are the steps as I (partially) understand: 

1. From the sample text, we first create a set of ngrams, each ngram consisting of source (of N words) and a target word. 
1. We initialize a randomized embeddings lookup table with dimensions equal to vocabulary size X embedding depth. 
1. We initialize 2 randomized linear NN layers. The output of the 2nd layer has the same size as the vocabulary. 

In the forward pass - 

1. From the embedding lookup table, get the embedding vectors (`Q`) of the N words in the context. 

1. Pass this to the 1st linear layer and run ReLU on it. So far, this looks like - `ReLU ( A1.Q + B1)` where A1 and B1 are the weights and biases of the 1st linear layer. 

1. Pass the above output into the 2nd linear layer and run `log_softmax` on that output. So this looks like - `log_softmax ( A2. (ReLU ( A1.Q + B1)) + B2)` where A2 and B2 are the weights and biases of the 2nd linear layer. 

1. The output vector of the 2nd linear layer has the same size as the vocabulary. This represents the score of each word. The goal is that, for the given N source words of the ngram, it should predict the ngram's target. Hence, the element corresponding to the target word (in this output vector) should have the highest score. 

1. The loss function (negative log likelihood) takes the output vector and a tensor denoting the index of the target word. It returns from the output vector the value of the single element corresponding to the target word. 

1. The training process tries to maximize in the output vector the value of the value corresponding to the target word.

I am mostly okay with the backprop concept, so not going into that.",datashri,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/1892350/please_fix_my_understanding_of_this_tutorial_on/
52,1701528767.0,Using LLMs for a business project,"Hey all! I hope you are doing amazing. I am a noob, I would highly appreciate any help that you can throw my way.

I am currently a computer science student and I recently landed a part-time internship at a business startup. They are expecting me to collaborate with a developer to add an E-mail generation option to their CRM.

I started learning about LLMs and now I have an idea about the basics. It seems to me that I will be working on a Retrieval Augmented generation system for E-mail generation (fine-tuning/prompt engineering won't respond to what they are expecting me to do).

At this stage, I am a bit confused about which LLM I should go for this project. I explored some of the available open and closed source LLMs, and I am aware that each one of them has pros and cons. However, since the startup is tight in budget, would it be a wise idea to go for a small open-source model? I have no idea about the deployment yet and how much it will cost, and if it's better than using OpenAI or Cohere. 

(The system will be used by employees so I wouldn't expect many API calls a day I guess?)

Also are there anything to keep in mind while working on this project?

Many thanks <3",Beneficial-Job-6266,0,0.5,1,https://www.reddit.com/r/learnmachinelearning/comments/1895clq/using_llms_for_a_business_project/
53,1701491950.0,Statistics for Aspiring Data Scientists,"Hello, I'm a computer science student with basic knowledge in statistics. I'm planning to pursue a master's in data science and want to strengthen my understanding of statistics to enhance my data science skills. Although I have experience in data science and machine learning projects, my focus has primarily been on the programming aspect. I'm now keen on participating more actively in Kaggle competitions, and I realize a strong foundation in statistics is crucial for achieving higher ranks. Can you recommend some beginner-friendly books or resources to start with? Additionally, what learning path would you suggest for someone in my position? Thank you!",Captain_70,4,0.75,4,https://www.reddit.com/r/learnmachinelearning/comments/188vr62/statistics_for_aspiring_data_scientists/
54,1701515140.0,Advice for graduation project (video summarization),"I'm a relative beginner when it comes to machine learning, but I'm interested in the field and learning every day. The only issue is that my project's due date won't allow me to follow the normal learning curve for machine learning.   
After reading a lot about current approaches to video-to-video summarization, I discovered that the task is a bit complex. That's why state-of-the-art methods employ a complex model structure. Most of these methods utilize a CNN-RNN architecture for feature extraction and frame scoring.

  
My question is: What are the most basic building blocks/algorithms that I can implement for frame scoring using both supervised and unsupervised methods? Of course, I know that the most basic ones won't achieve high performance, but I need to start my way up from the bottom to make sure I learn and understand everything.

Also, in your opinion, which is better for a grad project? I understand that supervised methods achieve high accuracy on specific videos they have been trained on, while unsupervised methods can work on a diverse set of videos but may have lower accuracy.",Ordinary_Life4810,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/1891h6w/advice_for_graduation_project_video_summarization/
55,1701514676.0,What kind of DL model should I try?,My project is essentially binary classification of text (mostly tweets) of people. Where I want to predict wheather they are complaining about given brand or not (wheather it requires attention or not). My company is using distil bert base uncased for a long time and it's working reasonably well. What I want to do it bring in change and make it even more accurate and fast. Any suggestions about which DL model should I experiment with are welcome.,Happy_Ad_5555,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/1891cs6/what_kind_of_dl_model_should_i_try/
56,1701514572.0,Kabsch-Umeyama Algorithm - How to Align Point Patterns,"Hi there,

I've created a video [here](https://youtu.be/nCs_e6fP7Jo) where I explain how the Kabsch-Umeyama algorithm can be used to align point patterns.

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",Personal-Trainer-541,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/1891bwg/kabschumeyama_algorithm_how_to_align_point/
57,1701502575.0,Need some essential career advice. Please help 🙏,"Hello.
I am looking for career advice. 
I am a final year computer science student. I have been interested in ML and Data Science for past few months. Am decent/good with stats and linear algebra. 
Also complete andrew ng's ML course.
Haven't built any good projects though. 

I am not from a great college and in `India`. So right out of my bachelor's its incredibly difficult to get any good DS roles that is `if there even are any entry level roles for DS/ML/data engineering`
I was wondering what path should I follow to get into MLE. I am interested in software design as well.  So I found data engineering can be good perhaps.
I dont really see myself getting into core research (as of now- who knows about the future?)

I have been doing full stack dev for the past month (its coz of a uni project).
So what I am wondering is will getting some full stack experience help me in any way to get into data related fields or not apart from any personal projects I make. Basically should i do general software engineering and improve my coding skills first
Or should I just stick to ML and jupyter note book based projects. What else should i do **practically** to get into data engineering roles atleast.
What I have been seeing is not many people are working or ML models from scratch but rather building upon existing licensed models like chatgpt.

Any advice?",intellectuallogician,0,0.5,7,https://www.reddit.com/r/learnmachinelearning/comments/188yk29/need_some_essential_career_advice_please_help/
58,1701469659.0,How to prepare for NLP engineer intern interview with weak background?,"I heard back from this [position](https://jobs.apple.com/en-us/details/200513478/machine-learning-natural-language-processing-engineering-research-internship) ""Machine Learning/Natural Language Processing Engineering & Research Internship"" for an interview. My application doesn't have any NLP background so honestly I don't know why they picked me. I'm expecting the interview sometime this month, how should I prepare especially for NLP knowledge?

I've took a undergrad level NLP course so I can answer basic questions like ""how does transformers work?"". But I haven't been following NLP publications. I know a bit of how GPT4 works, RLHF and those stuff. But if they ask ""what's a recent NLP paper that excites you?"" I would have no idea. What would be a good way to prepare? Go over some recent core papers (gpt4, llama etc?)",shaggyday,4,0.75,1,https://www.reddit.com/r/learnmachinelearning/comments/188ob3p/how_to_prepare_for_nlp_engineer_intern_interview/
59,1701479471.0,Advice on LSTM project,"Hi! I am senior CS student and I am doing a project for my intro to ML class and I want to attempt to predict the unemployment rate based on gas prices using LSTM.  I was wondering if I could get some advice on some things such as:  
\- Data Processing - As far as I have gathered, I have to do some feature engineering like converting the data to non-stationary. What other aspects of the data do I have to pay attention to? So far the only thing I've done is adjust the data to inflation. Is there any standardization/normalization I should consider doing?  
\- Training - How do I configure the data for training? I was thinking of having a sequence of monthly averages of gas prices as my example x (January, February, March) and its corresponding y to be the unemployment rate of the following month (April). I don't know if this is a good idea. Should I include the unemployment rate in the data for x?  
\- Data Amount/Augmentation - The data I have ranges from 1940's to current date, Is that sufficient? How do LSTMs generally perform on small amount of data? Is there any possibility of data augmentation for this type of model?  
\- Architecture Consideration - How complex do I want this model to be? I did a little bit of reading of some other LSTM models doing similar time-series forecasting predictions and these are some of the examples I am looking at:  DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks ([https://arxiv.org/pdf/1704.04110.pdf](https://arxiv.org/pdf/1704.04110.pdf)),  An Accurate Bitcoin Price Prediction using logistic regression with LSTM Machine Learning model ([https://www.researchgate.net/profile/Hari-Andi-2/publication/354710727\_An\_Accurate\_Bitcoin\_Price\_Prediction\_using\_logistic\_regression\_with\_LSTM\_Machine\_Learning\_model/links/6187a5fe07be5f31b753b6fd/An-Accurate-Bitcoin-Price-Prediction-using-logistic-regression-with-LSTM-Machine-Learning-model.pdf](https://www.researchgate.net/profile/Hari-Andi-2/publication/354710727_An_Accurate_Bitcoin_Price_Prediction_using_logistic_regression_with_LSTM_Machine_Learning_model/links/6187a5fe07be5f31b753b6fd/An-Accurate-Bitcoin-Price-Prediction-using-logistic-regression-with-LSTM-Machine-Learning-model.pdf)). Are these good examples to base my project on?  


Any other helpful tips are welcomed. Thank you in advance!",GjKernel,2,0.67,4,https://www.reddit.com/r/learnmachinelearning/comments/188rtqa/advice_on_lstm_project/
60,1701464974.0,How can I practice?,"Hi, I'm a freshman and I just finished the first course of Andrew NG's 3 course specialization.  In 2-3 months I'm looking forward to start working with one of my professors. I told him even though I'm not zero programming wise but I have no idea about ML, reinforcement learning, etc. and asked him to tell me what am I supposed to know before I can start work with him. He told me to check this course and learn things like numpy, pandas, scikit-learn, etc. I'm going through the specialization but I have no idea where can I apply the knowledge I gain or how can I practise?  


Is there a website or something like hackerrank where I can practise data science, ML algorithms and such?",Trevorego,7,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/188miwp/how_can_i_practice/
61,1701477561.0,What is wrong with my prediction model?,"Complete beginner here. Not sure if this is the right place to ask. Any help is appreciated. Thank you!

  
I'm currently trying a prediction model and facing some challenges. I used Chatgpt for most of the coding and see how it goes. project and the issue I'm encountering:

&#x200B;

Goal: power prediction from a wind turbine.

 I have a 5-year dataset of 10min data points. Had too many NaN, I used 7  day-rolling mean  and kNN. 

 I have a 5-year dataset of 10min data points. Had too many NaN, so I used 7-day-rolling mean and kNN to replace them. The model includes 6 features.

Target- Power (the graph for this variable is showing repetitive patterns).

Applied SARIMA to predict features.

random forest for power prediction.

Would different handling of NaN values impact the model?

&#x200B;

https://preview.redd.it/4u8i0eda2s3c1.png?width=1456&format=png&auto=webp&s=f399d6bc17e61c9339ad1a2fe56cdb9426ee16bf

&#x200B;",Impressive_Papaya306,4,0.75,8,https://www.reddit.com/r/learnmachinelearning/comments/188r64p/what_is_wrong_with_my_prediction_model/
62,1701487676.0,Advice on how to achieve this particular task.,"Hi everyone

I'm trying to create a program that can create parallel texts of one book in different languages using machine/deep learning. The program's input would be two files (eg. epubs) of a certain novel, each file is in a different language, and generate some sort of structured data of each line in one language and its rough equivalent in the other language. 

I can probably use statistical methods to do this like use some ready-made universal embedding library and try to match the sentences using it. But I'd like to explore some options that include machine/deep learning methods that can be trained to specifically and accurately do this task. 

What sort of roadmap can I follow that will help me accomplish this task? What should I learn? Can transformers be used to achieve this?

A little bit of background about me: I have a Bachelor's in an engineering field, and have a pretty strong background in Linear Algebra/Partial differential equations/Numerical Methods/Algos and data structures. I can also program quite well in typescript, python, bash and emacslisp/scheme. I'm willing to learn more to achieve this.

Thanks :)",Jenhate,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/188ui0n/advice_on_how_to_achieve_this_particular_task/
63,1701470617.0,Help: I don't understand Random Forest,"I have watched some YouTube videos and read several web pages that promise to explain the random forest algorithm in a simple way, but some things continue to be unclear to me.
For example: when I use random forest to do a classification, I learned that the output provided is the class that the largest number of trees ""voted on."" But why does each tree provide me with only one result if it used a subset of my data? Assume that each tree used a sample consisting of 12 data, e.g. 12 people,and that the two possible classes are red or blue. 

Why the output of a single tree Is simply 'red' or 'blue'?
Shouldn't the output from each individual tree be something like, ""10 red, 2 blue"" or ""7 blue, 5 red,"" etc.? 
I hope the question is clear. 
Sorry if it is stupid.",Dollililly,2,1.0,7,https://www.reddit.com/r/learnmachinelearning/comments/188oo0a/help_i_dont_understand_random_forest/
64,1701482590.0,Create Answer-Bot from .csv file without external APIs?,"Not 100% sure if this is in the correct subreddit but would there be anyway to create a chat-bot without using any external API keys (OpenAI, ChatGPT, etc.) where a user types in a question and it would use some algorithm to search a .csv file with (let's say 300 knowledge articles) and output either the closet answer it can find within the articles that relate to the question or output the knowledge article that closet can answer the question the user input?  


I have coding experience but am new to the AI/ML world.

&#x200B;",Bballjoe12,1,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/188svj4/create_answerbot_from_csv_file_without_external/
65,1701476635.0,"🌟 ""Creative Spark"" - Revolutionizing Creativity with AI: Share Your Thoughts! 🎨🎵✍️","Hey everyone!

I'm excited to introduce ""Creative Spark,"" an AI designed to be your creative sidekick! Whether you're into writing, painting, music, or digital art, this AI is here to boost your creativity and guide you through your artistic journey.

What is Creative Spark?
""Creative Spark"" is an AI companion that helps you:

Generate and develop ideas
Provide feedback on your creative projects
Offer suggestions tailored to your style and needs
Create a fun, engaging, and addictive creative process
Why ""Creative Spark""?
We believe creativity should be limitless and accessible to everyone. With ""Creative Spark,"" we aim to:

Make the creative process more intuitive and less daunting
Foster a supportive community for sharing and inspiration
Continuously adapt and evolve with your creative needs
We Need Your Input!
As we fine-tune ""Creative Spark,"" your insights are invaluable. We'd love to hear your thoughts:

What features would you want in an AI creative assistant?
How do you envision AI enhancing your creative process?
Any specific challenges you face in creativity that AI could help with?
Join the Creative Revolution!
Let's discuss how AI can transform the way we create and share art. Your feedback will shape ""Creative Spark"" into an AI that truly understands and amplifies your creativity.

Can't wait to hear your creative insights and ideas![Creative Spark GPT](https://chat.openai.com/g/g-tByz2BYfI-creative-spark)",Intelligent_Guava267,0,0.33,0,https://www.reddit.com/r/learnmachinelearning/comments/188quhs/creative_spark_revolutionizing_creativity_with_ai/
66,1701476269.0,Easy historical weather data request? Where should I go/What should I do?,"Looking to try out tensorflow and build a small linear regression for weather data in my area. Hopefully something cute to put on a resume.

Does anyone know where I can find some data? I'm just looking for 1 specific location/city in the USA. Everything I've tried initially doesn't get me closer to that dataset. I can clean the data myself. As far back as possible, but ultimately range of 100 years would likely be what I'm looking for.

The hardest part for machine learning, for me at least, is understanding how people find data. ",Quaysan,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/188qpnq/easy_historical_weather_data_request_where_should/
67,1701472310.0,M2 Max 96GB or M2 Ultra 64GB,"Mac Studio Apple M2 Ultra Chip with 24‑Core CPU and 60‑Core GPU, 64 GB RAM

or

Mac Studio Apple M2 Max Chip with 12‑Core CPU and 38‑Core GPU, 96 GB RAM

For working with LLM. What would you do?",breadandtacos,0,0.5,2,https://www.reddit.com/r/learnmachinelearning/comments/188pahu/m2_max_96gb_or_m2_ultra_64gb/
68,1701454547.0,Multiprocess Inference on a single GPU,"I want to implement tiling at inference time for a semantic segmentation model to help me detect smaller features. I need to detect features in real-time, so I need to maintain a high fps. Currently, I split the initial image into two halves and then scale each sub-image down to 640 by 640 (the model's input size). This naturally leads to half the initial fps, as I am running inference twice sequentially per input image.

My thought was that I could maintain the initial fps by running inference on each sub-image in a separate process using pytorch's multiprocessing module. However, I am a little fuzzy on how CUDA GPU's speed up inference in pytorch and if this would actually lead to boost in inference time. Would I need multiple GPU's to actually do multiprocessing? Or if a 640 by 640 image only takes up a tenth of the GPU memory could I in theory run inference on 10 such images simultaneously without seeing a dip in inference time per image (i.e. all ten images can be segmented simultaneously)?

Thanks in advance!",MusicalHawk9389,2,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/188ij82/multiprocess_inference_on_a_single_gpu/
69,1701445697.0,Future ML Researcher Job Market (UK),I'm an Economist looking to apply for ML PhDs in the UK focusing on Causal ML.  How have opportunities for  research scientist positions positions evolved?  Are the amount of opportunities in the private sector shrinking?,Ckdew,3,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/188f2lg/future_ml_researcher_job_market_uk/
70,1701430208.0,Are there any models that can answer with images from the training dataset?,"I have a set of PDF documents that I want to use as knowledge base for a LLM model, however many of these documents point to images in them to show how certain procedures should be followed.

One alternative would be to program this stand-alone and incorporate it with the LLM, but this would mean indexing every image every single time. So since some GPTs can now answer with images as well, I thought maybe there is a chance some of the models can retrieve an image from the training and use it alongside the answers?

If not, is anybody willing to partner up and develop something similar?",durian_pizza,5,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/1889n92/are_there_any_models_that_can_answer_with_images/
71,1701446665.0,CNN multi class classification,"Hi, I'm using a CNN model to classify image. I have a multi class problem.

I trained the model and saved using pickle. When I gave an image as input, the output is an array with the confidence of the model for each class.

So the problem I'm having is: how can I know that the array element  in position 0 is the confidence associated to the class (for example) 2?

Thanks",TonyCartoon,2,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/188fgi6/cnn_multi_class_classification/
72,1701455154.0,Prolog: Greedy Robbers River Crossing Puzzle,"  
Can anybody help solve the below Greddy robbers river crossing puzzle using   
swish **prolog**?   


It can be solved here directly- [https://swish.swi-prolog.org/](https://swish.swi-prolog.org/)  
I have tried many ways but still cannot get the sequence. No AI had been useful debugging it.  


  
Consider the following Greedy Robbers River Crossing Puzzle Three robbers are running from the scene of a bank robbery. They are each carrying a bag of cash. The amounts in the three bags are: £3000, £5000 and £8000. Blocking their escape is a river, that the robbers need to cross. As luck would have it, there is a raft which will allow either one or two robbers to cross the river. If only one robber is on the raft they may also carry one of the bags across. So the possible types of crossing are: one robber, one robber and one bag, two robbers. If they trusted each other, the robbers with all their bags could easily get to the other side of the river by making several trips. However, there is a problem. The robbers are greedy and selfish; so, if there is a chance of them getting more money than they had initially stolen, they will will steal from the other robbers. So the robbers do not trust each other; and because of this the river crossings must satisfy the following conditions: 1. No robber can be alone on either side of the river with bags containing a total amount of cash that is more than was in the bag they initially had in their bag. (Otherwise they would run off with the cash.) 2. No two robbers can be on one side of the river with bags containing a total amount of cash which is more than the total amount in their original two bags. (In this case they would split the additional amount and run off.) To solve this problem you must find a sequence of crossings that enable all three robbers and their three bags to get to the opposite side of the river.   


&#x200B;",Wasim-__-,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/188irvb/prolog_greedy_robbers_river_crossing_puzzle/
73,1701416163.0,Is Tensorflow certificate worth it?,"I planning to prepare for tensorflow examination, how much time should i dedicate for exam and is it going to hard, medium or easy level. Does it help me get job in ML domain ?",_Killua_04,5,0.67,14,https://www.reddit.com/r/learnmachinelearning/comments/1886678/is_tensorflow_certificate_worth_it/
74,1701436445.0,Machine learning specialization with zero python experience,"Hey guys, I have started Andrew Ng’s machine learning specialization and am understanding the theory behind everything but have no idea what is going on when it comes to the optional labs.

Should I skip the labs and do them after I learn a bit of python or would you suggest learning python first then doing the course or learn them simultaneously 

And if so how much programming do I actually need to learn and what resources would you recommend 

Thanks in advance",erenjeager2,1,0.57,6,https://www.reddit.com/r/learnmachinelearning/comments/188bkp0/machine_learning_specialization_with_zero_python/
75,1701447539.0,"OpenML Guide: Embracing Open Source and Free Resources, Offering a Wealth of Books, Courses, Papers, Guides, Articles, Tutorials, Notebooks, AI Field Advancements, and Beyond.",,Jiraiya27s,1,0.6,0,https://www.openmlguide.org/
76,1701439950.0,Six Figure Data Science eBook,,tropicalLeporid496,0,0.5,0,https://downloads.tatevaslanyan.com/six-figure-data-science-ebook
77,1701439712.0,Custom dataset,"I'm a graduate student in the field of animal behavior analysis and I'm working on my deep learning project. 

But I'm having trouble making the dataset now. I finished recording a video of an animal's movement, but I don't know how to convert the video into a picture. 

Any actionable advice I will follow, thanks for your help.",Holiday-Sir-3341,0,0.5,2,https://www.reddit.com/r/learnmachinelearning/comments/188cqmq/custom_dataset/
78,1701439532.0,Metrics for evaluating summarizations done by LLMs?,"Hey guys, I'm writing my thesis on text summarization by LLMs. I have to compare GPT with other LLMs and evaluate the summaries. I found that metrics like Rouge and Bleu are noot really suited for the evaluation. If you had to choose 4 metrics, which ones would you choose?",mrhennessy26,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/188co3i/metrics_for_evaluating_summarizations_done_by_llms/
79,1701397413.0,Who's a notable researcher working in a totally different paradigm than neural networks that has potential to beat it or make a better model for human/animal(limited) intelligence?,"Similarly, I know GHinton believes that neural networks right now might be close (mathematically) for a model but believes that a different learning algorithm is used by the human brain. 

I want to find researchers who have a radically different mindset into modeling real life neural networks. Please note that I am interested with researchers that want to get closer to biologically plausible models rather than beating benchmarks in the Ai field right now.

EDIT: i am not looking for researchers to recruit, i just want to know their name or read their research or thoughts.",MysticalDragoneer,8,0.79,12,https://www.reddit.com/r/learnmachinelearning/comments/1880fxx/whos_a_notable_researcher_working_in_a_totally/
80,1701403461.0,Looking for some advice on my prep before reading Mathematics for Machine Learning,"I'm interested in reading this book but I am definitely missing a chunk of the prerequisites for it. I haven't studied any university-level maths before so I know I have a lot to learn but I don't want to go down a huge, unnecessary rabbit hole of topics and subtopics if I can avoid it. 

From what I've read it seems I need to study: Stats, Linear algebra, and lots of Calculus.

Is there anything else I'm missing? A simple checklist would be greatly appreciated.

I've been using Khan Academy, specifically the [Statistics and Probability](https://www.khanacademy.org/math/statistics-probability) course, to brush up on my stats from school and delve into college level. I'm planning on doing the [College algebra](https://www.khanacademy.org/math/college-algebra) course afterwards (possibly unnecessary? I only ever see linear algebra mentioned), and then following this up with some of the Calculus courses. (Calculus AB,  Calculus CD, Calculus 1, Calculus 2, Differential, Integral, Multivariable) I'm not sure which of these are needed, I find the naming very confusing.

Will this be enough to build a good foundation? If not, any recommendations on resources I can use  before I read Mathematics for Machine Learning?

Also, I don't want to plan too far ahead but any ideas what I can do after this?",scorchedturf,5,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/1882gwj/looking_for_some_advice_on_my_prep_before_reading/
81,1701400020.0,Control theory and ML,"I am trying to get started in ML and could use some advice.

I work in distributed systems but have a background in control theory.  I can see a place for ML to tackle control theory for the complexity of distributed systems.

For example, I would like to use ML to control kubernetes clusters and other systems to fine tube for performance.

Any pointers?",tabgok,6,1.0,7,https://www.reddit.com/r/learnmachinelearning/comments/1881cfh/control_theory_and_ml/
82,1701416717.0,5 GitHub Alternatives for Data Science and Machine Learning Projects,,kingabzpro,2,1.0,0,https://www.kdnuggets.com/the-top-5-alternatives-to-github-for-data-science-projects
83,1701430228.0,Issue when training my model on a Mac gpu," I followed these instructions to utilize my gpu when training: [https://developer.apple.com/metal/tensorflow-plugin/](https://developer.apple.com/metal/tensorflow-plugin/)

However, whilst training my model, after the first epoch, the loss function goes very high (from like around 3 to above 270). This does happened when I train in my normal environment.

 I get this message when I train using my gpu: 

tensorflow/core/grappler/optimizers/custom\_graph\_optimizer\_registry.cc:114\] Plugin optimizer for device\_type GPU is enabled.

I tried disabling custom graph optimizers and plugging optimizers but I still keep getting that message when I train. Im not even sure this is even causing the issue.

If anyone has any experience training using tensorflow on a Mac accelerated metal, could you please help me?",Basic_Masterpiece414,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/1889nij/issue_when_training_my_model_on_a_mac_gpu/
84,1701397018.0,How are the initial word embeddings determined in a transformer model?,"Hi,  


I was just asking myself this question about the transformer. I'm mainly interested in the one from ""Attention is all you need"" encoder-decoder model, I assume other ones (GPT, Llama etc) will be similar.  


So I get the backprop thing to update the Q, K, V matrices, feedforward NNs, etc. but how are the initial word embeddings the model trains on determined? Are they just randomized? Or do they take those from word2vec or other simple models? And are there research papers that investigate if using word2vec embeddings as the initial embeddings is possible to train a transformer (& perhaps faster, as in they converge faster)?

I know that for neural networks, the weights are usually initially randomized, but I was wondering if its the same for Transformer models. I couldnt find an explicit answer for this in the Attention paper.

Thanks",Remarkable_Use328,5,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/1880b4k/how_are_the_initial_word_embeddings_determined_in/
85,1701361329.0,"Build, Visualize and Launch Big Data DAGs",,quicklyalienated76,28,0.87,0,https://www.taipy.io/posts/build-visualize-and-launch-big-data-dags
86,1701426661.0,Dynamic RNN layer determination?,"Hi,

I am working on a research project that could benefit from some ML-based modeling. I'm wondering if anyone is aware of research on LSTM (or other RNN) models in which the number of cells/layers is dynamically determined during the model's execution. For example, a neural network cell that outputs a class, a criterion deciding whether the network continues running (+ a penalty for a higher number of cell iterations).

I've tried searching for this without success. Any pointers toward keywords or studies would be much appreciated. (Bonus points if the model is able to incorporate new evidence each iteration.)",ActuaV,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/1888q00/dynamic_rnn_layer_determination/
87,1701356502.0,What should a fresh college graduate do to make it as a ML engineer?,"I am currently in my 3rd year of engineering in CS and about to start a web dev internship. But my interests have been more aligned towards ML. So I wanted to ask the more experienced audience:

1. How much theoretical maths do you actually need to know?
2. What can I do to increase my chances of being hired for such roles?

A little about me: I had taken AI and ML courses in college so I know the theory but have little experience implementing it.
Also I got a 99.9%ile on the maths section of my entrance exam so I have no problem with it. 
Any and all suggestion are most welcome. Thanks in advance :)


Edit: thank you so much everyone for your responses. This is my first time using reddit and finding such a helpful community is so heartwarming (⁠◍⁠•⁠ᴗ⁠•⁠◍⁠)⁠❤",Ok_Style_4294,34,0.8,49,https://www.reddit.com/r/learnmachinelearning/comments/187kkcl/what_should_a_fresh_college_graduate_do_to_make/
88,1701419053.0,IBM Watson DTE NLU Demo,"Hey everyone,

I'm exploring NLP demos and am curious about the Google NLP demo and IBM Watson's NLU demo.

I did some digging and people say IBM Watson is more of a marketing gimmick than real engineering.

My plan is to test these tools with my blog content to see how they interpret and analyze natural language.

Any insights or personal experiences would be really helpful, thanks so much!",TakExplores,0,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/1886vuy/ibm_watson_dte_nlu_demo/
89,1701390561.0,Rice Leaf Disease Recognition using Deep Learning,"Rice Leaf Disease Recognition using Deep Learning

[https://debuggercafe.com/rice-leaf-disease-recognition-using-deep-learning/](https://debuggercafe.com/rice-leaf-disease-recognition-using-deep-learning/)

https://preview.redd.it/h47q197nvk3c1.png?width=1000&format=png&auto=webp&s=49932b607920beedbb8892e8e75ce94629936ed6

&#x200B;

&#x200B;",sovit-123,5,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/187xysw/rice_leaf_disease_recognition_using_deep_learning/
90,1701376095.0,Which epoch is the best for me to choose?,"I have trained my deep learning model. I also saved the validation loss to a file and plotted on a graph

https://preview.redd.it/p2sbi7ikoj3c1.png?width=1000&format=png&auto=webp&s=d322a4a1d1c061c236740653ec8cc98f5736aba6

I have 2 questions for this:

* Does the validation loss look normal ? Is there any issue with the validation loss ?
* How can I determine which epoch is the best epoch so I can choose ?

If you need any additional information, I can provide. Thanks",Efficient_Scale_218,8,1.0,18,https://www.reddit.com/r/learnmachinelearning/comments/187s8uq/which_epoch_is_the_best_for_me_to_choose/
91,1701357323.0,"Do you have an ML job? If yes, what did you have to do/learn to get it?","Hello. So I’m a complete newbie in ML. I want to be able to land a job in ML in atleast a year or two from now. 

I’m hearing a lot of people on reddit saying the job market is tuff for entry ML engineers. 

So I want to hear your experiences. Did you have to go through data jobs before landing your first ML job or did you just jump right at it?",Ok_Tumbleweed8796,20,0.95,26,https://www.reddit.com/r/learnmachinelearning/comments/187kvld/do_you_have_an_ml_job_if_yes_what_did_you_have_to/
92,1701370745.0,An NLP project using OOP in python,"Help me come up with an easy/mid NLP project in which I can implement OOP. I really don’t have any ideas, because so far all my NLP-code didn’t require use of classes. It’s for school so I’m on a tight deadline, thus the project should be easy enough. Maybe you have any ideas? The project doesn’t have to be strictly all NLP, it could be just a part of it",Unlucky-Captain-4088,5,0.86,4,https://www.reddit.com/r/learnmachinelearning/comments/187q4ge/an_nlp_project_using_oop_in_python/
93,1701402102.0,Machine Learning Specialization by Andrew Ng - opinion requested,"I'm asking for thoughts on Andrew Ng's latest course on ML. Are they better than his much vaunted original course ?  


[https://youtube.com/playlist?list=PLkDaE6sCZn6FNC6YRfRQc\_FbeQrF8BwGI&si=f7lph\_qUQsrdHfwS](https://youtube.com/playlist?list=PLkDaE6sCZn6FNC6YRfRQc_FbeQrF8BwGI&si=f7lph_qUQsrdHfwS)",Rough-Visual8775,1,0.67,1,https://www.reddit.com/r/learnmachinelearning/comments/18821fw/machine_learning_specialization_by_andrew_ng/
94,1701369951.0,Check out the Intel Developer Cloud - it has free training and workshops and an option to launch a JupyterLab to try things out!,,sonya-ai,5,0.86,0,https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Democratizing-AI-Access-with-Intel-Developer-Cloud/post/1546586
95,1701400954.0,REALLY REALLY need help on Model premature convergence," Hello my saviors,

I am a beginner in c++ and deep learning and believe it is good to write c++ deep learning codes to practice both skills.

Now I have my codes and try to reproduce a project from coursera (Deep learning specialization course1 W4). However, my model always converge prematurely (after a few hundreds iteration). The cost always converge to \~0.6 and the accuracy is \~0.7 (vs coursera project cost = 0.08, accuracy = 0.99).

I have spent months checking everything and couldn't find what is wrong. I would genuinely pay 50 bucks (maybe is too little for programmers?) to anyone who can help me fix it.

The project is below

[https://github.com/l454025801/SiN](https://github.com/l454025801/SiN)",PermenantHeadDamage,1,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/1881non/really_really_need_help_on_model_premature/
96,1701397071.0,Looking to build NLP Model - Need sports games transcripts,Hi all - I am a college student looking to build a Word Language Model for Natural Language Processing using play-by-play and color commentary from any sports games - does anyone know if transcripts exist of such thing for TV/Radio. Thanks!,FantasticPotato2470,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/1880brb/looking_to_build_nlp_model_need_sports_games/
97,1701347731.0,"Getting started with ML, is there anything I need to focus on?","Is there a particular algorithm that's really in demand, or some common pitfalls I should avoid?

I wanna be able to put this on my resume, so any beginner projects I can focus on?

Thank you for reading and responding, I really appreciate your help.",Hades8800,7,0.9,20,https://www.reddit.com/r/learnmachinelearning/comments/187hj3j/getting_started_with_ml_is_there_anything_i_need/
98,1701386636.0,"Fine-tuned BERT model, how to deal with abbreviations and English as non-first language?","Hello,  


I am a software developer slightly dabbling in ML with not much experience at all. I am using the Hugging Face library using the BERT LLM and fine-tuning it based on some industry-related data to provide a sentiment analysis for groups of text. I work for a healthcare company, and we are trying to get a sentiment analysis of a shift note from a carer, but there are a few problems. I understand that it's hard to grasp where I'm coming from without seeing the training data-set but using the real-world data the analysis is correct around 87% of the time and it is good at picking up context, however the notes that are incorrect are usually when they have one of those problems in it, so I'm wondering if there is a way to get around this or try make up for these errors?  


1. Abbreviations are used a lot for things like locations, businesses and just general words/phrases. Do I need to add in the abbreviations into the data sets? For example- a note might say ""OT today"", meaning they went to the Occupational Therapist today. Which is a positive analysis, so would I need to train the data on the abbreviation as well as the normal word?   
Also when it is an abbreviation of something that I wouldn't know (which may be in context of their company/location/industry) how could I help the data, for example in a note ""Friendlies for a LMW fasting test."" came back negative with 0.99 confidence, and there is nothing in there that would determine negative based on the training data. 
2. A lot of workers do not have English as their first language, so there are misspelled words and the incorrect word (which is a correctly spelt word) based on the context of what they are trying to say- eg. ""I didnt no what that is"" (no is supposed to be know). Does this have that much of an impact on the performance of the model?
3. Do numbers play a role in the analysis as there are notes like ""Physio at 10"" which come back negative, while there would be no data in the data-set that would make this negative.
4. Does punctuation play a big role in determining the context as well? I would get a note like this that comes back negative 0.85 confidence (names changed for privacy)- ""8:30 TL Kieran start shift  Ben came and cut trees shapes with jigsaw  Planing with John   11:00 TL Kieran finished shift"". Where the person didn't input any punctuation, and it's all hard to understand context.",looking_to_learn_ml,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/187whjn/finetuned_bert_model_how_to_deal_with/
99,1701383724.0,Class probability imbalanced random forest?,"
Hello,

I’m working on a project where I’m trying to classify an imbalanced data set. 15% class as negative and 85% class as positive. The data set has ~4000 data points. I’m interested in getting the “true probability” that an input is of the positive class. I’m using a RF model and decided to use SMOTE to handle the imbalance. There’s a pretty significant improvement over the standard RF model when looking at the confusion matrix and the AUC score. The SMOTE model is able to detect negatives significantly better. 

I’m using predict_proba for the probability which I understand is the average proportion in the leafs of the decision trees. However I’ve read that these probabilities are true probabilities and can’t be used as such. I read about the idea of calibration platt and isotonic. And also read about how under/over sampling makes those probabilities invalid. I found a formula about how to adjust the probability back to the original dataset. 

I’m confused about whether the formula or calibration is the correct thing to do to get to the true probability using the SMOTE model. I also noticed that it seemed like the SMOTE essentially changed the classification threshold. When adjusting the SMOTE probabilities those with probabilities of 80% were classed as negative. 

Ultimately I’d like to use these probabilities as part of an expected value calculations but I struggling to understand whether the probabilities I have are valid probabilities for that. 

Please help clarify my understanding. Thanks!",FullMetal373,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/187vbpa/class_probability_imbalanced_random_forest/
100,1701380910.0,Looking for similar educational content like this,"https://youtu.be/p1bfK8ZJgkE?si=439ofCFcaFX1EBie (Krish Naik - End to end deep learning project with deployment)

I am a ""full stack"" data scientist with a couple of years experience, and I really like this type of content where they cover end-to-end projects with a high level of code and implementation quality (i.e. modular and reusable code, decorators, dataclasses, pydantic, mlops, dvc, ci/cd, deployment, etc.)

Are there any similar courses, videos, creators, websites, or similar you would recommend that cover similar stuff with equal skill level? I have implemented end-to-end projects like this in my current job, but i wish to learn more and adhere to best practices when it comes the python development, machine learning application, and so on.",Fendrbud,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/187u6w9/looking_for_similar_educational_content_like_this/
101,1701344705.0,All in one resource,Are there any resources that covers the whole implementation along with codes and if possible with a little intro,Dani_sk,6,0.88,6,https://www.reddit.com/r/learnmachinelearning/comments/187go21/all_in_one_resource/
102,1701379373.0,Applio cli troubleshooting,"os ubu 22.04   
Applio-RVC-Fork 

python [infer-web.py](https://infer-web.py) \--pycmd python --is\_cli

go infer

logs/weights/modelRV.pth assets/audios/vocals.wav wav logs/added\_IVF558\_Flat\_nprobe\_1.index 0 -2 harvest 160 3 0 1 0.95 0.33 True 8.0 1.2 1 0 50 1000

error of the moment

FileNotFoundError: \[Errno 2\] No such file or directory: 'assets\\\\rmvpe/rmvpe.pt'  


the [rmvpe.pt](https://rmvpe.pt) file exists in assets/rmvpe/   


no idea why / who it has the \`\\\\\` in the error line or what it wants as a fix",altpersona2,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/187tkas/applio_cli_troubleshooting/
103,1701355137.0,Any good books I can read on Kindle for Ai/ML stuff?,"Reading super intelligence now, seems a little pop sciencey..",derpgod123,3,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/187k1oq/any_good_books_i_can_read_on_kindle_for_aiml_stuff/
104,1701363794.0,MLM to parse through audio input to discern music from background ambience,"Hello all :)  
I'm working on an iOS audio app that processes microphone input to reactive visualizations synced to the music. I have an AVFoundation pipeline set up to record audio, perform real-time FFT analysis into frames of features like spectral centroid and chroma vectors, and map these to parameters driving the visuals.

I would now like to train a model to distinguish music from ambient noise in the mic data to filter out segments with just irrelevant background talking or sounds. The app is built in Swift and needs to perform prediction very efficiently even on older iPhones (ideally lol, not the biggest concern).

What type of neural network model would you recommend for classifying short sequences of audio features per frame? I'm considering LSTM or Transformer architectures. What feature sets provide the most discriminative signal for music vs noise? Should I quantify model accuracy by frame-level predictions or aggregate metrics like overall sequence accuracy? Any advice on optimizing models for real-time mobile inference?

I have experience gathering and labeling timestamped training data pairs of raw audio and feature sets. Please let me know what other specifics around data, model configuration, metrics, or optimization would be useful to provide. Thanks in advance for any guidance!",zeke-001,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/187nesm/mlm_to_parse_through_audio_input_to_discern_music/
105,1701363587.0,Is there any ML model (read description)?,"Hello, I'm looking for a ML model, I don't know much about ML but what I'm looking for the model that can remember the conversation and at the last gives the output, note that the number of questions are fixed but the task is user can give the questions' answers' in any order.

Here's how conversation will be

    Machine: How may I help you?
    Human: I am my name and 16 years old.
    
    Machine: in which state you're living?
    Human: I'm living in state.
    
    ....
    
    Now at the end should produce the JSON or key value pair output according to the data.

Note that I don't want to use GPT here, but if there is any model available I want to use that.",harkishan01,1,0.67,2,https://www.reddit.com/r/learnmachinelearning/comments/187nbmq/is_there_any_ml_model_read_description/
106,1701348987.0,Prep for FAANG+ ML Research Intern Interview,"I just got a referral for a Research intern position in ML at a FAANG+ company, but there's a catch - my three interviews are in just one week. My background is in mathematics and it's been over a year since I last dived into ML courses. I'm trying to view this as a learning experience, yet, being naive, I can't help but hope it turns out well. I've started with neetcode's list for some quick DSA prep, but I'm not sure it's the best fit for a research-focused ML interview. Could really use your suggestions or experience on how to effectively utilize this week for prep. Any tips on how to make the most of it? ",Opening_System_1662,2,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/187hwoy/prep_for_faang_ml_research_intern_interview/
107,1701360032.0,"When doing batch inference with a BERT model, how do I know when my batch size is too big?","I've got an Nvidia A6000, which has like 15 times more VRAM than it needs to run a BERT model. I have found that if I am doing inference for classification on a large dataset, I can crank the batch size to like 128 or bigger, but I'm not sure if I'm actually getting a speedup at all. Is there anyway way to know without running my dataset like ten times whether my batch size can be increased and I'll see a speedup? At the moment my dataset has nearly 500,000 sentences to classifier and if I have to run it 10x at different batch sizes I might as well just accept a slower single run.",crono760,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/187lws7/when_doing_batch_inference_with_a_bert_model_how/
108,1701355614.0,"Error using TensorFlow, Keras-rl2 and numpy.","I don't know if it's appropriate to send it here, but google, stackoverflow and ChatGPT were of no help. Been banging my head for hours now.  
So I'm using:  
  \- tensorflow 2.13.0 (Tried to use tensorflow-macos 2.12.0 got the same error)  
  \- keras-rl2 1.0.5

  \- numpy 1.23.5

I'm working on OpenAI's gym, and get this error.  


     File ""/Users/tima/AI/BlackJack/venv/lib/python3.11/site-packages/keras/saving/legacy/serialization.py"", line 368, in class_and_config_for_serialized_keras_object
        raise ValueError(
    ValueError: Unknown optimizer: 'additionalupdatesoptimizer'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope

Here's my code  


    import random
    import gym
    import tensorflow as tf
    import numpy as np
    
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, Flatten
    from tensorflow.keras.optimizers.legacy import Adam
    
    Adam._name = ""Adam""  #if I don't include this, I get an error
    
    from rl.agents import DQNAgent
    from rl.policy import BoltzmannQPolicy
    from rl.memory import SequentialMemory
    env = gym.make(""CartPole-v1"",
                #    render_mode=""human"",
                   )
    
    states = env.observation_space.shape[0]
    actions = env.action_space.n
    
    model = Sequential()
    model.add(Flatten(input_shape=(1,states)))
    model.add(Dense(24, activation=""relu""))
    model.add(Dense(24, activation=""relu""))
    model.add(Dense(actions, activation=""linear""))
    
    
    agent = DQNAgent(
        model=model, 
        memory=SequentialMemory(limit=50000, window_length=1), 
        policy=BoltzmannQPolicy(), 
        nb_actions=actions, 
        nb_steps_warmup=10, 
        target_model_update=0.01)
    
    agent.compile(Adam(lr=0.001), metrics=[""mae""])
    agent.fit(env, nb_steps=100000, visualize=False, verbose=1)
    
    results = agent.test(env, nb_episodes=10, visualize=True)
    print(np.mean(results.history[""episode_reward""]))
    env.close()

&#x200B;",mmario312,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/187k83h/error_using_tensorflow_kerasrl2_and_numpy/
109,1701353184.0,How to Improve your LLM? Find the Best & Cheapest Solution,,OnlyProggingForFun,1,1.0,0,https://youtu.be/pHv9SsE4Mb4
110,1701336216.0,NLP project ideas for knowledge graphs on language models,"Hey everyone, for my internship, I've got to come up with a problem statement that needs to utilize knowledge graphs to solve an NLP problem. Now, I'm new to this and have yet to dive into the field, but the idea is to do that via this project. So any suggestions would be extremely helpful!! ",venkat_1924,2,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/187ek93/nlp_project_ideas_for_knowledge_graphs_on/
111,1701302439.0,Machine learning model to detect duplicate invoices?,"So I’m an auditor for a state agency, and I’ve been working on finding some duplicate invoices. I’ve had some luck finding it, but it involves a bit of filtering and some guessing. 

Generally I find them by filtering on, making sure the invoice dates are equal, the amount are the same, and a fuzzy match on the invoice id. 

The system doesn’t allow invoice ids to duplicate from the same vendor so you won’t have invoice 712 twice, you may have invoice 712 then 712- or something. 

That works on finding a lot of them. But those are just simple instances when the the invoice ids are numbers. However, it gets more complicated with certain invoices. 


Like one invoice ID may be December 2023 Rent and then the duplicate is Rent DEC 23. Those are kinda hide to find by filtering and honestly just involves a bit of luck. 


Now the biggest issue is I don’t have time to filter through them all and there’s a bigger subset that I’m not even exploring because it would take even longer. 

Maybe the invoice dates are two days off sometimes we have instances where there are an entire day off. 

And depending on where the voucher is coming from, I don’t always have direct quick access to see the documentation and confirm. I have to reach out and request it from someone at times. 

Not only that but I set it so that we only select vouchers over $1000 to reduce the amount I have to filter through. 

So I was thinking about creating an Ann model to predict if invoices are duplicates. 

So I was thinking about just getting invoice ids with just numbers and letters and ignoring spaces. 

Then for features I would do, difference in length of invoice Id, a dummy variable for if the a fuzzy match using only numbers on the invoice id works. 

How many payments to them in the last year. In the last year, how many instances of payments to them would match within the last year. How many days apart are the invoices. A dummy variable for if the month matches, one for if the day matches. 

The edit distance between the invoices ids, as well as the the edit distance between just the numbers in the invoice. 

I don’t know if it will work. Maybe, maybe not, I don’t know. 

Just wanted some thoughts, suggestions, ideas or whatever.",CaptainVJ,8,0.85,21,https://www.reddit.com/r/learnmachinelearning/comments/18744ro/machine_learning_model_to_detect_duplicate/
112,1701339592.0,Machine Learning for Batteries,"Hello, I am currently an MSc student who will perform a thesis in modelling, but I want to pursue a PhD in AI/ML in battery modelling and materials discovery. Are there any scientists and engineers who are working on this field? May I ask which courses you have taken? I only know PyBaMM",SecureStandard3274,1,0.66,0,https://www.reddit.com/r/learnmachinelearning/comments/187fd2n/machine_learning_for_batteries/
113,1701321826.0,10 Best Deep Reinforcement Learning Courses in 2024,,Aqsa81,2,1.0,0,https://www.mltut.com/best-deep-reinforcement-learning-courses/
114,1701262886.0,We've programmed our DIY smartwatch to take the wheel and steer the Space Rover around 🚀🌌,,Albert_Gajsak,38,0.87,1,https://v.redd.it/x5d7paiyba3c1
115,1701284153.0,What do you think ChatGPT does when you ask it to do Sentiment Analysis?,Could be silly question but if you give a sentence to ChatGPT and ask it to give a sentiment analysis what do you think it does?,PinstripePride97,12,0.75,30,https://www.reddit.com/r/learnmachinelearning/comments/186x2t3/what_do_you_think_chatgpt_does_when_you_ask_it_to/
116,1701319018.0,How to calculate mean for Gaussian distribution,"&#x200B;

[Pattern Recognition and Machine Learning from Christopher Bishop](https://preview.redd.it/zrpddrgnye3c1.png?width=975&format=png&auto=webp&s=b920316736ffcce931f6f1bef765841ab2522e94)

my doubt is 'has a Gaussian distribution with a mean equal to the value y(x, w)'. Isn't the mean\[μ\] and variance\[σ\] predeterminded by the existing values of x, from pre-existing dataset?  

In N (t|y(x, w), β−1), we haven't defined y(x,w) as mean but as a parameter of probability(t given y(x,w)), is it still a gaussian distribution? ",TadpoleTechnical9009,2,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/1879x8d/how_to_calculate_mean_for_gaussian_distribution/
117,1701332190.0,"TensorFlow Tensors(What are Tensors: Understanding the Basics, Creating, and Working with Tensors)","Tensors are a FUNDAMENTAL concept in machine learning.  

Master them with this FREE resource, covering: 

 • What is a Tensor? 

• How to create tensors

• Functions to create various Tensor objects 

• How to create tensors with custom values

• How to initialize tensors with specific values 

• Creating TensorFlow variables (mutable tensors) 

 • Creating tensors from NumPy Arrays 

• Creating random tensors

• Special types of tensors 

• Indexing and slicing tensors 

• Operations for shaping and manipulating tensors 

• Broadcasting tensors 

• Basic mathematical operations with tensors

[https://www.machinelearningnuggets.com/tensorflow-tensors-what-are-tensors-understanding-the-basics-creating-and-working-with-tensors/](https://www.machinelearningnuggets.com/tensorflow-tensors-what-are-tensors-understanding-the-basics-creating-and-working-with-tensors/)",mwitiderrick,0,0.5,1,https://www.reddit.com/r/learnmachinelearning/comments/187dl9y/tensorflow_tensorswhat_are_tensors_understanding/
118,1701330588.0,ML studio best settings?,"&#x200B;

[Text generation](https://preview.redd.it/5kqetxc0xf3c1.png?width=889&format=png&auto=webp&s=91b3504db5e9f979247b19b1ffa8381e4a3b65cf)

  
What are the best settings for running Llama 7b on LM studio? At the moment I got 12 tok a sec. ",albertsaro,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/187d6je/ml_studio_best_settings/
119,1701307747.0,ML sys design help for fine-tuning llm,"hey folks, I am pretty new into llm space. our team are experimenting doing some fine-tuning on say llama model. we currently have one VM that come with some GPU capacity.
I am preciously pure backend swe background so has little knowledge in llm or mlops.
my question is, how do I trainkkmg/storing and updating a model utilizing the GPU instead of calling some wrapper API like replicate (or in Google colab), how should I set it up?
I am imagining I can just download llama from hugging face, add my data and train and store in local disk? but how do I retrieve it during inference time? (let's say for now it is a toy project and we use same VM for training and serving)

thank you so much!",WelcomeHefty372,3,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/18761ng/ml_sys_design_help_for_finetuning_llm/
120,1701315297.0,Do you think visualize hidden layer and weight of FFNN can help to improve your understanding toward problem or model?,"When model is constructed by simple FFNN (with 256 nodes), do you think visualizing hidden layer weights and hidden layer itself,  can help the understanding?  


I am building deep learning model for classification which is constructed by FFNN only, One person told me that if you draw some graph of data and hidden layer, it'll give me some insight of my hidden layers performance.  


I know that visualizing CNN filter and intermediate result can give some insight to the practicioner. But what about FFNN?",poemfordumbs,2,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/1878qj9/do_you_think_visualize_hidden_layer_and_weight_of/
121,1701327218.0,"Why am I getting ""duplicate"", ""no duplicate"" response from T5 Model?","Hello, I'm asking the questions to the T5 Model
```
question: is there  something?  sentence: there is something
```
```
question: is there  something?  context: there is something
```

getting `duplicate` as answer and sometimes in other questions it also returns `not_duplicate`, I'm new here I don't know much about this",Downtown-Rice-7560,1,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/187cc1b/why_am_i_getting_duplicate_no_duplicate_response/
122,1701322152.0,Does anyone have an idea of a project where it uses machine learning / deep learning to solve daily life problems?,"I want to do one where it can actually help me with my daily life... Or at least help with problems encountered by people in my office or community... 

I'm running out of ideas. Thinking outside the box is my weakness lol.",Funny_Shoe1772,1,0.67,2,https://www.reddit.com/r/learnmachinelearning/comments/187aved/does_anyone_have_an_idea_of_a_project_where_it/
123,1701294712.0,Introduction to Deep Learning,"Hi everyone,

if you want to start with Deep Learning, maybe my post ""**Introduction to Deep Learning**"" is helpful.

[https://datamapu.com/posts/2023/20231102\_intro\_dl/](https://datamapu.com/posts/2023/20231102_intro_dl/)

&#x200B;

https://preview.redd.it/6olx84okyc3c1.png?width=1920&format=png&auto=webp&s=033122f2d90ffbeaec7b3471175bbf43e2383bf5",datamapu,2,0.67,0,https://www.reddit.com/r/learnmachinelearning/comments/187158q/introduction_to_deep_learning/
124,1701284010.0,Fine-tuning BERT tiny model for text classification with Intel Neural Compressor,,ramyaravi19,4,0.84,0,https://www.intel.com/content/www/us/en/developer/articles/code-sample/fine-tuning-text-intel-neural-compressor.html
125,1701315126.0,Reading math centric papers?,"Hey everyone. There’s a math heavy paper that I want to include in a research project. It proposes it’s own metric (Ct scores. Meehan et. Al.)  but I’ve been struggling with reading the math and going through the paper and GitHub to find out how they actually implement it in code. I already tried to contact the first author but got no response.

Their GitHub is not the easiest to navigate either as it has a whole bunch of individual .py files that sim struggling to navigate.

I’m trying to just isolate the final function call they use to get their graphs and whatever dependencies I’d need to run it.

What would be your best advice to go about this? The best advice I’ve gotten from project mentors has been to not try to understand every mathematical step before just getting an implementation and building intuition as I go",Transit-Strike,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/1878oik/reading_math_centric_papers/
126,1701246650.0,Keras 3.0 is put and its a major update," The biggest update in the AI community, Keras 3.0 is finally out. A great step towards streamlining AI development be it PyTorch, TensorFlow, or JAX.

A big thanks to François Chollet for making our lives easier.

**- Multi-Backend Support:** Seamlessly switch between TensorFlow, JAX, and PyTorch. Includes low-level training loops for flexibility.

**- XLA Performance Enhancement:** Defaults to XLA compilation for faster GPU and TPU execution. Optimizes backend selection for model efficiency.

Expanded Ecosystem: Use Keras models with PyTorch, TensorFlow, or JAX's TPU training.

**- Cross-Framework Low-Level Language:** Introducing keras\_core.ops, a unified namespace for custom operations across frameworks, extending the NumPy API with neural network functions.

**- Progressive Complexity Disclosure:** User-friendly for novices, introduces advanced features for experienced developers.

**- Stateless Core API:** Aligning with JAX's statelessness, enhances compatibility and efficiency.

[https://medium.com/aiguys/unifying-dl-frameworks-with-keras-3-0-296c6df29ee8](https://medium.com/aiguys/unifying-dl-frameworks-with-keras-3-0-296c6df29ee8)

&#x200B;

https://preview.redd.it/e85ycjapz83c1.png?width=828&format=png&auto=webp&s=2dad43e9f54e8c640394ffe21b92b0cf88302310",Difficult-Race-1188,29,0.94,1,https://www.reddit.com/r/learnmachinelearning/comments/186kqtw/keras_30_is_put_and_its_a_major_update/
127,1701273243.0,Getting started with GenAI,"Job hunting has become easier for the folks who know genAI, compared to other SDE roles (as stated and observed on many platforms. May be I am not correct).  But on my personal capacity I have observed that, whenever I look for job description for ML engineer role I have found GenAI word in the description, meaning that it has become first and foremost requirement for most of the early stage startups. Hence, somewhere I feel like FOMO. 
I want some advice and learning path to start with it. What one should learn if he/she wants to align with the current industry standards especially in terms of GenAI, to get the decent job in this market. What types of projects can be created for either portfolio or resume and anything extra you can add.",JordaarAce,6,0.8,4,https://www.reddit.com/r/learnmachinelearning/comments/186sn5w/getting_started_with_genai/
128,1701241316.0,Keeping up with AI research,Progress has been fast and it's becoming difficult for me to keep up with everything happening in this sphere. How do people keep up? Is there a service or newsletter I can subscribe to?,UndocumentedMartian,24,0.96,11,https://www.reddit.com/r/learnmachinelearning/comments/186jheb/keeping_up_with_ai_research/
129,1701301806.0,"Junior Data Scientist, Senior Python Dev or PhD?","Hello!

I currently have the option of three career paths.

One is as an advanced junior data scientist in healthcare because although I have done uni courses part-time and have had some exposure in my previous work, I do not have that much practice (plus total lack of domain knowledge). The job will involve both building models and data analytics. I have some experience in the first one (very simple one), no professional one in the second one. I do not expect that the models building part will involve much need of innovative new architectures, I believe it to be more of applying what's already out there and fine-tuning it for the business needs. For this one I will be paid slightly higher salary than what a junior will get due to my extensive python coding experience but definitely lower than what I could get for the other role. I was told most likely it will take me one year to understand the domain. I have always wanted to try such role to see if I would enjoy it, to learn and see if I can do it well.

The other is as a Senior Python developer with exposure to ML (in this case this ML involves research since it is a different company). This means I would continue doing what I have been doing essentially focusing on software engineering and platform development and potentially helping out the ML research with processing tasks. Any more involved participation will depend on extra time I would like to put in. This same company also has the option of being fully focused on ML but again it is less compensation since it is going to be more junior level.

Finally, the third option is to go for a PhD which pays slightly less than the junior levels (since it is a very well paid PhD). In this case I could either go for NLP PhD (but I have been told the field is so saturated now that publishing anything is really challenging) or for PhD in Program Verification (which is extremely well structured and more laidback in terms of publications).

All opportunities pay well enough for stress-free life, it's just that the senior role pays well enough to try to get a mortgage for a flat (the others are about 30% less); I am certainly tempted to think short-term and prioritise learning over money, however, I am very confused which thing would be best for me in the long-term.

I already know that I have a talent for software engineering, but I have not confirmed if I can be that good in Data Science; I am not sure if PhD is worth it unless it is in AI but as I said, this field is so saturated right now that I am not sure if the stress is really worth it; plus, I would still need to find a job after the PhD anyway so in a way I think whether I do a PhD or get good experience in the field, options will be similar in the future. Ultimately, I just want to make sure that I can be in a leadership position in the next 5 years and to have gained enough knowledge that one can only attain by experience.",prudlioo,1,0.67,15,https://www.reddit.com/r/learnmachinelearning/comments/1873wen/junior_data_scientist_senior_python_dev_or_phd/
130,1701300881.0,Why is decreasing batch size increasing the amount of memory needed?,"I'm training a neural network on four 16 GB GPUs. Originally I was using batches of a few thousand data points to train the network on a series of hyperparameters. Some of the runs completed, but several crashed stating that they ran out of memory.

Hoping to eliminate the crashes, I reduced the batch size by about 4x and trained again. This time, every single run crashed because it ran out of memory.

Confused, I decided to reduce the batches even further to only 64 data points per batch. I ran that, and they all still crashed from running out of memory.

Does anyone have any idea what could be happening?

&#x200B;

&#x200B;

&#x200B;

&#x200B;

&#x200B;

In case it helps, here's the error message:

    2023-11-27 18:51:09.717343: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
    To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
    2023-11-27 18:54:01.355277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
    2023-11-27 19:00:51.960361: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:226] Using CUDA malloc Async allocator for GPU: 0
    2023-11-27 19:00:52.228060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15324 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0
    2023-11-27 19:00:52.282522: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:226] Using CUDA malloc Async allocator for GPU: 1
    2023-11-27 19:00:52.282683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 15324 MB memory:  -> device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0
    2023-11-27 19:00:52.283269: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:226] Using CUDA malloc Async allocator for GPU: 2
    2023-11-27 19:00:52.283440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 15324 MB memory:  -> device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0
    2023-11-27 19:00:52.284022: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:226] Using CUDA malloc Async allocator for GPU: 3
    2023-11-27 19:00:52.284189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 15324 MB memory:  -> device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:07:00.0, compute capability: 6.0
    2023-11-27 21:24:10.972455: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:306] gpu_async_0 cuMemAllocAsync failed to allocate 8409510812 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)
     Reported by CUDA: Free memory/Total memory: 553779200/17066885120
    2023-11-27 21:24:11.066413: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:311] Stats: Limit:                     16068509696
    InUse:                     10511914280
    MaxInUse:                  10511924132
    NumAllocs:                    24416031
    MaxAllocSize:              10511888552
    Reserved:                            0
    PeakReserved:                        0
    LargestFreeBlock:                    0
    
    2023-11-27 21:24:11.066645: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:63] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;
    2023-11-27 21:24:11.068387: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4, 13
    2023-11-27 21:24:11.068498: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 8, 6
    2023-11-27 21:24:11.068625: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 64, 1
    2023-11-27 21:24:11.068751: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 120, 8
    2023-11-27 21:24:11.068800: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 148, 2
    2023-11-27 21:24:11.068906: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 1028, 1
    2023-11-27 21:24:11.068948: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 3600, 4
    2023-11-27 21:24:11.068990: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 4440, 2
    2023-11-27 21:24:11.069031: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:66] 10511888552, 1
    2023-11-27 21:24:11.069120: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:97] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 16039018496
    2023-11-27 21:24:11.069177: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:99] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 10511914280
    2023-11-27 21:24:11.069264: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:100] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 16575889408
    2023-11-27 21:24:11.069342: E tensorflow/compiler/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:101] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 10511924132

&#x200B;",1strategist1,1,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/1873k8k/why_is_decreasing_batch_size_increasing_the/
131,1701297582.0,Replace LSTM with transformer in neural network,"I've small experience with Tensorflow, but I'm trying to work on an existing project which implements a model for accident anticipation in car dashcams videos (https://www.github.com/smallcorgi/Anticipating-Accidents). My goal is to replace the LSTM used in the original project with a transformer and to compare the results. Is this feasible using Tensorflow 2? I've done some research but I'm not sure how much this change would impact the code structure and the model logic. If anyone has some suggestion, any help is highly appreciated. By now I've just made some small adaptation to make the code work with Tensorflow 2 and Python 3 as the original code was quite outdated (you can find my forked repo at https://www.github.com/luibo/Anticipating-Accidents-with-Transformers). Thank you!",luiboo,0,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/18729od/replace_lstm_with_transformer_in_neural_network/
132,1701267776.0,Is switching ecosystems from tidymodels to scikit-learn worthwhile?,"As the title suggests. I currently make ML models in tidymodels, and I am not sure what to think of the options for neural networks tidymodel offers. 

In general I get the feeling that scikit-learn is way ahead of tidymodels in terms of the different kinds of neural network models it offers. Is it worth switching over to python for? I only ever used R. 

What doesn't help is that I am the only one on my team with even the slightest inkling of Machine Learning, or even basic statistics, so there isn't really any experienced co-worker to learn from. ",Chemical_Minute6740,4,0.83,12,https://www.reddit.com/r/learnmachinelearning/comments/186qjf9/is_switching_ecosystems_from_tidymodels_to/
133,1701259820.0,Beating Graph Neural Networks SOTA performance with automatic feature engineering,"Hi,  
I wrote a [Medium article](https://medium.com/@janmeyer1986/unlocking-peak-performance-graph-neural-networks-soar-with-automatic-feature-engineering-637a30e3648a) investigating the power of automatic feature engineering. Using the well known CORA data set, I show that with little effort, I outperform state of the art Graph Neural Networks by several percentage points. This holds true even across several different Neural layer implementations:

&#x200B;

https://preview.redd.it/h812tja02a3c1.png?width=577&format=png&auto=webp&s=b758cadd12263818ab2d1f290f3b7047cd01c7cd

That's the framework I used: [https://github.com/getml/getml-community](https://github.com/getml/getml-community)",JanKMeyer,4,0.76,0,https://www.reddit.com/r/learnmachinelearning/comments/186nykq/beating_graph_neural_networks_sota_performance/
134,1701263705.0,Hugging face model deployment,"A relatively noobish question when it comes to machine learning, so i got a project in my company, i have to make a LLM that would act as an expert in a certain field, i made the dataset and trained the model in an online yupiter handbook and it seems to be giving responses that i anticipated so thats nice. The question i have is how would i download this and use it locally, the model i mean, hardware is not the issue here just to state that right away, from the model i trained i got 2 files that i saved to my hugging face repo:  [BadDotNetDev/AI-Terapeut · Hugging Face](https://huggingface.co/BadDotNetDev/AI-Terapeut)   


i got only adapter\_config.json and adapter\_model.bin  


the base model i used is falcon 7b.

&#x200B;

if there is any more info needed here please ask, i am eager to learn how to do this because i cant find it anywhere, not even in the hugging face docs, maybe i was looking in the wrong place.",AvailableGuess836,4,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/186p4ob/hugging_face_model_deployment/
135,1701259972.0,"How can I get the word ""deployment"" onto my resume? What do I need to do?","I have never deployed a model to production. My career has been mostly training, testing and basically research, with stakeholders saying the accuracy is not satisfactory, or the project just evaporates and a new priority appears. 

I don't feel too bad about this as I know most models don't make it to production.

But a lot of job specs I'm interested in list deployment experience as a requirement.

What kind of personal project would satisfy a recruiter that I have deployment experience?

Can you give me an idea of what I need to do?

I was thinking of maybe one or two models on a Steamlit website that I could share with recruiters. Perhaps an image classification model, and a general classification model that predicts churn or whatever. Perhaps adding AWS into the mix.

Would that satisfy a recruiter?",scrotalist,2,0.63,7,https://www.reddit.com/r/learnmachinelearning/comments/186o04q/how_can_i_get_the_word_deployment_onto_my_resume/
136,1701280647.0,Convert signal into image,"Hi, can you guys recommend some approach to convert signal data (12-leads ECG signal) to image? 

I want to train a CNN model with the images to detect a certain CVD. 

Any feedback would be great for beginner like me.",Mediocre_Bag7587,0,0.5,3,https://www.reddit.com/r/learnmachinelearning/comments/186vn3m/convert_signal_into_image/
137,1701278442.0,Need Help With Speech Recognition,"I'm making a university project about a Voice Assistant. I want to train and use my own speech recognition model, i know it'll be less accurate and more hassle than just using googlea speech recognition functionalities but I'd prefer that I do it myself. However on looking online, I only found one good dataset - Mozillas - which is about 79 GB.

Can anyone help me as to how I'd go about making a smaller scale speech recognition model and what dataset i could use?",pleasehelpmeguys12,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/186ur1m/need_help_with_speech_recognition/
138,1701277591.0,nixtla timegpt,"I saw this GPT like thing from Nixtla ([https://docs.nixtla.io/](https://docs.nixtla.io/)) for time series analysis. I was wondering how adapts GPT architecture for time series data? I guess time series is no different from sequential text data but I am lacking a good way to think about how to leverage existing models for this.

This is a kind of Christmas project that I am thinking of working on but already stuck on how to conceptualize something like this?

Can someone reference papers/tech literature which can help me get started?",deluded_soul,0,0.4,5,https://www.reddit.com/r/learnmachinelearning/comments/186ueod/nixtla_timegpt/
139,1701276274.0,unclean datasets searching,"I am deeply sorry if this matter was discussed previously in the sub ,if it was discussed and solved pls give me the link , i am just so desperate rn ,so basically i am working on my data science final project and right now i am searching for datasets that must follow the following criteria:

>1- Size (Number of columns and rows). columns must be more or equal to 9 or 10,rows must be more than 900  
2- Quality (Don’t choose a cleaned data because that’s your mission).  
3- Simulates a real-time problem.  
4- Your proposal must show the description of your dataset and  
prove that it’s not a clean one

and unfortunately kaggle doesn't feature some sort of filter for unclean datasets or mildly unclean datasets, and i have searched for unclean data in many key words and investigated them and they weren't even clean

so the question is : is there is a website , a method , and app, a filter ,etc

to find unclean datasets, or include guaranteed unclean datasets, or mostly include unclean datasets",baiyesla-a3,1,0.99,0,https://www.reddit.com/r/learnmachinelearning/comments/186tv45/unclean_datasets_searching/
140,1701261870.0,How to implement code research paper?,"Hey guys, is there any guide or resources to implement research papers with code?

I want to implement this paper (https://github.com/microsoft/ProphetNet/tree/master/GENIE) but since I'm a beginner I'm confused even tho there is a small guide.",AhmedHailane,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/186ojyp/how_to_implement_code_research_paper/
141,1701261864.0,"Introduction to Machine Learning (L10, Support Vector Machines)"," Hello everyone!

This year I'm trying to record my ""Introduction to ML"" course in English. Maybe, it will be of any use for anyone.

[Lecture 10, Support Vector Machines](https://www.youtube.com/watch?v=MbSDxuWJzjg)

[DEMO: Support Vector Machine (my simplified version)](https://fbeilstein.github.io/simplest_smo_ever/)

In previous lectures

Part 1 (Tools for ML): [Lecture 1, Introduction](https://www.youtube.com/watch?v=MxZULf38HRU), [Lecture 2, Python](https://www.youtube.com/watch?v=_IBdjLg-W6I), [Lecture 3, NumPy](https://www.youtube.com/watch?v=jJGiC_ccPg8), [Lecture 4, Pandas](https://www.youtube.com/watch?v=dKWPi5PfuEQ), [Lecture 5, MatPlotLib](https://www.youtube.com/watch?v=LkY3qyhq6Q8)

Part 2 (Survival Math): [Lecture 6, Mathematical Optimization](https://www.youtube.com/watch?v=HNrAjs6QqiY), [Lecture 7, Probability and Naïve Bayes](https://www.youtube.com/watch?v=46ev3LdbDZ4), [Lecture 8, Statistics](https://www.youtube.com/watch?v=ZVz-M-QwJsc)

Part 3 (Supervised Learning): [Lecture 9, Linear Regression & Regularization](https://www.youtube.com/watch?v=MIfdv6VFLbo)

All course materials: [GitHub](https://github.com/fbeilstein/machine_learning)

 P.S. I would greatly appreciate any comments that will help me to ""upgrade"" my English",fbeilstein,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/186ojw9/introduction_to_machine_learning_l10_support/
142,1701220607.0,The last 10 years of NLP research in one video,,AvvYaa,16,0.87,0,https://youtu.be/uocYQH0cWTs
143,1701242798.0,Can I use logistic regression for image classification?,"Hi, I’m very new to ML and I’ve just learn logistic regression. The most common example I find for using the algorithm is cancerous tumour detection but I want to work with images and videos so I thought maybe I can try to use this for a very simple image classification (if an image is of a cat or a dog). Is it possible?",Icy-Acanthisitta3299,4,0.75,11,https://www.reddit.com/r/learnmachinelearning/comments/186jual/can_i_use_logistic_regression_for_image/
144,1701271805.0,Can we apply integrated gradients on text generation models?,"This is a doubt that I need to confirm.  I am working on a project that explores different explainable AI methods for explaining bug-fixing models (models that can generate a patch to a given buggy code). I read about the Integrated Gradients method from [here](https://www.tensorflow.org/tutorials/interpretability/integrated_gradients). 

The problem is: Can we apply the Integrated Gradients method to text generation models?

As I understood, for an image classification example, it uses a baseline and generates a set of intermediate data points for a pixel, then calculates the gradient and takes the average.

Is this possible for text generation models? Because when generating text we are not generating the whole text at once, I feel like generating intermediate data points and the rest of the process doesn't make sense. If I want to get a feature importance value for each token in the input, is IG a possible approach?",thehungrywolf99,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/186s32f/can_we_apply_integrated_gradients_on_text/
145,1701247739.0,MLP in MATLAB,"hey guys

I want to create an MLP neural network in Matlab for predicting long-term precipitation using 5 inputs such as relative humidity.

Any advice for me? (Matlab 2022b) 

&#x200B;",Sahand_99,3,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/186kzef/mlp_in_matlab/
146,1701267531.0,PowerPoint-Präsentation - Finxter_Prompting_OpenAI-2.pdf,,CheapBison1861,1,1.0,0,https://blog.finxter.com/wp-content/uploads/2023/03/Finxter_Prompting_OpenAI-2.pdf?utm_source=www.neatprompts.com
147,1701266419.0,Recommendations for Interactive Online AI Training in Image Generation,"Hi!

I'm on the lookout for an online training program focused on AI in the domain of image generation for videos, images, and animations. Key requirements are:

1. **Interactive Format**: A course that includes live classes with a teacher, not just pre-recorded video lectures. I'm looking for an interactive learning experience where I can engage directly with instructors.
2. **Language**: The class must be conducted in English.
3. **Content Focus**: I'm interested in AI techniques for generating images, videos, and animations and specifically interested in training that showcases and teaches using different platforms such as MidJourney, DALL-E, Adobe Firefly, Runway, Leonardo.ai, HeyGen, ClipDrop, RunDiffusion, etc

I would greatly appreciate any suggestions for such courses or training programs. Personal experiences, links to courses, websites, or pointers to institutions offering this kind of training would be extremely helpful.

Thank you in advance for your help!",Ambitious_Mention455,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/186q1at/recommendations_for_interactive_online_ai/
148,1701234683.0,Please Help!,"Hello, I am in a philosophy class Titled: Logic, Probability, and Artificial Intelligence and it is the last one needed for graduation. I am looking for a tutor to help me with practice problems as the final is worth 50% of my grade. The problems involve Bayesian Networks, DAGs, probabilities, and derivations. If this sounds familiar to anyone, please let me know. I really need help, I have As in all my classes except this one.",Missvelveteenrabbit,4,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/186hmj8/please_help/
149,1701255751.0,Neural Networks in C,"I am working on a project that involves running a neural network on a STM32 device, and I am looking for some tips on how to program it in C. Does anyone have any good sources of information or examples for this?",anointedninja,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/186mvax/neural_networks_in_c/
150,1701172294.0,When do you say you actually know ML?,At what point of time can you consider you know Machine learning . I have been studying ml and I've made some projects as well. Sometimes I am not sure whether it was good enough or not. There is so much tao ML with no defined standard or benchmark above which you can say you know ML. So how to know for sure you know ML.,OutsideNetwork3634,46,0.88,39,https://www.reddit.com/r/learnmachinelearning/comments/185u9ht/when_do_you_say_you_actually_know_ml/
151,1701167262.0,"Failing at leetcode easy, but I've been working in data science & analytics for almost 5 years! What to do?","It's so bad I'm not even ashamed, it's actually hilarious. 

I've been working with python, sql, DAX for almost 5 years, and most recently pyspark and sparksql.

I decided to try out leetcode easy python questions and the problems are unlike anything I've come across in my profesional life. 

It feels like a wase of time to even try to become good.

But I would like to at least get more comfortable, just in case. I am looking at moving jobs and may come across some leetcode interviews.

Is anybody in a similar position to me? How are you at leetcode?

Any resources out there to get better at these leetcode questions?",scrotalist,51,0.91,36,https://www.reddit.com/r/learnmachinelearning/comments/185sze3/failing_at_leetcode_easy_but_ive_been_working_in/
152,1701242497.0,How to know if a Data science institute is being genuine?,"Hello, I am thinking of joining a training institute in Saket Delhi. According to them their 80% of their students get a job after the training. How do I know if they are exaggerating?

If you have any reference or know anything about the institute please do tell.

Thank you for the helping advance.",nonExiestent,0,0.5,1,https://www.reddit.com/r/learnmachinelearning/comments/186jriq/how_to_know_if_a_data_science_institute_is_being/
153,1701205764.0,"Web app for exploring the latent space of a simple neural network. The purpose is to understand the concept of latent spaces, which are used in many AIs.",,Wiskkey,3,1.0,1,/r/aiwars/comments/1864qzj/web_app_for_exploring_the_latent_space_of_a/
154,1701203475.0,Is self learning possible if many GPUs are required?,"The best way to learn anything is to build/do it yourself (learning through application, rather than through reading). No one learns to drive a car, or create a video game just by reading about it. 

I'd like to teach myself something about machine learning, but can ML models be created using a normal computer, or do you need a lot of compute/GPUs? If you need a lot of GPU's it seems it'd be hard to teach yourself ML, if you can't really create a ML model on a typical gaming computer. ",morecoffeemore,2,0.63,5,https://www.reddit.com/r/learnmachinelearning/comments/1865w79/is_self_learning_possible_if_many_gpus_are/
155,1701201960.0,Reasons for ML bias,"So I saw a conversation about bias in ML, especially facial recognition. A point was brought up that it’s not just a data problem, but also a problem with the actual algorithms being used. Is this point BS or is there any foundation to this view? Any examples? ",Radiant_Walrus3007,3,0.8,2,https://www.reddit.com/r/learnmachinelearning/comments/1865amn/reasons_for_ml_bias/
156,1701222713.0,Ultimate Review of Content at Scale 3.0 – MASSIVE Advantages," ""If you are at all familiar with the folks at Content at Scale, you know that they have created a premier AI writing assistant capable of writing entire articles from a few keywords, producing quality content in the process.  It is an amazing advancement in technology that many content creators have taken advantage of to produce a huge amount of quality content. 

Content at Scale as a brand has come to be known for its combination of unmatched quality, SEO optimization, and human-like writing tone, making it a popular option for brand-conscious publishers. The platform is designed to help users generate content rapidly without compromising on its quality. With an array of features and seamless integration with popular platforms like WordPress, Content at Scale aims to be the best option available for AI content creation.

[Content at Scale](https://contentatscale.ai/?fpr=rob86) has now released its Version 3.0 update, bringing exciting features to its platform. In this article, I will review the new features offered in version 3.0 as well as highlight some of the more compelling original features.""

The original article is here

[https://ai-solutions.pro/review-of-content-at-scale-update-for-version-3-0/](https://ai-solutions.pro/review-of-content-at-scale-update-for-version-3-0/)",Science-man777,1,0.6,0,https://www.reddit.com/r/learnmachinelearning/comments/186djw0/ultimate_review_of_content_at_scale_30_massive/
157,1701216320.0,RAG/IR literature,"Looking for literature on the latest state of the art for RAG/IR. Specifically:

-how should IR outputs be ordered before passing into answer generation model?

-how many IR outputs should be passed to answer generation model?

-any papers that refer to IR output score thresholds for RAG

I’m not new to ML but I’m fairly new to reviewing the latest literature and how to find it.
I appreciate any help, thank you!",bballerkt7,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/186b6fp/ragir_literature/
158,1701211705.0,I'm working on a project for school and I need volunteers. If anyone can help me out. I would be very happy,"The school project is as follows: I made a chatbot that you talk to, and when you talk to it, it analyzes your personality. Then there is a different chatbot that takes that analysis and tries to imitate your personality. I need some volunteers to test this out and see how accurate it is.",darkLordSantaClaus,1,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/1869c9m/im_working_on_a_project_for_school_and_i_need/
159,1701209585.0,Dataset labeling,"I have a csv file with the data I need, but I'm having trouble understanding how to label my dataset for X_Train, Y_Train, X_test and Y_test. 
(The dataset is for Phishing emails, I'm making a program that reads the dataset and detects what's Phishing and what isn't.)

I was told there are ML libraries that can help and or automatically classify the dataset but I am unable to find it.",Footballski1942,1,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/1868fvu/dataset_labeling/
160,1701195418.0,Are there any real differences between a network used for time series converting and for prediction?,"I have an application where I need to read in data and convert it in real time. The exact function to do so is unknown, so I am training a deep network in order to do this task. Online, I see lots of information about time-series prediction: is such ""conversion"" like I'm doing any different from prediction, other than the fact the for my case, the output dimensions will always be the same as the input dimensions (whereas for predicting/forecasting the output dimensions are more arbitrary and can be any point(s) in the future)? For instance, the network doesn't ""know"" it is converting the inputs to outputs just as it doesn't ""know"" it is being used for prediction/forecasting, correct? Fundamentally, there is nothing I would need to change about the network (eg building off someone's time series forecasting code), the only difference is the labels (and then making sure the dimensionality of the output is consistent)?",Amun-Aion,2,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/1862nh8/are_there_any_real_differences_between_a_network/
161,1701188267.0,Advice on player tracking using homography and object recognition for NBA broadcast feed ?," I've been thinking about this idea of a project I had, in order to consolidate my knowledge of computer vision techniques and deep learning.

The objective of the project is to feed NBA broadcast video to a model that provides player tracking along with their position on the basketball court (and then add more interesting features from there like player recognition, position data could be tied to shooting percentage, etc.).

I established that the correct way to go about this was to train a neural network to predict the homography of the court onto a 2D plane (by detecting a set of keypoints), run object detection on the resulting area, and then associate pairs of detections between frames for efficient tracking.

First off, is this approach sensible ? Some feedback, pointers or just general advice would be very welcome.  
Secondly, as their isn't any basketball dataset with annotated homography publicly available (to my knowledge), I need to create my own. Not being very familiar with annotating tools, I would like to know if anyone had an idea of what tool I should use to set keypoints on an image and their corresponding homography ?

Some related papers on the subject for references:  
\- [A Robust and Efficient Framework for Sports-Field Registration (2021)](https://openaccess.thecvf.com/content/WACV2021/papers/Nie_A_Robust_and_Efficient_Framework_for_Sports-Field_Registration_WACV_2021_paper.pdf)  
\- [Sports Field Registration via Keypoints-aware Label Condition (2022)](https://openaccess.thecvf.com/content/CVPR2022W/CVSports/papers/Chu_Sports_Field_Registration_via_Keypoints-Aware_Label_Condition_CVPRW_2022_paper.pdf)  
\- [Computer vision for detecting and tracking players in basketball videos, Sara Battelini (Politecnico de Torino) (2020)](https://webthesis.biblio.polito.it/15863/1/tesi.pdf)

Thank you for reading.",MFalkey,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/185ztdl/advice_on_player_tracking_using_homography_and/
162,1701183891.0,Stable Video Diffusion (SVD) Explained,,OnlyProggingForFun,2,0.75,1,https://youtu.be/TVcE1Ic05lw
163,1701179835.0,Free mathematics exercises resources?,"Are there any free mathematics (Algebra, Calculus, Statistics) exercises resources that I can use to practice my skills? Preferably with a grading system or show correct answers.",247_learner,2,0.75,2,https://www.reddit.com/r/learnmachinelearning/comments/185wmrj/free_mathematics_exercises_resources/
164,1701193263.0,Where can I find the input shape of all keras applications?,"They don't seem to have them in their docs, like for [eficientnet](https://keras.io/api/applications/efficientnet/#efficientnetb0-function) I had to get them from [Kaggle](https://www.kaggle.com/code/lys620/efficientnet-with-keras). Any idea what I should for the [other applications](https://keras.io/api/applications/)?",bububeti,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/1861si1/where_can_i_find_the_input_shape_of_all_keras/
165,1701188847.0,Sequence classification using BART - extract token?,"Hi all, 

I’m playing around with zero shot classification using facebook/bart-large-mnli . I was wondering if there’s a way to extract the token(s) from a sequence that are prompting a certain classification. For example, if I pass in something like “The woman is named Jane Doe” and this sequence scores high for a ‘name’ label, is there an easy/efficient way to return ‘Jane Doe’ or ‘named Jane Doe’ (or whatever token(s) the model recognizes as the name portion) from the result dictionary? 

I know for a task like this, I could probably just use regex in some form, but that seems to defeat the point of using the classification model all together

Thanks!!!",rjakie,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/18601ru/sequence_classification_using_bart_extract_token/
166,1701157159.0,Where to start?,"I have 2 years of experience in IT with a different domain completely, intrested in machine learning any suggestions wherecan i start as im good in maths and python as well",Rangaul,5,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/185qksg/where_to_start/
167,1701188523.0,Need guidance for FYP,"Hi, I am a final year student in CS and currently doing final year project. 

I foolishly take a very hard one (for me). It is an AI model project which then need to be implemented as a system. 

Eventhough I had done a lot of research, I seem to still cannot implement my goals properly. 

I need help where can I find guidances or even a tutor for me to learn from.

Project description:
- A CNN model to classify ECG signal into 2 different class. 
- Dataset using raw ECG signals (where I struggle the most) 

I hope that someone can help me here.",Mediocre_Bag7587,0,0.5,2,https://www.reddit.com/r/learnmachinelearning/comments/185zx5s/need_guidance_for_fyp/
168,1701174577.0,Rust in ML,"Why hasn't Rust gained the same recognition as Python in AI, ML, and DS, despite its significant ecosystem potential and notably better speed compared to Python? 

Also, why haven't people actively developed Rust libraries for data analysis and processing, similar to what has been done in Python?",IndependentFresh628,2,0.75,3,https://www.reddit.com/r/learnmachinelearning/comments/185ux5b/rust_in_ml/
169,1701187637.0,I wanna get started on machine learning,"I am in my second year of B.Tech computer science and I have been wanting to get started with machine learning for the last semester but never really got around to doing it. I don’t know where to begin, how deep to go into the math, what to refer to , how do I learn to make models. What would the list of topics be and where would LLMs be on it? How good should I be in openCV and other libraries, like should I know all the functions? And also do keep in mind that I am interested in research aspects of AI and thus depth is as important and diversity for me. Also if you have any links to courses or books or blogs please drop them down.",StatusPending5512,1,0.6,5,https://www.reddit.com/r/learnmachinelearning/comments/185zk95/i_wanna_get_started_on_machine_learning/
170,1701171122.0,How to load big model on low memory,"Hey, I found today a model on HuggingFace [https://huggingface.co/microsoft/Orca-2-7b](https://huggingface.co/microsoft/Orca-2-7b) , I want to run this on my local system but I have 8GB of RAM, is there any way I can run this?",Downtown-Rice-7560,2,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/185tyqm/how_to_load_big_model_on_low_memory/
171,1701170011.0,AZURE AI Language,"Hi everyone,
I'm new to Azure AI (since I have always used GCP). I read the documentation but I didn't find any information about the reachable performances  based on the number of processed documents.

Just to give a clue about what I'm saying, Google Document AI reports such type of information (see here: https://cloud.google.com/document-ai/docs/workbench/training-overview#number_of_documents)

Is there anyone experienced who can help me?
I'm focused on the Custom Text Classification and Data Extraction models",fedeloscaltro,2,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/185tobl/azure_ai_language/
172,1701180683.0,"Evaluate, monitor, and safeguard your LLM-based apps","For the last couple of months, I along with my team invested lots of effort into building a solution that can help users evaluate and monitor the performance of their LLM and AI apps.

If you're a ChatGPT (or any other LLM :)) user and are integrating it into your apps, and if, by any chance, it ever happened to you that the outputs you received weren't exactly the ones you were hoping for... You should find this useful 😃

Today, we are releasing it publically and launched it on ProductHunt. **I would be very thankful if you try it out and support the launch**. 🙏

[https://www.producthunt.com/posts/deepchecks-llm-evaluation?r=h](https://www.producthunt.com/posts/deepchecks-llm-evaluation?r=h)",AsDivyansh,1,0.67,0,https://www.reddit.com/r/learnmachinelearning/comments/185wy2l/evaluate_monitor_and_safeguard_your_llmbased_apps/
173,1701230656.0,I need help on how to learn machine learning(took a screenshot of my previous post that was removed as I was too lazy to type everything again),,Eric_Vlogz-77,0,0.11,6,https://i.redd.it/nf5p05i6o73c1.jpg
174,1701178686.0,Why we use partial derivative instead of full derivative in backpropagation,I wonder why we use partial derivative for backpropagation step while training a neural network,Cool_Measurement_166,0,0.5,14,https://www.reddit.com/r/learnmachinelearning/comments/185w8fz/why_we_use_partial_derivative_instead_of_full/
175,1701178174.0,Which model? Controlling Kafka/Kubernetes,"I am looking for pointers on where to start/which model(s?) to use.

I am a backend distributed system SWE experimenting with what it would take to automate away the oncall side of my job. I am new to ML and want to experiment with ML to see what it can (and cannot) do in an area near and dear to me.

I want to (eventually) create an ML model which takes in observability data about Kafka and Kubernetes and have it update/recommend configurations and operations.",tabgok,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/185w1zp/which_model_controlling_kafkakubernetes/
176,1701164012.0,"I've come up withan idea for a synthetic dataset generator, would this work?",,JakeN9,2,0.75,1,https://i.redd.it/wwpgtfyy523c1.png
177,1701134866.0,Running into vanishing gradient on transformer model,"Hi all! Sorry if I am missing something totally obvious here, but I have been having some issues with a *very simple* transformer model that is training on sentiment classification for tweets. I am doing this just as a minimum viable example of transformers so that I can better understand them. I am also using PyTorch's built in nn.Transformer.

From reading some literature, I've gathered that part of the reason why transformers are so great is because you can make them very deep without running into vanishing gradients. However, on my model, if I make the number of encoder / decoder layers greater than 1, I run into vanishing gradients (avg gradient magnitude is around 1e-10 to 1e-12 and loss will not decrease at all). When I run the model with just 1 layer, I tend to see just 1e-8 gradient magnitude on average which is extremely small but the model still seems to learn.

Which leads me to my second issue... The model does learn but after just one or two epochs, the training and validation losses seem to diverge, indicating the model is overfitting. This doesn't seem quite right that my model is overfitting so quickly.

Some special notes: I am using AMP optimizations. I tried removing this to see if this is messing with my gradients. It's not.

Full disclosure: this is for a school project, but the performance of my model is uncorrelated with my grade. I am asking this question not for a grade but rather because I want to learn how this stuff works and where I am going wrong.

Here is the code if anyone wants to look at the finer details (I would focus on train\_transformer.py, src/transformer.py and src/utils.py) [https://github.com/NoahSchiro/cs448\_final](https://github.com/NoahSchiro/cs448_final). The dataset in question is [https://www.kaggle.com/code/paoloripamonti/twitter-sentiment-analysis/input](https://www.kaggle.com/code/paoloripamonti/twitter-sentiment-analysis/input)

My speculation is that a transformer model is just way too overpowered for the task at hand and that's why I am seeing very quick convergence / vanishing gradients. Any help is greatly appreciated!  
",NoahSchiro,8,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/185jx2j/running_into_vanishing_gradient_on_transformer/
178,1701150022.0,12 Best Coursera Free Courses Machine Learning for Everyone in 2024,,Aqsa81,3,0.8,0,https://www.mltut.com/coursera-free-courses-machine-learning/
179,1701115835.0,Why doesn’t linear regression work on classification problems?,"Hello. Im a beginner in ML. I’m trying to really understand why linear regression doesn’t work on classification problems. 

I often the answers along the lines of: “it predicts continuous values” or “finds the best fit lines” or something similar. 

This is quite difficult for me to intuitively grasp and I’ve been stuck trying to figure this out for more than 3 weeks now. 

I’m working on a titanic dataset and trying to use linear regression but I do not even know how to make it work with linear regression. 

I understand that’s not what LR is meant for but I just I want to really see and understand why that’s so. 

If possible explain like a total newb. No complex or tacit language",Ok_Tumbleweed8796,17,0.84,28,https://www.reddit.com/r/learnmachinelearning/comments/185cbk8/why_doesnt_linear_regression_work_on/
180,1701169636.0,Need help finding a LLM," Hello there,

I'm a student and me and my team have the assignment to make a chatbot for our university. We need to make a chatbot that can help other students find information about their course. We will get our data from manuals of multiple university websites (as pdf). This data will be turned into Q&A data using ChatGPT 4.

However, we are struggling to find a pre-trained LLM that fits our assignment. We've researched T5, BERT and GPT-2 but our teacher was surprised those were the models we researched, since there are more popular and newer models. Our chatbot must be in Dutch, but we can translate so the LLM doesn't need to be trained on Dutch data. The LLM can't be too big, because we don't have the hardware for very large models.

We are currently looking at openchat and falcon, both with 7B parameters. Are these good options or does anyone have any tips for better LLMs?",Flo501,1,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/185tkzn/need_help_finding_a_llm/
181,1701164669.0,Book for ML,"Do we have any one book to learn ML from Scratch including the Maths behind it?

&#x200B;

&#x200B;

&#x200B;

\#MachineLearning",peeyushkmisra,1,0.67,1,https://www.reddit.com/r/learnmachinelearning/comments/185scmw/book_for_ml/
182,1701130463.0,Question regarding multi head LLM self attention,"Hi, I've just started learning about the transformer architecture, and have a question:

1. When  multi head self attention computes dot product of Q, K and you get an  attention scores, the diagonal where the same word aligns has no  detrimental effect as it’s uniformly distributed, but doesn’t this mess  with the soft max scale, why is each word compared to itself? (edited)
2. Wouldn't  we want to normalize the diagonal between same word computation,  otherwise the attention score amplifies word -> word, which make  dilute the attention score product?
3. GPT  says the the transformer relies on the difference in weights to  determine the attention pattern, but that it's worth exploring (i guess  especially seeing as the transformer picks up this pattern itself)?",JakeN9,5,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/185ibbr/question_regarding_multi_head_llm_self_attention/
183,1701133365.0,Implementing soft nearest neighbor loss in PyTorch,"Hello! It’s been a while since I wrote blogs. I have written two blogs, and they are as follows:
- Improving k-Means Clustering with Disentanglement: https://medium.com/@afagarap/improving-k-means-clustering-with-disentanglement-caf59a8c57bd
- Implementing Soft Nearest Neighbor Loss in PyTorch: https://medium.com/@afagarap/implementing-soft-nearest-neighbor-loss-in-pytorch-b9ed2a371760

The first article covers a paper I presented in IJCNN 2020 while the second article is a step-by-step tutorial on implementing the loss function we presented and expanded in the referenced paper.

I hope you enjoy reading them. Thanks!",afagarap,4,0.84,0,https://www.reddit.com/r/learnmachinelearning/comments/185jdzp/implementing_soft_nearest_neighbor_loss_in_pytorch/
184,1701107722.0,Navigating the AI Landscape on the Horizon,"I think by now most of us have heard the sentence: ""AI will not replace jobs, people that know how to use AI will replace people that don't"".

For many of us that are not programmers or software architects but rather white collars working in marketing, accounting, project management etc, what shall we start learning exactly? 

I can only think about getting to know some basic concepts (e.g., what is generative AI, what is an hallucination etc), the big players out there and their focuses (e.g., who is best at doing text to video, image generation, etc) and perhaps some tips on prompt optimization, but then that's it. 

I don't see the differentiating factor as all of this can be learned in an afternoon by anyone, and searching on the web ""Best practices in AI for \[my profession\]"" or directly prompting an AI platform don't sound too complicated either.

Is this all there is or am I missing something?",YepYepisalifestyle,12,0.94,3,https://www.reddit.com/r/learnmachinelearning/comments/185910n/navigating_the_ai_landscape_on_the_horizon/
185,1701094834.0,Are Kaggle Competitions Worth It? Ponderings of a Kaggle Grandmaster,,ledmmaster,21,1.0,5,https://forecastegy.com/posts/are-kaggle-competitions-worth-it-ponderings-of-a-kaggle-grandmaster/
186,1701154239.0,"Getting ""AttributeError: 'LightningDataModule' object has no attribute '_has_setup_TrainerFn.FITTING"" when using simplet5 and calling `model.train` method","```
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
Cell In[11], line 2
      1 # train
----> 2 model.train(train_df=train_df, # pandas dataframe with 2 columns: source_text & target_text
      3             eval_df=eval_df, # pandas dataframe with 2 columns: source_text & target_text
      4             source_max_token_len = 512, 
      5             target_max_token_len = 128,
      6             batch_size = 8,
      7             max_epochs = 3,
      8             use_gpu = False,
      9             )

File ~/projects/nlprocessing/env/lib/python3.11/site-packages/simplet5/simplet5.py:395, in SimpleT5.train(self, train_df, eval_df, source_max_token_len, target_max_token_len, batch_size, max_epochs, use_gpu, outputdir, early_stopping_patience_epochs, precision, logger, dataloader_num_workers, save_only_last_epoch)
    385 trainer = pl.Trainer(
    386     logger=loggers,
    387     callbacks=callbacks,
   (...)
    391     log_every_n_steps=1,
    392 )
    394 # fit trainer
--> 395 trainer.fit(self.T5Model, self.data_module)

File ~/projects/nlprocessing/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:740, in Trainer.fit(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)
    735     rank_zero_deprecation(
    736         ""`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.""
    737         "" Use `trainer.fit(train_dataloaders)` instead. HINT: added 's'""
    738     )
    739     train_dataloaders = train_dataloader
--> 740 self._call_and_handle_interrupt(
    741     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
    742 )

File ~/projects/nlprocessing/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:685, in Trainer._call_and_handle_interrupt(self, trainer_fn, *args, **kwargs)
    675 r""""""
    676 Error handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)
    677 as all errors should funnel through them
   (...)
    682     **kwargs: keyword arguments to be passed to `trainer_fn`
    683 """"""
    684 try:
--> 685     return trainer_fn(*args, **kwargs)
    686 # TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7
    687 except KeyboardInterrupt as exception:

File ~/projects/nlprocessing/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:777, in Trainer._fit_impl(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)
    775 # TODO: ckpt_path only in v1.7
    776 ckpt_path = ckpt_path or self.resume_from_checkpoint
--> 777 self._run(model, ckpt_path=ckpt_path)
    779 assert self.state.stopped
    780 self.training = False

File ~/projects/nlprocessing/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1138, in Trainer._run(self, model, ckpt_path)
   1136 self.call_hook(""on_before_accelerator_backend_setup"")
   1137 self.accelerator.setup_environment()
-> 1138 self._call_setup_hook()  # allow user to setup lightning_module in accelerator environment
   1140 # check if we should delay restoring checkpoint till later
   1141 if not self.training_type_plugin.restore_checkpoint_after_pre_dispatch:

File ~/projects/nlprocessing/env/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1438, in Trainer._call_setup_hook(self)
   1435 self.training_type_plugin.barrier(""pre_setup"")
   1437 if self.datamodule is not None:
-> 1438     self.datamodule.setup(stage=fn)
   1439 self.call_hook(""setup"", stage=fn)
   1441 self.training_type_plugin.barrier(""post_setup"")

File ~/projects/nlprocessing/env/lib/python3.11/site-packages/pytorch_lightning/core/datamodule.py:461, in LightningDataModule._track_data_hook_calls.<locals>.wrapped_fn(*args, **kwargs)
    459     else:
    460         attr = f""_has_{name}_{stage}""
--> 461         has_run = getattr(obj, attr)
    462         setattr(obj, attr, True)
    464 elif name == ""prepare_data"":

AttributeError: 'LightningDataModule' object has no attribute '_has_setup_TrainerFn.FITTING
```",Downtown-Rice-7560,0,0.33,0,https://www.reddit.com/r/learnmachinelearning/comments/185pv50/getting_attributeerror_lightningdatamodule_object/
187,1701153773.0,Dataset for Evaluating Computer Science Learning Resources," Hey Community,

I'm working on a project to evaluate the quality of computer science learning resources, but I'm struggling to find labeled datasets (already searched on Kaggle and UCI ML repo). Any tips on where I can find one or how to create it efficiently? Open to suggestions. Your insights are much appreciated!",sudo_ManasT,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/185pqym/dataset_for_evaluating_computer_science_learning/
188,1701152463.0,Am I making a GPU mistake?,"To anyone who sees this, any input is appreciated.

&#x200B;

I'm attempting to make a rig for generative AI projects with an emphasis on visuals (not sure what LLM I'm gonna use yet), and the Radeon M100 card seems perfect for my build.  They're cheap when used, so I could buy two of them for the price of a hypothetically better single graphics card, and their VRAM of 32GB seems a solid selling point.  However, would it be a mistake to buy this sort of GPU for some reason I can't see?  

&#x200B;

For context, if it helps, I'm aiming to utilize a new Ryzen 7000 series CPU with a motherboard to match.   
PCIe 5.0 is overkill for the MI100, but I've read that two PCIe 5.0 x8 slots will mimic the performance of two PCIe4.0 x16 slots (which tops the specs of these GPUs).",Gamer-C,1,0.67,1,https://www.reddit.com/r/learnmachinelearning/comments/185peoj/am_i_making_a_gpu_mistake/
189,1701123083.0,Which Udemy Data Science/ML Course should I take provided my background on the subject?,,daymanAHAHahhhhhh,4,1.0,2,/r/learndatascience/comments/185fb3k/which_udemy_data_science_course_should_i_take/
190,1701160711.0,Which one first NLP or CV,"I have completed machine learning that will be required for both nlp and cv. I have also learn some text preprocessing techniques and also I have learned ANN and CNN. I have loved both NLP and CV and I want to do both. There are alot of problems where I need both. But I have to start from one. So, guys can you tell me which one to start first? I will learn both but I have to start from one.

And also I don't know any SQL.

So, Anyone can tell be which one is best for beginners. Remember my goal is to learn both.",CodingWithSatyam,0,0.25,3,https://www.reddit.com/r/learnmachinelearning/comments/185rfbj/which_one_first_nlp_or_cv/
191,1701122384.0,What would be the best approach to this computer vision project,"What would be the best way to approach building a computer model that will analyse a video for very small details. Details like noticing a small tumour or lesion in a video. 

Would it be possible to make this real time or post analysis? What algorithm would be best to indentify tumours efficiently in each frame? 
I would appreciate any help thank you",the__mess1ah,3,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/185f2fo/what_would_be_the_best_approach_to_this_computer/
192,1701128950.0,Pattern recognition / object detection in 2D images / websites / UI,"I'd like to write a program where the input is something like a screenshot of a website, and the output is the coordinates of recognized objects. For example buttons.

The use case is automated UI testing.

&#x200B;

https://preview.redd.it/orvle9839z2c1.png?width=148&format=png&auto=webp&s=786dc88e419dda20110285d01337a255a4be9ae9

Or think of something like Minesweeper, where the patterns are very simple and unchanging. 

&#x200B;

https://preview.redd.it/yzj2cwnq7z2c1.png?width=2048&format=png&auto=webp&s=e1e133a33f0c1e15b9f5eb205638d253fc6fcdec

Or window buttons:

&#x200B;

https://preview.redd.it/v9ypg29g9z2c1.png?width=300&format=png&auto=webp&s=5a6fd21a4ded8c1f4bc031605922193f37b4ed08

I'm thinking to use YOLOv8, but I'm also thinking that it's probably overkill, and that older methods will require less resources and run inference faster.

What are my options? And how do those options compare to YOLOv8? I assume that YOLOv8 is more general purpose, more powerful, more robust, but more resource expensive?

&#x200B;",GeniusPengiun,1,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/185hq9x/pattern_recognition_object_detection_in_2d_images/
193,1701114763.0,Blogpost about Linear Regression,"Hey everyone,

so happy to share that I decided to start a blog about Data Science and Machine Learning. Start with some basics: **Linear Regression**.

Linear Regression is a simple and interpretable ML model, that is often used in industry and academia. It has however its limitations. Linear Regression is an important basic knowledge for everyone working in Data Science and Machine Learning.

[https://datamapu.com/posts/2023/20231113\_linear\_regression/](https://datamapu.com/posts/2023/20231113_linear_regression/)  


https://preview.redd.it/42l0h6np3y2c1.png?width=1920&format=png&auto=webp&s=c3ee916c255b4d22886dca5efbcf7070efca2971",datamapu,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/185bwdy/blogpost_about_linear_regression/
194,1701104143.0,Building my own machine learning algorithm versus using AWS Rekognition or Azure Cognitive Services,"The client I work for is a national delivery company and their drivers take images of parcels being delivered for compliance reasons. That's thousands of photos being taken every day. Some members of the customer service team then review these images and mark them as compliant or non-compliant.

I've spotted the opportunity to automate this using machine learning - potentially saving the company a lot of time and money and opening the gates to other areas of the business being automated. And so, I've built a CNN that's been trained on \~100 images only and it looks extremely promising already.

Before I train it on a lot more images and think about the infrastructure side of things, can anyone foresee any reasons as to why using third party services may be more favourable? I'd like to present something bulletproof back to the business so that they have no room to decline going ahead with it.",rafiulansari97,2,0.67,14,https://www.reddit.com/r/learnmachinelearning/comments/1857keq/building_my_own_machine_learning_algorithm_versus/
195,1701093361.0,[D] Creating an Automated UI Controller with GPT-4 Vision & Agents,"Hey,

Last weekend, I managed to merge GPT-4 Vision with another GPT-4 and a device controller to work as a AutoGPT equivalent using AutoGen. Good thing is, it is not limited to Browser. It can work on any UI window. Let me know what you guys think and what can be done better.

Demo and approach available at: [https://medium.com/@gitlostmurali/creating-an-automated-ui-controller-with-gpt-agents-35340759d08b?sk=98d85484bd7e5e554f48a801728bfb68](https://medium.com/@gitlostmurali/creating-an-automated-ui-controller-with-gpt-agents-35340759d08b?sk=98d85484bd7e5e554f48a801728bfb68)

I'll update the repository soon -> [https://github.com/gitlost-murali/grounded-gpt-agents](https://github.com/gitlost-murali/grounded-gpt-agents)",Outlandish_MurMan,5,0.73,0,https://www.reddit.com/r/learnmachinelearning/comments/1853i61/d_creating_an_automated_ui_controller_with_gpt4/
196,1701047138.0,🎉 Exciting News for Machine Learning Enthusiasts! 🚀,"We are **excited** to update the community about the 100 Days of Code ML Challenge.

**Who are we?**

-We are two graduate students specializing in machine learning and artificial intelligence, who are eager to delve deep into various ML topics and projects.

**What is the 100 Days of Code Challenge?**

-It’s a commitment to code for at least 1 hour for 100 days. But this isn’t just about coding – it’s about learning, experimenting, and applying machine learning in innovative ways.

**What Can You Expect?**

-Diverse Topics: From fundamental algorithms to cutting-edge techniques.

-Project-Based Learning: Hands-on projects to apply ML in real-world scenarios.

-Collaboration and Networking: An opportunity to connect with like-minded individuals.

**We WANT Your Input!**
This journey is not just ours – it's yours. 
We want to know:

-Topics of Interest: 

What specific ML topics are you most interested in?

-Applied Uses:

Are there specific industries or problems you think ML can significantly impact?

**How to Participate: Simply join the discussion, however you want.**

- Twitter: @100daysml
- Reddit: r/100daysml
- Discord: https://discord.com/invite/BVhwgeqy
- https://www.100daysofml.com

**Right now the tentative release date is January 1st, 2024.**
 
Let's code and learn together!

We are looking for a select few individuals to assist us. If you are interested please reach out to ml_w0lf.

- u/ml_w0lf
- u/vicethal",ml_w0lf,48,0.88,10,https://www.reddit.com/r/learnmachinelearning/comments/184qgua/exciting_news_for_machine_learning_enthusiasts/
197,1701093671.0,Are SOTA LLMs(LMMs?) going to be much smaller in the future?,"Since most LLMs these days are becoming multi-modal, with capabilities to browse the web and parse information from given files, will they become much smaller as they'll need to be trained on less data?

Models like GPT-3, which has 175B parameters, are that big because they are trained on a ton of information from the internet which they can retrieve from their data for the user. Thats why GPT-4 is so useful, because it is trained on so many things, it can help on a wide range of topics.

But, now that GPT-4 has plugins, and also the ability to browse the web, will it need to be trained on so much data. If the user needs help on a particular topic, it can just search the web for the information and then present it to the user. I t would save a lot of training time and data.

For the purposes of it just being able to speak English correctly, it needs relatively little data. The TinyStories models, with 10-30M parameters, perform pretty decently as a LM. It only neededsimple english vocabulary to learn to speak it properly. So, in the future, will we see base SOTA models be 7-13B with multimodal vision, voice, file parsing, and most importantly, web browsing capabilities, which will perform as good as today's GPT-4?",open_23,4,0.83,8,https://www.reddit.com/r/learnmachinelearning/comments/1853m18/are_sota_llmslmms_going_to_be_much_smaller_in_the/
198,1701120503.0,can i fine-tune gpt 3.5 turbo model for a domain specific task on my laptop? (32GPU),,Life_Ask2806,0,0.5,1,https://www.reddit.com/r/learnmachinelearning/comments/185e9pg/can_i_finetune_gpt_35_turbo_model_for_a_domain/
199,1701090710.0,Understanding Neural Networks:,"Maybe this article helps to understand how to design a neural network for different tasks such as classification or regression (what kind of loss function, what kind of activation function for the last layer etc). 

[https://medium.com/advanced-deep-learning/complete-guide-to-neural-networks-7eccbc3bbd80](https://medium.com/advanced-deep-learning/complete-guide-to-neural-networks-7eccbc3bbd80)

&#x200B;

https://preview.redd.it/h0hos9c14w2c1.png?width=2280&format=png&auto=webp&s=10fa9630b04e821b752c9d060d3bff5167a0ff9b",Junior_Syllabub_3037,5,0.78,0,https://www.reddit.com/r/learnmachinelearning/comments/1852mx6/understanding_neural_networks/
200,1701117580.0,Linear Regression - Analytical Solution and Simplified Example,,datamapu,1,1.0,0,https://datamapu.com/posts/2023/20231123_linear_regression_example/
201,1701053606.0,Why do I need a GPU for ML/AI,"I'm fairly new to AI and was planning to host my own LLM. I I mentioned this to a coworker and he mentioned I would need a gaming GPU. Why is that?

Can someone explain the purpose of a GPU for AI?",notdoreen,23,0.79,32,https://www.reddit.com/r/learnmachinelearning/comments/184so8i/why_do_i_need_a_gpu_for_mlai/
202,1701100038.0,Finding a ML/DL engineer job as a Ph.D. in AI application,"I am a postdoc who holds a Ph.D. in one of the engineering major not computer science. I received my Ph.D. in South Korea and work as a postdoc in the US. All that I did during my Ph.D. degree was developing ML or DL-based solutions. 

During my Ph.D. I felt so lonely because nearly everyone around me had no genuine interest in ML/AL. I had to find online community of DL study and discussed with ML/DL engineers in the field. 

To switch from academic position to industry field, which one should I do first?   
Could it be helpful just to contribute to open source project or publish my own implementation of any DL models? Any advise would be welcome.",BH_Kim,2,0.75,1,https://www.reddit.com/r/learnmachinelearning/comments/1855yl9/finding_a_mldl_engineer_job_as_a_phd_in_ai/
203,1701111068.0,Data engineer to Data Science Career Change via MS," 

Hello there!

I am a data engineer with 2.5 years of experience who is applying for ms in ds/ ms in cs in various colleges in the USA.

I am facing a block in my SOP, where I am not able to connect these two fields as efficiently as I want to convince them that I have the right profile for being a Data Scientist. I am applying to the top 30 colleges in the USA for the same.

If you don't mind, could you guys please give me your thoughts/ inputs on the same.

I want my SOP to be perfect and I would love any suggestion!

As a data engineer from a top 10 company, my team has created a product like Talend, where a user can ingest data from any rdbms, or filesystem and load it to any other db via our UI/product. ( We have scaled upto 3000 pipelines presently). We also have transformation and loading (egressing it out)  
Excluding this my lead and I have designed the spark structured streaming for the entire organization.  
I have just started working on GCP and will be getting my certification for the same in a month.  
I am 24 currently!

P.s : I have also published two research papers in the field of datascience and won a hackathon in the field of data science.

Thank you for your time!!",LividPie10,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/185aevu/data_engineer_to_data_science_career_change_via_ms/
204,1701110665.0,EDA for Book Sales Inquiry,"Greetings. I did a fairly basic EDA for a book sales dataset I found on Kaggle. I have about 11 findings, and tested a few ideas, but I'm wondering if I am missing anything that would make this analysis better in prep for ML. What other tests should I conduct?

[https://github.com/Blion6868/Data\_Visualization/blob/main/Book\_Analysis.ipynb](https://github.com/Blion6868/Data_Visualization/blob/main/Book_Analysis.ipynb)",Tyron_Slothrop,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/185a92l/eda_for_book_sales_inquiry/
205,1701079183.0,Sentence simplifications python,"I am trying to analyze fairly lengthy and somewhat (structurally) complex legal texts in python. The texts in question mostly refer to financial asset classes (e.g. equities, bonds) and the relevant limitations of investment in such (e.g. up to 20% investment in equities), but often more than one asset class - numerical reference pair is contained in a single sentence and understanding what the ""root"" asset class is for a given numerical reference can be challenging.

I have already tried out most of the available ClausIE libraries (pyclausie, stanford, spacy-clausie) but results were rather poor. Any other ideas how I might get there? Ideally I don't lose words but achieve a rearrangement into a list of small sentences.

I seem to understand that sentence simplification is somewhat of a ""new"" and active research area. Would it be an idea to force train a classifier, i.e., label each sentence a list of simplified sentences?

Cheers",RDA92,5,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/184zhs1/sentence_simplifications_python/
206,1701026420.0,Are ML researchers able to implement architectures just from their head?,"Are (top) machine learning specialists and researchers able to write code for (simple and complex) neural networks and model architectures from scratch just from their head without using existing code, guides, books and discussions (such as StackOverflow) or are they able to implement a paper from scratch just by seeing the architecture and its description in the paper? And if yes, how to achieve such excellence?",NimmMichAnnalena,67,0.92,26,https://www.reddit.com/r/learnmachinelearning/comments/184icuq/are_ml_researchers_able_to_implement/
207,1701062459.0,Orca-2-13B Runs Directly on Rust+WASM – No Python/C++ Hassles,"Faster compared to Python. Portable, more secure and lightweight are compared with Python and other native solutions. In terms of benchmarks, Rust / C++ is 50,000x faster than Python; WasmEdge runtime + portable app is 30M compared with 4G Python and 300MB llama.cpp Docker image that is NOT portable across CPU or GPU; Wasm sandbox is more secure than native binary. 

https://www.secondstate.io/articles/orca-2-13b/",smileymileycoin,9,0.7,5,https://www.reddit.com/r/learnmachinelearning/comments/184veb9/orca213b_runs_directly_on_rustwasm_no_pythonc/
208,1701103464.0,Real-Time Anomaly Detection with AWS SageMaker & Kinesis Streams,,FormalAssociate4660,1,1.0,0,https://medium.com/p/214173b0b0e1
209,1701102549.0,"Host a reliable LLM on-prem for knowledge base consultation, which to choose from?","Hey all, I was tasked to find a suitable LLM that would be able to be run on-prem as this requires certain levels of security.

The obvious first thought went to GPT models, but then I need this to be absolutely precise as if reading word per word out of the documents it will be trained on. The idea is still to re-use a pre-trained model, as I have nowhere near enough material to train a new one, but then using LangChain and other libraries there are ways to host this entirely on my own. Then the model will be further trained on the documents I will give it (mainly PDF files and HTML stuff).

I thought BERT would also be a good choice here, do you have any other suggestions?

&#x200B;",durian_pizza,0,0.5,4,https://www.reddit.com/r/learnmachinelearning/comments/1856xt9/host_a_reliable_llm_onprem_for_knowledge_base/
210,1701100014.0,"I wan't to get into ML, but don't know where to start.","So I'm a Software Engineer but quite new to ML.  
I want to find some topic that would be interesting to get deep into, but don't seem to find a staring point. Blindly searching through arxiv org in't really helpful and courses are too general and not really captivating.  
I wan't to find something like LLM, but can't formulate a question to even start googling, etc. What are the fields within ML like LLM? I don't wan't to get into LLMs but maybe there is something else like it that is interesting to get into?  
Also if you want to suggest some websites, youtube channels, twitters, etc. that cover the news in NN, ML in general would be appreciated. ",mmario312,0,0.4,4,https://www.reddit.com/r/learnmachinelearning/comments/1855yb6/i_want_to_get_into_ml_but_dont_know_where_to_start/
211,1701099644.0,Good fine-tuning dataset for training LLMs to analyze and fix code?,"Hello all!

I'm currently working on a research project where we want to evaluate LLMs performance in Automated Program Repair. More specifically, as it is a smaller project, we want to test 2 models (Llama 2 and Falcon). Our current approach is to use pre-trained models and fine-tune them further to provide patches to bugs.

I figured I should take my shot and see if anyone here knows a nice dataset that might be applicable. If you need more information, I will be happy to provide it.  


Thank you in advance",ekan1999,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/1855thn/good_finetuning_dataset_for_training_llms_to/
212,1701065004.0,A question about the Bayesian Information Criterion (BIC),"Hello everyone,

I am working on a project, and I got negative scores for Bayesian Information Criterion (BIC)

how can I interpret this result?

Thanks",Esmaeel_,6,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/184w2xj/a_question_about_the_bayesian_information/
213,1701074350.0,"Retrieval Augmented Generation (RAG) explained: Embedding vectors, Sentence BERT, Vector Database (HNSW algorithm explained visually)",,hkproj_,3,1.0,0,https://www.youtube.com/watch?v=rhZgXNdhWDY
214,1701046797.0,Reading List for Andrej Karpathy’s “Intro to Large Language Models” Video,"I loved Andrej’s talk about in his “Busy person’s intro to Large Language Models” video, so I decided to create a reading list to dive in deeper to a lot of the topics. I feel like he did a great job of describing the state of the art for anyone from an ML Researcher to any engineer who is interested in learning more.

Here’s the reading list: 
https://blog.oxen.ai/reading-list-for-andrej-karpathys-intro-to-large-language-models-video/

Let me know if you have any other papers you would add!",FallMindless3563,12,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/184qcev/reading_list_for_andrej_karpathys_intro_to_large/
215,1701084812.0,Does it matter if I have the same GPU when using Pytorch's multi GPU capabilities?,"I am about to find myself in posession of several computers with Nvidia A series GPUs (I've got 4 with A4500s and one with dual A6000s). Say next year I get additional GPUs for some of these machines. Could I add a different GPU to the A4500 machines, for instance, and still use libraries like Accelerate or just raw Pytorch to distribute AI computing across them?",crono760,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/1850xko/does_it_matter_if_i_have_the_same_gpu_when_using/
216,1701061075.0,Is this loss normal?,"I am finetuning whisper on a custom dataset and I got this loss curve (train and valid).  


My learning rate is 1e-5 with warmup steps of 50 and linear decay, num\_epochs = 10. I have 2.5 k train samples overall with a batch size of 16

&#x200B;

Here's the loss curve  

[Whisper loss curve](https://preview.redd.it/jah37b5rnt2c1.png?width=1600&format=png&auto=webp&s=32cc9f5d1a6b94447ec872ca63e5440d2e0de9de)",Amgadoz,3,1.0,12,https://www.reddit.com/r/learnmachinelearning/comments/184uzsw/is_this_loss_normal/
217,1701076939.0,YOLOv7 model and dataset,"I am working on my final year project on some kind of object detection problem. we decided to employ YOLOv7.

Basically I have no idea on the amount of training set, validation set and testing set for a custom model to detect document from different companies. I see a large variation of amount of dataset.

In addition, is it necessary to apply GPU to train the model? Is colab free version sufficient to train the model within reasonsible time? Thanks.",uartimcs,1,0.99,1,https://www.reddit.com/r/learnmachinelearning/comments/184yzd3/yolov7_model_and_dataset/
218,1701052041.0,Al/ML Engineer without degree?,"Is it actually possible to land a job as Machine Learning Engineer without degree? | saw lot of yt video where most people say that they succeed as ML engineer and managed to get a job by learning all the stuff on their own, but on the other hand some people state that its really difficult/nearly impossible or u must be very lucky, must live in specific countries etc. Now whats the truth behind the veil and why is this so controversial? Thank you for the answers!",Nacs0sz,2,0.56,10,https://www.reddit.com/r/learnmachinelearning/comments/184s591/alml_engineer_without_degree/
219,1701051661.0,Need Clarity on AutoEncoder Architecture for Super-Resolution,"I'm currently trying to create a Super-Resolution model using AutoEncoder and need help to understand a few things both theoretically and mathematically:
- When and Of What Exactly is Prior/Posterior Probability Calculated Of ?
- How does Encoder know that the lesser dimension Representation in Latent Space is Correct?
- What is the Role and working principle of Regularization and Back-Propogation in Decoder Structure?
- What is the Significance of KL Divergence?

I'm new and am struggling to understand a lot of terminologies here. Please, any help would be extremely helpful!!!",GraceMeme,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/184s0os/need_clarity_on_autoencoder_architecture_for/
220,1701028741.0,What are the advantages of GANs over Diffusion Models in image generation?,"Diffusion Models have recently gained popularity in the field of image generation, with widely used products such as Stable Diffusion employing this approach and yielding impressive results. While GANs are also recognized for their efficiency, in what scenarios do I need to choose GANs over Diffusion Models and do GANs have any advantages compared to Diffusion Models in image generation?

Here are a few reasons I can think of:

* Diffusion Models take more time and larger datasets to train.
* To train a Diffusion Model project, one must have substantial computational resources (a lot of GPUs), compared to GANs.
* The codebases of some popular Diffusion Models projects are not open source.

I don't know if these are correct. As for the mathematical aspect, I'm not an expert in that area.",Electronic_Ant2706,7,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/184j8oo/what_are_the_advantages_of_gans_over_diffusion/
221,1701055512.0,Beginners advice for Machine Learning to create 3d models?,"(Apologies if this isn't a 'machine learning' thing - perhaps its an AI thing?)


I'm wanting to create 3d models of faces - ie. I feed it in many faces with different proportions, and it can then creating variations based off that


Is that currently possible, and if so, what would be a good way to start coding it?",freelance3d,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/184tbmc/beginners_advice_for_machine_learning_to_create/
222,1701052577.0,Predicting Typing Speed,"I've scraped a typing website for data on my typing speed and want to use machine learning to create something that can predict how fast I will type a text.  I've assembled a CSV where each row contains the four characters leading up to the character of interest, the actual character I am typing, the three characters after that, and the number of milliseconds it took me to type the character.  My dataset has 500,000 rows at the moment, but I can easily get more if it would help.

I have no experience with machine learning, but here's what I tried.  I looked at scikit-learn's [choosing the right estimator](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) article, and because I'm predicting a quantity and have greater than 100k samples, I used SGD Regressor.

One of the first problems I ran into was I didn't know how to work with text - I read about one hot encoding and am using that at the moment.  Because this resulted in a large number of columns, I replaced all characters in my dataset that I typed fewer than 25 times with a generic ""rare character"" character (so for example, I'm fine if my predictor doesn't distinguish between # and \* because I don't type either one very frequently).

I also saw that you should scale your values when using SGDRegressor so I used StandardScaler on my y column.

Finally, I created the model and tested it:

    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size=0.7)
    sgd = SGDRegressor(max_iter=2000)
    sgd.fit(X_train, y_train)
    y_pred = sgd.predict(X_test)
    print(sgd.score(X_test, y_test))

However, this gave me an R-squared value of 0.083 which seems really low.

Do you all have any thoughts as to what I could try to improve my model?  


Thanks!",Sufficient-Summer-88,1,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/184sbrg/predicting_typing_speed/
223,1701038357.0,"Is anyone happily training models with an Apple Macbook M2 Air 15’ 16GB RAM with no regrets for not using a Macbook Pro M3, and what size of models and keyword sets you manage with it? On is anyone using the Macbook Pro because the Air was possibly not enough?",,aspublic,2,0.67,5,https://www.reddit.com/r/learnmachinelearning/comments/184n4vk/is_anyone_happily_training_models_with_an_apple/
224,1701023877.0,Hallucination Meth? Need sauce.,"I am writing a paper on LLM Hallucination and I want to give a mathematical basis for it as a background.  
What are some **sources** for mathematical basis for hallucination. I am poor in LLM math in general but I feel it will improve my chances for paper acceptance.  
Sources like *academic papers* and *YT explainers*.",MangoedBanana,5,0.73,4,https://www.reddit.com/r/learnmachinelearning/comments/184heec/hallucination_meth_need_sauce/
225,1701026075.0,Best learning ressources?,"Hi,

I'm setting up my learning resources at the moment to get into ML & DL. Which resources do you can recommended? YouTube Channels beside 3B1B, StatQuest? Books with implementation parts such as [https://udlbook.github.io/udlbook/](https://udlbook.github.io/udlbook/)? Other resources? Apps like Brilliant? Where to get the latest (and relevant) papers?",huanjosingho,3,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/184i80h/best_learning_ressources/
226,1701032762.0,Why are time series forecasting models not considered generative?,,WadeEffingWilson,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/184kucd/why_are_time_series_forecasting_models_not/
227,1701045500.0,[D] Any future in ML for someone with a psychology degree and interest in health?," 

I have a psychology degree and an interest in overall health (mental, physiological, neurological etc). I also enjoy and find technology interesting as well with an overall interest in automation/making lives easier- in a health sense

So far, I am considering to learn a programming language on my own and head back to university for some ML classes and linear alge

bra/stats.

However, I also like tech and leadership. I am trying to navigate through what I want as a career. I heard about machine learning/AI and thought there may be an intersection where I could use my interests in health and incorporate them with tech. Perhaps program AI that would aid specific health issues? Of course, I am looking for something that pays well and has a good environment.

If you all could be kind enough to pitch in your thoughts and help with my brainstorming :)",bigbentower,1,0.67,1,https://www.reddit.com/r/learnmachinelearning/comments/184pvew/d_any_future_in_ml_for_someone_with_a_psychology/
228,1701043756.0,How do i become a Machine Learning engineer? (being an Electronic engineer),,Matnaranjo,1,0.67,1,https://www.reddit.com/r/learnmachinelearning/comments/184p8d5/how_do_i_become_a_machine_learning_engineer_being/
229,1701010158.0,🤔Cloud Document AI Too Expensive? A Concise Review of State-Of-The-Art Alternatives 💸🚀,,lovestacoo,4,1.0,0,https://journal.hexmos.com/document-ai-sota-models/
230,1701014113.0,[Seek Guidance/Ideas] I want to build a (Python) Chatbot that can answer questions based off some text fed to it. How to proceed? What topics do I need to learn? Please provide a pathway.,"For **example**:

If the bot is fed a **text article** on ""*World Health Organization*"" (say) then if it is asked ""*When was the World Health Organisation established*?"" it should be able to **answer it based on that article**.",Debatreyo,3,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/184dpf5/seek_guidanceideas_i_want_to_build_a_python/
231,1700999999.0,I am at a crossroads and unsure where to go now,"I am currently doing EE undergraduate. So far, I've also managed to self-learn ML by myself alongside my academics. EE is difficult enough on its own. I've barely scraped by in my freshman level courses, while still keeping up with ML. However, now that the workload has increased, and I'm doing harder college courses, I'm not sure I can keep up with ML.

I can't take any ML courses in my college because there's only two in my major and they're quite inadequate. However, I am unwilling to simply stop learning. I've worked quite hard and have built a decent foundation so far. But, if I give up for a few years till I graduate, I'll have forgotten everything I've learned and I will have to start over from scratch. I also want a job in the ML sector, so I don't wanna start learning just as I freshly graduate as it would be too late then. I'm not sure where to go from here now. ",open_23,5,0.78,9,https://www.reddit.com/r/learnmachinelearning/comments/18496yf/i_am_at_a_crossroads_and_unsure_where_to_go_now/
232,1701017079.0,Training my first SpaCy NER model,"Hi, so I’m training my first space model, and I’m training it to identify six different things, from a variety of text examples. For this first round, I ran the training model against the training set because I didn’t have a validation set. So obviously, the results were superb and I put some example text and ran a display server and it did OK… For the second go around I’m creating a validation set for it to run against but I did annotate 200 examples for this time.

Is there a certain number of examples I should annotate for each particular thing being identified? I really want to improve my results tremendously  

Any recommendations that you may have since this is my first time playing with this? 

Any thing I should keep in mind? 

Any advice at all would help. Thanks.

spare me folks (very new)",hiddenhospital,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/184et78/training_my_first_spacy_ner_model/
233,1701029673.0,Can any generative model (classical ML or DL) be made where there are only a few samples for each class in a multivariate dataset?,"I've used VAEs before when I have large amounts of data but I'm working on a research project and have access to only a small amount of data.

The data that I have is a time series that was originally sampled at 5m intervals over a month. The signal in the data is most prominent (signal to noise) at 1h bins, so I rebin the time series from 5m to 1h. The data was originally univariate but I stack it into a 2D set with shape (31,24) for 1h bins and (31,288) for 5m bins.

From clustering, I have 3 main classes. The first cluster has 15 members (days), the second has 8, the third has 6, and there are 2 anomalies that aren't assigned to a cluster.

Is there a way to create a generative model from this data? It would be useful for testing. I have access to more data but since this is part of research, I want to challenge myself to include a generative model, if it's possible. I don't think there's enough for a VAE or GAN and I'm not sure if there is a classical ML generative model that could do this.

Since it's a time series, yea, it would make since to forecast but from what I've read around (and not an opinion that I share), time series forecasting models aren't considered generative models.

I created a cheap approximation by selecting a different value from each variable (hour) within a given class so the effect is that the new sample is unique as a whole but made of observations the model has seen before. This wasn't the right way and didn't have the effect I wanted, so I moved on.

I tried using the inverse-transform method to resample from the ECDF but the fit wasn't right. Likely due to not having enough samples, I think.

Are there any ways to generatively create more samples for the classes given the small amount of data that I have?",WadeEffingWilson,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/184jm99/can_any_generative_model_classical_ml_or_dl_be/
234,1701010799.0,What are the good pre-paid infrastructure options to train neural networks?,"This is for one of my ""hobby"" projects. Most of the people I know who do deep learning either have their own GPU systems or they use VMs with GPU from common cloud service providers like Azure. Buying a GPU just for a hobby project looks like an overkill. Getting a cloud subscription require a credit card and it comes with a lot of risk. I know couple of people who ended up paying a lot when they forgot to shutdown their VM.

So far Google-colab is the only service I found which allows me to buy compute units before hand and get on with the training.

What other options are there where I can buy some compute units of a GPU VM (or a GPU supported notebook) and it doesn't end up bankrupting me for a mistake?",graphitout,2,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/184cih8/what_are_the_good_prepaid_infrastructure_options/
235,1701010739.0,Vision Transformers need registers: Improving attention maps of vision transformers,,SouvikMandal,2,0.75,0,https://medium.com/@mandalsouvik/vision-transformers-need-registers-ca7ded042d6a
236,1701044827.0,Possible GPU,"I just found a offer for a GPU that is an a affordable price for me!, but saddly, i have a laptop and im not sure how to use such gpu with the laptop as i dont currently own a desktop, but yhe specifications seem better then what collab has to offer so i feel it should be enough for deep learning models but i have to make the devision quick, may anyone offer some advice as to if this is a fair gpu for that and most importantly how to use it with my laptop, ( and if i should ) i wish to get to training more often and wanted to learn how to use the gpu myself so i felt having one availble amd not depending on googles resourses would be amazing, it is a RTX 4060 TI VENTUS 3X 16G OC MSI NVIDIA GeForce",Alexercer,0,0.25,4,https://i.redd.it/i1cply3mbs2c1.png
237,1701018937.0,Getting probability from classification decision tree,Should I give an observation a probability based on the proportion of true/false in the leaf node or should I give all observations the probability given by the confusion matrix of my decision tree? (Side note the target variable is binary),Traditional_Soil5753,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/184fj8e/getting_probability_from_classification_decision/
238,1701018831.0,"i am trying learn ai from the scratch , this is the step by step approach given by chat gpt . pls give your opinion."," 

### Step 1: Prerequisites (2-3 weeks)

#### Mathematics:

* **Resource:**
   * Continue reviewing linear algebra. Use Khan Academy or MIT OCW for additional practice.
   * Extend your knowledge to cover more advanced topics like matrix factorization and applications.

#### Programming:

* **Resource:**
   * Codecademy or SoloLearn for Python basics. Focus on data structures and algorithms.

### Step 2: Fundamentals (6-8 weeks)

#### Machine Learning:

* **Resource:**
   * Coursera: [Machine Learning by Andrew Ng](https://www.coursera.org/learn/machine-learning)
* **Duration:**
   * Complete the course in 6-8 weeks, spending around 8-10 hours per week.

#### Statistics:

* **Resource:**
   * Khan Academy: [Statistics](https://www.khanacademy.org/math/statistics-probability)
* **Duration:**
   * Spend 2-3 weeks covering basic statistical concepts.

### Step 3: Core AI Concepts (10-12 weeks)

#### Deep Learning:

* **Resource:**
   * Coursera: [Deep Learning Specialization by Andrew Ng](https://www.coursera.org/specializations/deep-learning)
* **Duration:**
   * Complete the specialization in 10-12 weeks, dedicating 10-12 hours per week.

### Step 4: AI Applications (8-10 weeks)

#### Natural Language Processing (NLP):

* **Resource:**
   * Coursera: [Natural Language Processing in Python](https://www.coursera.org/learn/natural-language-processing-in-python)
* **Duration:**
   * Spend 8-10 weeks exploring NLP concepts and applications.

#### Computer Vision:

* **Resource:**
   * Coursera: [Convolutional Neural Networks by Andrew Ng](https://www.coursera.org/learn/convolutional-neural-networks)
* **Duration:**
   * Allocate 4-6 weeks to understand computer vision principles.

### Step 5: Specializations (Variable duration)

#### Reinforcement Learning:

* **Resource:**
   * [Reinforcement Learning Course by David Silver](https://www.youtube.com/watch?v=2pWv7GOvuf0)
* **Duration:**
   * Variable, depending on depth of study, but aim for 6-8 weeks.

#### AI Ethics:

* **Resource:**
   * Explore online courses on platforms like Coursera or edX focusing on ethics in AI.
* **Duration:**
   * Variable, depending on the course, but aim for 4-6 weeks.

### Step 6: Projects (Ongoing)

* Work on practical projects throughout your learning journey to apply concepts. Platforms like Kaggle offer datasets for hands-on experience.

### Step 7: Advanced Topics (Ongoing)

* Explore advanced topics such as Generative Adversarial Networks (GANs), Transformers, etc., based on your interest.",Happy_Magazine_2477,0,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/184fhne/i_am_trying_learn_ai_from_the_scratch_this_is_the/
239,1701018485.0,Are there any FH for AI i Germany?,"I've just finished Studienkolleg and wanted to find an FH to study KI in, but most of them are Uni. Are there any?",DevilBreath01,0,0.5,3,https://www.reddit.com/r/learnmachinelearning/comments/184fcpi/are_there_any_fh_for_ai_i_germany/
240,1700986497.0,Better Architectures for Neural Networks - Chris Manning vs Yann LeCun,,danipudani,5,0.86,1,https://youtu.be/IVGnA_mP-f4?si=LaJ2jTgGAQUJsaJg
241,1701014700.0,Completed 1st course of ML specialization,"I recently completed first course(supervised learning) of ML specialization by Andrew Ng. should I continue to 2nd course or do little project. But, I feel, there is too little to implement, so should I go ahead with 2nd course?",Cold_Young2592,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/184dxfc/completed_1st_course_of_ml_specialization/
242,1701026435.0,🔴 never watch another video (let your AI instead),,,0,0.33,1,https://www.youtube.com/live/Csy-diarREY?si=DPJqygf7lbf6WQkR
243,1700982683.0,Sk-opt gp_minimize giving different learning rates everytime i run it?,"hello, im trying to use bayesian optimization on a pytorch gan using skopt's gp\_minimize to find optimal generator and discriminator learning rate values, but everytime i run it i get different values. what does this mean? should i be expecting different values? if its supposed to give optimal solutions, why is it giving more than one? thank you!",RazzmatazzInternal85,3,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/18455sw/skopt_gp_minimize_giving_different_learning_rates/
244,1700974177.0,8 Best Machine Learning Courses for Finance You Must Know,,Aqsa81,4,0.75,0,https://www.mltut.com/best-machine-learning-courses-for-finance/
245,1700960154.0,ZeroMQ or RabbitMQ - OpenCV for Video Analytics,"Hello all,

I'm experimenting with video analytics and exploring a multi-task setup. My approach is a central worker that processes video streams, converting them into frames. These frames are then distributed via ZeroMQ to various other workers. Each worker specializes in tasks like motion detection, YOLO object detection, license plate recognition, and processing the frames they receive from ZeroMQ. I looked at RabbitMQ and think it might be better suited with many workers and a TTL? I could also use pickle + multicast to keep it lean.

I'd like to hear if this approach is practical or if there is a more efficient method to accomplish these tasks concurrently. I'm open to suggestions and would greatly appreciate any insights or resources you could share. Are there any articles or guides you recommend that could help me refine this system?

Thank you so much for your time and help!",Ok_Needleworker_1987,5,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/183ygry/zeromq_or_rabbitmq_opencv_for_video_analytics/
246,1700987574.0,Machine learning and AI roadmap,I am complete beginner so I wanted to know a path that will help me in leaning machine learning and creating professional projects pls help,Any_Violinist_3325,0,0.5,2,https://www.reddit.com/r/learnmachinelearning/comments/1846azx/machine_learning_and_ai_roadmap/
247,1700986584.0,Help me decide between courses.,"I have a background on python programming and some data analytics (numpy,pandas etc...) I want to focus myself into ML and creating models.I have chosen 2 courses looked best for me but I cannot decide.

First one is the legendary [Andrew Ng](https://www.coursera.org/specializations/machine-learning-introduction) and the second one is [Sebastian Raschka](https://lightning.ai/courses/deep-learning-fundamentals/), the Andrew ng course has a great rating and recommended by almost everyone (plus a certificate ) but the I also heard great stuff from Sebastians course too, on top of that Sebastian uses PyTorch/pytorch lightning so feels more mainstream to me.

Which one should I choose ? any experiences on these courses ?",Ok-Preference-4696,0,0.5,2,https://www.reddit.com/r/learnmachinelearning/comments/1846327/help_me_decide_between_courses/
248,1700966444.0,Loss quickly plateaus and stop improving in any significant way,"I'm training a model based on transformer decoder architecture. I can fit it quickly to one example, the loss is steadily improving and the test results are excellent.

On medium size dataset, the loss quickly plateaus no matter how many more time I give it. The test results are OK but I'd like to improve it, given that it doesn't seem to be doing much after 30-40% of training time.

I know there are tons of things at play here, but I'd like to hear a general guidance of where I should be looking to make it better.

I'm using a learning rate cosine decay scheduler with warmup. Increasing model capacity (more heads, larger linear layers) does not seem to make a difference. Tweaking optimizer's weight decay did make it a bit better. Other than that I'm out of ideas.",SolidMarsupial,2,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/1840jhz/loss_quickly_plateaus_and_stop_improving_in_any/
249,1700944461.0,Where to get updated about latest research?,"Hi,

I'm a computer science student which want to get deeply into ML. Which resources do you can recommend to get updated about latest research and developments in the wide-field of ML?

Thanks!",SEPASebastian,6,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/183sukv/where_to_get_updated_about_latest_research/
250,1700931277.0,How much general knowledge should I have and when do I specialise?,"So far, most courses I've seen seem to be on Machine learning and deep learning. My question is, how much general knowledge should I have in ML before I decide to specialise? Do I go through all the machine learning and Deep learning courses for a foundation? Is there anything additional I need to learn?

And once I do have a solid base, how do I know where I should specialise?",open_23,7,0.9,4,https://www.reddit.com/r/learnmachinelearning/comments/183nzqe/how_much_general_knowledge_should_i_have_and_when/
251,1700950313.0,Neural Network Weight Prediction with Diffusion Models,,tylersuard,3,0.81,2,https://medium.com/@ceo_44783/neural-network-weight-prediction-with-diffusion-models-fc757fcdcf0e
252,1700938162.0,Portfolio advice,"

Currently I have a couple of ml projects in my GitHub that consists in EDA and supervised model building using kaggle datasets, I don't think this is enough to land my first DS job. So I want to learn how to put my models into production, where should I start? How can I show this project? What is the best cloud option (free tier)? 

Thanks in advance",PedroAtreides,4,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/183qjiq/portfolio_advice/
253,1700938937.0,I shared a 1+ hour Python Machine Learning Course on YouTube,"Hello, I wanted to share that I uploaded a Python Scikit-learn course on YouTube. I covered the basics of machine learning, feature engineering steps and most of the machine learning algorithms in the course.

[https://www.youtube.com/watch?v=0iGbDII-HqY](https://www.youtube.com/watch?v=0iGbDII-HqY)",onurbaltaci,3,0.72,0,https://www.reddit.com/r/learnmachinelearning/comments/183qu3c/i_shared_a_1_hour_python_machine_learning_course/
254,1700920395.0,Pneumonia Detection using VGG16 Transfer Learning," Hello everyone!

I am excited to share my latest Kaggle notebook with you all. In this notebook, I have implemented and evaluated the performance of VGG16 Architecture by fine-tuning it on Chest X-Ray Images(Pneumonia) dataset. I would love to hear your feedback and thoughts on my notebook, so please do feel free to comment and share your views. In case you do find this notebook helpful, please do not hesitate to give it an upvote or share it

[https://www.kaggle.com/code/akshitsharma1/pneumonia-detection-using-vgg16-transfer-learning](https://www.kaggle.com/code/akshitsharma1/pneumonia-detection-using-vgg16-transfer-learning)

Thanks a lot for your time and support :)",akshitsharma1,7,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/183k7uz/pneumonia_detection_using_vgg16_transfer_learning/
255,1700930709.0,Need suggestion for interview,"Hello everyone, happy thanksgiving weekend.

Here is the situation:

I had been without a job for about 4 months, post which i finally received an offer and joined around 2 weeks back. The pay is okayish but the work is absolutely boring, just reports and refresh. No one even talks about Data science in the team.

Now i had applied to another company which by all records does good work and pays decent. The role is pretty close to what i was doing earlier.

I had applied to the second company a couple of months back and they have been very slow to interview. I genuinely wanted to close it before i joined the first company but that was not to be. Next week the second company has scheduled the last 2 rounds, my questions are:

1. I never told the prior round interviewers about this new company as i had not joined then, in the coming rounds should i tell that i have joined a new company for a couple of weeks?

2. 🤞if everything goes good, should this couple of weeks be forver be a mark on my resume and i have to keep explaining it to other companies or can small experiences not be mentioned in resume.

Wanted to know your thoughts on this and how you would have dealt this situation.",dipranjanchatterjee,4,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/183ns9y/need_suggestion_for_interview/
256,1700911573.0,How I made a Chatbot to speak with YouTube Videos,"Hey,

Given recent advancements in the local LLMs area and how easy it has become, I wrote some code that virtually allows one to chat with YT videos and ask questions about them. The code can be found here:

[https://github.com/devspotyt/chat\_with\_yt](https://github.com/devspotyt/chat_with_yt)

There's also an explanation for the Pythonic code in the README and a reference to a video explaining it. This was way easier than I anticipated, all I had to do is:

1. Set up a Gradio UI with relevant inputs.
2. Extract the video ID from a YT video URL.
3. Use a pythonic package to get a transcript of the video, then convert that transcript to a more ""AI-Friendly"" text.
4. Connect the code with relevant LLMs such as LLama / Mistral via Ollama / HuggingFace inference endpoints which are publicly available (/can run locally).

And that's pretty much it. You can get a short summary of videos, ask when a certain topic was discussed, etc. And the best part is that this is 100% free and can run locally without sharing your data.

The code itself was written in a 1 hour blitz coding session (with the help of a certain LLM ofc), but overall its kinda dope IMO, lmk what you think about it.

cheers",dev-spot,10,0.92,0,https://www.reddit.com/r/learnmachinelearning/comments/183hrq7/how_i_made_a_chatbot_to_speak_with_youtube_videos/
257,1700890864.0,What machine learning algorithms should I learn for the 'common workforce'?,"When looking at data analytics or machine learning jobs for the general workforce (ie not specifically working for an analytics/ml company), what machine learning algorithms should I wrap my head around? ie. would understanding stochastic gradient descent be good enough to tackle the majority of problems in most work places?

What else should I learn?",UnionInteresting8453,24,0.89,14,https://www.reddit.com/r/learnmachinelearning/comments/183cpss/what_machine_learning_algorithms_should_i_learn/
258,1700950529.0,Looking for internship opportunities,"Hey there! I'm a 3rd-year BTech student in India and most of the summer 2024 internships are already closed. Missed out on snagging one! I'm pretty good with Python, acing data structures, algorithms, and I'd say I'm mid-level in data science. Any chance you know of remote openings or have some contacts? Would really appreciate the assist!",Historical-Till-6199,0,0.33,1,https://www.reddit.com/r/learnmachinelearning/comments/183v2p6/looking_for_internship_opportunities/
259,1700900377.0,[1hr Talk] Intro to Large Language Models by Andrej Karpathy,,talycaba,13,0.93,1,https://youtu.be/zjkBMFhNj_g?si=lMUOEdSfb6xOm8XU
260,1700932917.0,Didn't find op for builtin opcode 'SHAPE' version '1'. Version mismatch,"Hey guys! Learning Tensorflow lite.  


Ive been working on a project that involves image processing and I have successfully dumped a model onto my `ESP32-S3-DevKitC-1` board. However, while running the program, I get the following errors while allocating tensors:

```
Didn't find op for builtin opcode 'SHAPE' version '1'. An older version of this builtin might be supported. Are you using an old TFLite binary with a newer model?

Failed to get registration from op code SHAPE

AllocateTensors() failed
```


On furthur [research](https://github.com/tensorflow/tflite-micro/issues/2261), I have come to believe its a version mismatch between the model and TFLite op codes.

Note: Just to test my thesis, I compiled another dummy model with only one convolutional layer instead of 4 which my model has, and that seems to work without throwing any errors. Only when I use my 4 layer model, it seems to throw this error.

How do I resolve this error? Thank you all for your help in advance!",sumolpp,3,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/183omdb/didnt_find_op_for_builtin_opcode_shape_version_1/
261,1700932759.0,How to Best Use AI as an Educational Tool – 10 Genius Tricks You Didn’t Know Existed,""" Up until now, much of the discussion surrounding the use of generative AI in education has centered on catching AI used in cheating.  Some educators have seen generative AI as an awkward reality that makes writing assignments difficult to regulate.  With ChatGPT 4.0, students can pass off AI writing as their own original work thus circumventing the point of the assignment.  AI is seen as the ultimate slacker tool, making it irresistibly easy for lazy students to complete writing assignments at the press of a button.  

Educators Strike Back?

How are teachers supposed to respond to this?  I think there are two possible responses to this.  One is the first, very understandable response, which is to attempt to catch the “AI cheater” in the act.  This reaction makes sense at the moment since educational organizations have not yet had time to understand and respond to the technology.  To help on that front, we have created a thorough review of how educators might catch the students who decide to become AI cheaters in the article at this link.

If You Can’t Beat’em…

However, in this article, we will look at what I believe is the second possible response educators can have to this technology: rather than trying to constantly stay ahead of this ever-evolving technology in order to try and “catch the cheater,” can we rather ask if there is a way of using generative AI as an educational asset?  Could we possibly view [machine learning](https://ai-solutions.pro/what-is-machine-learning-a-beginners-guide/) and [Natural Language Processing](https://ai-solutions.pro/what-is-natural-language-processing-nlp-the-ultimate-beginners-guide/) as a natural next step in the advancement of technology, much like math teachers eventually accepted the use of calculators in math class? ""

Here is the full article:

[https://ai-solutions.pro/ai-in-education-10-genius-tricks-you-didnt-know-existed/](https://ai-solutions.pro/ai-in-education-10-genius-tricks-you-didnt-know-existed/)",Science-man777,2,0.53,8,https://www.reddit.com/r/learnmachinelearning/comments/183ok48/how_to_best_use_ai_as_an_educational_tool_10/
262,1700914508.0,"Review on MIT Great Learning's ""Data Science and Machine Learning: Making Data-Driven Decisions"" program","I have just completed Great Learning x MIT's Data Science and Machine Learning: Making Data-Driven Decisions program and here's my 2 cents:

Pros:

1) Covers foundational to advanced topics in data science (Python, Probability, Statistics, Machine Learning, Deep Learning etc.)

2) Lecture videos created by MIT faculty members and industry professionals.

3) Mentorship and guidance from Great Learning's program managers.

4) A total 4 major projects and 50+ guided projects 

Cons:

1) Limited emphasis on big data tools, does not explore tools like Hadoop or Spark. 

2) Machine learning using cloud services is not covered.

Overall great return of investment if you ask me.",Ok-Gear-1889,4,0.83,2,https://www.reddit.com/r/learnmachinelearning/comments/183iigc/review_on_mit_great_learnings_data_science_and/
263,1700914379.0,Easily implement parallel training.,[https://github.com/NoteDancing/Note](https://github.com/NoteDancing/Note),NoteDancing,3,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/183ih8e/easily_implement_parallel_training/
264,1700900042.0,Logistic Regresion for Breast Cancer Prediction,"Hello everyone!

I am excited to share my Kaggle notebook with you all. In this notebook, I  have implemented logistic regression for breast cancer prediction using the  [Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data)  dataset

I would love to hear your feedback and thoughts on my notebook, so please do feel free to comment and share your views. In case you do find this notebook helpful, please do not hesitate to give it an upvote or share it

[https://www.kaggle.com/code/akshitsharma1/anime-art-with-dcgan-generate-stunning-faces](https://www.kaggle.com/code/akshitsharma1/anime-art-with-dcgan-generate-stunning-faces)

Thanks a lot for your time and support :)",akshitsharma1,4,0.84,0,https://www.reddit.com/r/learnmachinelearning/comments/183f0zn/logistic_regresion_for_breast_cancer_prediction/
265,1700909866.0,Computer Vision Roadmap,"Hey, I'm learning ML for 3 months. I have learned some machine learning algorithms and also ANN and it's optimizers and loss functions. So, I was looking for Computer Vision roadmap on internet. I have searched on YouTube, and they don't even tell to learn basic ml algorithms. They just say, learn a programming language then learn image preprocessing and Image classification using CNN and a lot of things. But none of them say learn basic of ml algorithms like: SVM, Decision Tree, etc. 

So, Can you guys tell me the required things that I need and also do I need that algorithms. If I need then tell me what algorithms and also please give me full beginning to the end roadmap. So, if I have left any thing in ml that are required in computer vision that I will cover from that roadmap. And also tell me all technical knowledge that I need for computer vision.",CodingWithSatyam,4,0.83,0,https://www.reddit.com/r/learnmachinelearning/comments/183hckm/computer_vision_roadmap/
266,1700929530.0,Seeking advice on where to start with a multi-language categorisation project,"Hey everyone,

I've been diving into a challenging task lately, and I'm seeking advice from the community regarding categorizing book data efficiently across multiple languages.

Context: I'm working with numerous book retailers, aiming to match their category/breadcrumb information to my own classification system.

For instance, a book categorized as:

* ""books > business, finance & law > management > management skills > leadership"" by a book site
* needs to fit into my category: ""books > business, finance > business and management > strategy"".

Currently, I'm employing text similarity methods like Levenshtein distance, but it's falling short at scale, achieving less than 80% accuracy (i.e., less than 8 out of 10 matches).

Question:

1. I'm exploring the feasibility of a machine learning-based solution suitable for a multi-language environment. I've noticed RoBERTa, available in 100 languages—do you think this could be a viable option?
2. Should I lean towards a classification approach like an SGD classifier, or would a more advanced method using embeddings in a high-dimensional space, perhaps akin to a KNN exercise, be more effective?

Specifics:

* Approximately 240 classes in my categories.
* Roughly 6,000,000 items to classify in English, French, and German.
* Targeting a minimum accuracy of 95%.
* I'm aiming for low inference costs as inventory changes frequently, ruling out solutions like GPTs/APIs due to budget constraints.
* I have begun to create a dataset with book name, external breadcrumb, my target breadcrumb

I'd greatly appreciate any insights or guidance you might have on this matter. Thanks a lot for your help.",Numerous_Speed_9107,1,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/183nd1f/seeking_advice_on_where_to_start_with_a/
267,1700976053.0,How do I get started in Ai Technology as a complete beginner?,"Hi everyone! I've got a burning question and I'd be incredibly grateful if anyone could help me clear up my doubts and confusion.

With the rapid advancement of AI technology and new innovations popping up every week, I'm eager to dive in and learn more. As a complete beginner with zero prior experience in machine learning or AI, I'm wondering where to start in order to build a solid foundation in AI technology. I want to leverage AI to make money, create bots, and offer services.

For those of you who are already making $$$ in this field, I'd love to hear about your journey. What were your initial steps? And if possible, could you kindly share some beginner-to-advanced level resources or links that I can use to kickstart my learning journey?

Thank you so much for taking the time to read this, and I'm eagerly looking forward to the incredible support and insights from the comments section.",Pinepilot,0,0.3,30,https://www.reddit.com/r/learnmachinelearning/comments/1843ep3/how_do_i_get_started_in_ai_technology_as_a/
268,1700838413.0,Talk to Taipy - an app that uses natural language to manipulate and visualize data,"Hi! My team has been working on an LLM application called Talk to Taipy.

[https://talk-to-taipy.taipy.cloud/](https://talk-to-taipy.taipy.cloud/)

https://i.redd.it/vrdd3zsa9b2c1.gif

Talk to Taipy was created as an end-user application to manipulate and visualize your data using natural language.  You can add your CSV file and ask the prompt to show/filter/plot... the data. You can also get the Taipy and Panda code of the plot/query.

It was built with Taipy, an open-source Python library that turns your Data and ML applications into full applications, from the front-end to the back-end. ([https://github.com/Avaiga/taipy](https://github.com/Avaiga/taipy)). For the AI part, Talk to Taipy was created using Hugging's face starcoder.

We are open to constructive feedback to make it the best application possible, so don't hesitate!",quicklyalienated76,102,0.99,2,https://www.reddit.com/r/learnmachinelearning/comments/182u4c8/talk_to_taipy_an_app_that_uses_natural_language/
269,1700924286.0,Azure AI Cloud Skills Challenge," 🚀 Microsoft Azure AI Fundamentals Cloud Skill Challenge 🤖

The  challenge has begun! Join now and unlock the power of Microsoft Azure  AI resources for your future projects. The learning adventure continues  until December 2nd! 🗓🌐

It will be an incentive-driven competition, where participants who rank highest on the leaderboard will qualify.

🎁 Perks Await You:

🌟 LinkedIn Premium Voucher (12 months)

📜 Certificates of Achievement

🎖 Exclusive Badge

📝 Registration Form:

Please    take a moment to fill out this  form   and incentives will be sent to    the email you provide. The email  should   be you given one for the    event registration.

[https://forms.office.com/r/TAr28SpwBE?origin=lprLink](https://forms.office.com/r/TAr28SpwBE?origin=lprLink)

🔗 Challenge Link:

[https://learn.microsoft.com/training/challenges?id=18cbff95-6b28-489f-b346-9b2648684292&WT.mc\_id=cloudskillschallenge\_18cbff95-6b28-489f-b346-9b2648684292&wt.mc\_id=studentamb\_209465](https://learn.microsoft.com/training/challenges?id=18cbff95-6b28-489f-b346-9b2648684292&WT.mc_id=cloudskillschallenge_18cbff95-6b28-489f-b346-9b2648684292&wt.mc_id=studentamb_209465)

📧 Event Support:

Encountering challenges or have questions about the event incentives send an email to:

[nirmal.chandrasiri@studentambassadors.com](mailto:nirmal.chandrasiri@studentambassadors.com)

🚀 Don't miss out on this incredible opportunity to learn and earn fantastic rewards! 🙌🏻

\#Sweepstakes #Azure #AI",Code-Squad,0,0.33,1,https://www.reddit.com/r/learnmachinelearning/comments/183lh6f/azure_ai_cloud_skills_challenge/
270,1700920294.0,Azure AI Cloud Skills Challenge," 🚀 Microsoft Azure AI Fundamentals Cloud Skill Challenge 🤖

The     challenge has begun! Join now and unlock the power of Microsoft  Azure    AI resources for your future projects. The learning adventure   continues   until December 2nd! 🗓🌐

It will be an incentive-driven competition, where participants who rank highest on the leaderboard will qualify.

🎁 Perks Await You:

🌟 LinkedIn Premium Voucher (12 months)

📜 Certificates of Achievement

🎖 Exclusive Badge

📝 Registration Form:

Please  take a moment to fill out this  form   and incentives will be sent to  the email you provide. The email  should   be you given one for the  event registration.

[https://forms.office.com/r/TAr28SpwBE?origin=lprLink](https://forms.office.com/r/TAr28SpwBE?origin=lprLink)

🔗 Challenge Link:

[https://learn.microsoft.com/training/challenges?id=18cbff95-6b28-489f-b346-9b2648684292&WT.mc\_id=cloudskillschallenge\_18cbff95-6b28-489f-b346-9b2648684292&wt.mc\_id=studentamb\_209465](https://learn.microsoft.com/training/challenges?id=18cbff95-6b28-489f-b346-9b2648684292&WT.mc_id=cloudskillschallenge_18cbff95-6b28-489f-b346-9b2648684292&wt.mc_id=studentamb_209465)

📧 Event Support:

Encountering challenges or have questions about the event incentives send an email to:

[nirmal.chandrasiri@studentambassadors.com](mailto:nirmal.chandrasiri@studentambassadors.com)

🚀 Don't miss out on this incredible opportunity to learn and earn fantastic rewards! 🙌🏻

\#Sweepstakes #Azure #AI",Code-Squad,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/183k6r2/azure_ai_cloud_skills_challenge/
271,1700904257.0,I'm trying to prepare a cool presentation for high school students. Any advice?,"Hello r/learnmachinelearning! I come to you in a time of great need.
I'm a phd student in deep learning, and i need to prepare a laboratory on neural networks for my university open day.
Around 200 high school students are attending. They chose the topic so they are (at least in principle) interested.

It's going to be structured like this:
- a 45 min presentation about neural networks, explaining the basics and how they work
- 1:30 hands on session on tensorflow playground, Teachable machines, etc.. with various challenges
- 15 minutes for questions 

The problem is: I want it to be fun and engaging, but i'm afraid that the presentation might bore them.
I'm trying to spice it up with fun/cool examples like the network struggling with dogs and cupcakes, but i'm running out of ideas.

Do you know any other cool thing that i could show to keep them entertained? 
Any help is much appreciated!",Willinki7,2,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/183g1b5/im_trying_to_prepare_a_cool_presentation_for_high/
272,1700903887.0,Positive and Negative Sentiment Analysis with results only in 1 class?,"I have a movie review dataset worth 50K rows where it has two columns: Label and Text. The label is either 0 (negative) and 1 (positive).

Goal: Predict sentiment if it's 0 or 1 when a user inputs a text.

Did the data preprocessing, using of stop words, balancing of word count, and the count of negative and positive texts are in 50/50 proportion along with other data cleaning. I tried using LSTM and BERT approach (uncased 110m) model to train it. The results are always the same. The F1 and recall scores show it has high accuracy on detecting the first class, but the second class has 0.00 scores literally. 

For those who have encountered this doing sentiment analysis, what is the usual reason?",vlodia,2,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/183fy99/positive_and_negative_sentiment_analysis_with/
273,1700884864.0,First Time Working With Machine Learning,"Hello all,  
I am a new developer trying to get into the field of Machine Learning. For my first project I am trying to tune an LLM (have not decided which one yet, but it will be open source) from a bunch of text articles online. I want the LLM to produce more accurate and detailed results on a certain niche topic. So far I have collected the data in a large text file and cleaned the data (lower cased, removed punctuations, standardized the spacing, removed proper nouns,  and Lemmatized). I have also tokenized the data at sentence level, as I believe this will maintain more of the context and jargon of the writings.   
From Here I am a bit lost. After tokenizing the data what should I do? Should I embed the data? I already tried with fasttext, but it made my file significantly larger. I used both the English Crawler and Wikipedia Versions. Also is it possible to mix the two embedings? Furthermore I am wondering how would I go about doing this without labeling data, since it seems odd to do this with such a large file manually. How would I do MLM or NSP?? Also If I do MLM or NSP, do I no longer need to embed the data into vectors?? Also how exactly should my text files look like before and after embedding and or doing MLM/NSP?  
Thank you and Happy Thanksgiving weekend!",Need_More_Learn,5,1.0,6,https://www.reddit.com/r/learnmachinelearning/comments/183b02m/first_time_working_with_machine_learning/
274,1700877417.0,1 training image for facial recognition,"Is it theoretically possible to have a model that only requires 1 training image of a person to accurately identify the person?

I mean if you think about it, with us humans, we’re usually pretty good at being able to match a name to a face after just one interaction with the person

Either this is a perfect example of how AI won’t ever beat humans in certain aspects, or there does exist a model that can accomplish this task (which I believe exists considering that human consciousness itself can be modeled mathematically)",WannaChai,7,0.89,19,https://www.reddit.com/r/learnmachinelearning/comments/1838kwa/1_training_image_for_facial_recognition/
275,1700898507.0,Decision tree,Does the order matter in a decision tree or can the nodes be placed in any order?,Traditional_Soil5753,2,1.0,6,https://www.reddit.com/r/learnmachinelearning/comments/183enoc/decision_tree/
276,1700884687.0,Target is a range of values,"How do I train a model where each target is an interval of values?  Any value within the interval can be considered correct, and errors are punished differently depending on where they fall in relation to the interval.  The below illustration should explain what I'm working with:

&#x200B;

<---all\_equally\_incorrect\_zone----|----sweet\_spot---|--further\_from\_the\_sweet\_spot\_is\_worse\_zone---->

&#x200B;

Also, some intervals are completely empty.",chilltutor,3,0.81,6,https://www.reddit.com/r/learnmachinelearning/comments/183ay26/target_is_a_range_of_values/
277,1700898961.0,"Albumentation: Auto-annotations, yolov8","""\[D\]""

&#x200B;

Good day everyone!  

I'm currently doing albumentation to images that already have annotations for yolov8 object detection. After image augmentation, I'm really having a hard time recognizing the image thus making the annotation of the transformed images very very hard.  

Since the original image already have annotations, is there any way to refer to the original annotations to automatically transform them the way the images are transformed?  

Thanks in advance!

&#x200B;

 ",kelpiegmng,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/183erds/albumentation_autoannotations_yolov8/
278,1700896152.0,System to run ML Code,"New to ML here. I need to run a deep learning code written in Python using the tensorflow library. 


Do i use any special systems for this? What specs do I need",Advanced-Prune-6277,0,0.33,4,https://www.reddit.com/r/learnmachinelearning/comments/183e3ao/system_to_run_ml_code/
279,1700890807.0,Need help is tutoring for Google professional machine learning Exam (PMLE). Let me know if anyone can help. Willing to pay,,Glittering_Shirt1311,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/183cp75/need_help_is_tutoring_for_google_professional/
280,1700858863.0,I don't think I'm using HuggingFace Inference Endpoints properly,"I've created a HF Inference Endpoints for translation, in particular french->english. This is the setup

* **Instance type:** GPU · Nvidia A10G · 1x GPU · 24 GB
* **Model:** [Helsinki-NLP/opus-mt-fr-en ](https://huggingface.co/Helsinki-NLP/opus-mt-fr-en)
* **Container:** default

I have 2k documents to translate and I'm using python package `request,` together with `concurrent` to fire multiple HTTP POST request to my endpoint. Each document should have 100-300 sentences and I wasn't able to translate them as they were, so I split each document in 6 section.

Checking the usage of the machine, I realise I barely use any resource in terms of CPU/GPU. Also, after a while, some requests start failing.

I'm quite sure this could be much faster and could process more text all together, but I can't understand how to do so. My data is in a pyspark dataframe: I first tried with an UDF (and it was a terrible idea), now I'm creating a list of documents and use that as input.

Here's the code I'm using

    def translate_text(text):
        payload = {""inputs"": text}
        headers = {""Authorization"": f""Bearer {API_TOKEN}"", ""Content-Type"": ""application/json""}
    
        try:
            response = requests.post(API_URL, json=payload, headers=headers)
            response.raise_for_status()
    
            if response.status_code == 200 and response.text:
                response_data = response.json()
                translated_text = list(map(lambda x: x.get(""translation_text""), response_data))
                return translated_text
            else:
                print(""Translation response is empty or not in JSON format."")
                return None
    
        except requests.exceptions.RequestException as e:
            print(""Request error:"", e)
            return None
    
        except requests.exceptions.JSONDecodeError as e:
            print(""Failed to decode JSON response:"", e)
            return None
    
    def translate_text_dict(text_dict: dict) -> dict:
        output_dict = {}
    
        with concurrent.futures.ThreadPoolExecutor() as executor:
            results = executor.map(
                lambda args: (args[0], list(map(translate_text, args[1]))), text_dict.items()
            )
    
            output_dict = dict(results)
    
        return output_dict

the input dictionary has, as key, an unique id and, as value, the list of sentences to translate. Could this be improved?",Stewiejobs90,5,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/1831oqu/i_dont_think_im_using_huggingface_inference/
281,1700872286.0,Open Source Code for Training/Fine-tuning > 20B LLM,"Hello,

I want to train large language models, specially using deep-speed. Is there any well known open-source code for that?",rodeowrong,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/1836son/open_source_code_for_trainingfinetuning_20b_llm/
282,1700846634.0,How to make your model classify text to two classes simultaneously,"Hello, Let's say i have a medical question that can be classified into two medical specialties, for example a question can be answered by an ""Oncologist and a Dermatologist"", while some other texts should only be classified to one class for example a ""Dermatologist"" only, how should I do that?
And how should my dataset be, it contains some labels that mention ""Oncology - Dermatology"" and others mention ""Oncology"" , ""Cardiology""... Keeping these makes a lot of classes (120 class)  

I'm new to NLP and I haven't found the exact name for this case so that I can google it.
Thank you in advance.",skillmaker,7,0.89,7,https://www.reddit.com/r/learnmachinelearning/comments/182x5y1/how_to_make_your_model_classify_text_to_two/
283,1700879200.0,coursera machine learning specialization by andrew ng,from where i can find unsolved labs for coursera machine learning specialization by andrew ng,ahmedYehia89,0,0.33,0,https://www.reddit.com/r/learnmachinelearning/comments/18396ww/coursera_machine_learning_specialization_by/
284,1700847128.0,Super-resolution in TensorRT for faster image and video upscaling,"Hello!

As a high school student studying in computer sciences, I recently undertook a project to develop a  small command line program for using waifu2x models with TensorRT. It's aimed at boosting inference speed on Nvidia cards and supports both image and video upscaling. 

I mainly wrote this as a learning experience, but I think it turned out pretty good. I've been working on it on and off for a bit now, and there are still a few missing features that I plan on adding when I have the time, but feel free to give it a try! Contributions and feedback are most welcome. 

I've included a link to a reference for TensorRT integration in C++ in the acknowledgments section. 

[https://github.com/z3lx/waifu2x-tensorrt](https://github.com/z3lx/waifu2x-tensorrt)",z3lx_,3,0.81,0,https://www.reddit.com/r/learnmachinelearning/comments/182xc86/superresolution_in_tensorrt_for_faster_image_and/
285,1700852351.0,Clustering Images for Labeling Question.,"I’m trying to figure something out.  I’ve got Yolo working well for a specific case, now I’m wondering if I can split out a current detection class into multiple others without having to relabel everything manually.

For Example, let’s say I can detect a car, but now I want to detect “red car” and “blue car”.   Has anyone had any luck with labeling a small number of samples and then using clustering to label the other samples?  I’m not quite sure how to go about this.

FYI I realize that a pure color method could be implemented using openCV, but I just chose this example to demonstrate the intent.

Thanks for any input on if you’ve implemented something similar and if it worked.",someone383726,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/182z9a9/clustering_images_for_labeling_question/
286,1700821633.0,Roadmap for career/job in data science field ( Newbie )," Hello guys, I'm a newbie in the field of data science. Right now I'm pursuing my bachelor's in computer science engineering. And till now I've entered the domain Started with Python and SQL language And moving on to machine learning ( following Andrew NG's courses course I'm on the last part which is unsupervised learning ) And I've worked on small projects Titanic prediction, credit card fault detection And right now I'm working on a stocks & crypto price prediction model ( as my minor project ) I've planned to enhance it shortly integrate it with the front end and make it deployable ( which I'm gonna show as my major project )

So you guys know where I stand No prior experience I'm applying for it but no success till now The ones I get are virtual internships which I don't think are worthy like the CodSoft one ( yeah I did that :( ) Really wanna move forward any suggestions or roadmap for me like what should I do or anything I missed I should do before moving ahead you know like my lagging area so that my resume also gets shortlisted for either the DATA ANALYTICS OR the MACHINE LEARNING role. And I was thinking to start learning Power BI as well what do you guys think should I go for it? I mean is it helpful for me that I get a job or a real Internship( not a virtual one 😕 )?

Anyways Help would be appreciated. Thank you!!",Potential_Zone1522,9,0.91,0,https://www.reddit.com/r/learnmachinelearning/comments/182p6q6/roadmap_for_careerjob_in_data_science_field_newbie/
287,1700817129.0,Need ML project ideas,"Hello

I am a master's degree student in the AI specialty. My bachelor's was on the same topic. IMO my level is near the jun/strong jun ML engineer(checked by different *what-the-name*\_level\_ML\_engineer\_need\_to-know sites. I work on a strong junior software dev position(iOS). Can you give me ideas about the pet project ideas and ML algorithms that I can put in the CV(that will be good to for the middle-level ML engineer)?",No_Bench_6923,8,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/182o5zl/need_ml_project_ideas/
288,1700851668.0,Quiz Bot based on Machine Learning Interview book by Chip Huyen,"Getting ready to interview or just want a more interactive way to learn? 

I made a [GPT-based tutor](https://chat.openai.com/g/g-4CPfBqlVc-machine-learning-interview-tutor)  using a Custom GPT based on Chip Huyen's excellent ""[Intro to Machine Learning Interviews Book](https://huyenchip.com/ml-interviews-book/)"". (Note: it's entirely free, you'll just need a ChatGPT subscription.)

Please let me know what you think. Hope you find it helpful!",Accomplished_Term23,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/182z01u/quiz_bot_based_on_machine_learning_interview_book/
289,1700850762.0,"I'm trying to set up a simple chatbot for an NLP project, but responses are incoherent. I'm not sure that I'm' training the model correctly.","For example, here is a sample convo

Enter Your Name: James

Welcome to Chatbot Service! Let me know how can I help you

James: Hi!

Bot:  everything's been good with you? i haven't been better. how about yourself?

James: I am doing well

Bot:  That is good to hear

James: What are you doing today

Bot:  i'm doing great. what about you? i'm absolutely lovely, thank you.

James: What is your favorite movie

Bot:  that was my favorite class. you have got to be talented.

James: What class are you talking about

Bot:  of course they talk to each other. what do they talk about?

James: They gossip about horrible things

Bot:  i feel the same way. it smells so good after it rains. i especially love the night air when it rains.

James: quit

Bot:  well, she's quite short. how tall would you say that she is?

James: bye

Bot: Bye

Here is the code I have 

    import numpy as np # linear algebra|
    import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)


    from chatterbot import ChatBot
    from chatterbot.trainers import ListTrainer
    from chatterbot.trainers import ChatterBotCorpusTrainer
    import os

    import collections.abc

    collections.Hashable = collections.abc.Hashable
  
    bot = ChatBot('Buddy',
            logic_adapters=[{
            'import_path': 'chatterbot.logic.BestMatch',
            'default_response': 'I am sorry, but I do not understand.',
            'maximum_similarity_threshold': 0.90
        }],
            read_only = True,
            preprocessors=['chatterbot.preprocessors.clean_whitespace',
                        'chatterbot.preprocessors.unescape_html',
                        'chatterbot.preprocessors.convert_to_ascii']
                        )


    directory = 'kaggle'

    for filename in os.listdir(directory):
      if filename.endswith("".txt""): # only pick txt file for training
        print('\n Chatbot training with '+os.path.join(directory, filename)+' file')
        training_data = open(os.path.join(directory, filename), 'r', encoding='utf-8').read().splitlines()
        trainer = ListTrainer(bot) # bot training
        trainer.train(training_data)
      else:
        continue


    decision = input('Train chatbot with English corpus data? (Y/N): ')

    if decision == 'Y':
      print('\n Chatbot training with English corpus data')
      trainer_corpus = ChatterBotCorpusTrainer(bot)
      trainer_corpus.train('chatterbot.corpus.english')



    name = input('Enter Your Name: ')

    print ('Welcome to Chatbot Service! Let me know how can I help you')

    while True:

      request = input(name+': ')

      if request==""Bye"" or request=='bye':
        print('Bot: Bye')
        break
      else:
        response=bot.get_response(request)
        print('Bot: ', response)",darkLordSantaClaus,1,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/182yo61/im_trying_to_set_up_a_simple_chatbot_for_an_nlp/
290,1700797306.0,What is Quantum machine learning ?,"As title portrays the topic of discussion, wondering what is ""quantum machine learning"" in easy words. How does it outperform classical Machine learning? What are the pros and cons of using it. What are its considerations and is it used in real life use cases to address the available problems. What are your bits of thoughts on it.",JordaarAce,16,0.86,15,https://www.reddit.com/r/learnmachinelearning/comments/182ipt3/what_is_quantum_machine_learning/
291,1700769706.0,Language models feel so inefficient for me,"For all designs I know in my life, this box of a neural networks feels something of inefficient. Specially for language models. 

Everytime you calculate a word as output you have to generate the probability for the whole dictionary. And that after going through billions of parameters. And the memory cost when you want a larger context is ridiculous.

For the first chatgpt I remember reading somewhere that one prompt could cost as high as 100 times more energy what web search costs. 

I sometimes am fascinated how efficient the human brain is. When we are asked a simple question we don’t burn a lot of energy to answer that. I mean all that with the disadvantage of not having a large knowledge base.

Anyways, just wondering. If I got one of my assumptions wrong I d really appreciate the insights.",besabestin,54,0.88,31,https://www.reddit.com/r/learnmachinelearning/comments/1829m0y/language_models_feel_so_inefficient_for_me/
292,1700828959.0,What curve can I fit or what model can I train?,"I have a dataset of two column values something like the one shown below. I need to predict the values of y for values of x greater than 60. The curve must follow the increasing trend it is shown till x=60.

I have tried polynomial regression and SVR but it declines for values greater than 60. I have tried to fit the curve y = alnx + b to this curve but the R2score is 0.94. What model can I train for this purpose, or how can I improve the R2score but regressing over an appropriate logarithmic function?

https://preview.redd.it/4ls08i2jha2c1.png?width=1208&format=png&auto=webp&s=744498301cd046ed703357415cb581d391433c06",ninadsutrave,2,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/182r1xz/what_curve_can_i_fit_or_what_model_can_i_train/
293,1700799048.0,Resources for Deep learning,"I am a CS graduate. I didn't have DL course in my curriculum. I have started learning Deep learning mainly using Andrew Ng's videos. I understand the concepts. But I forget the concepts and terms after sometime. I don't have this problem with other courses in CS. 

I want to learn DL thoroughly so that I can build my own models for different applications. Can someone suggest a resource that covers the basics well and has lots of hands-on materials. 

Any help us very much appreciated.",thaaat_one,9,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/182j8iw/resources_for_deep_learning/
294,1700840556.0,[Discussion} Is it possible to built a Multi-LLM Assistant?," 

  
For example with the following structure:

* System = GPT-4 Turbo + Llama2 +3rd LLM (!)+ Google or Bing API for websearch + Langchain + any vectorDB + Document upload + longterm Memory + …

Idee behind it is to get more accurate, updated (websearch) and specialized system or even let the LLms discuss your prompt before completion! Question is also, how shall the interaction of multiple LLMs in a system be organzied (Algorithm, Python Library …)? And what kind of Interaction can/should this be? Master-slave or Multi-Master system?",SykA196286,0,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/182uw4r/discussion_is_it_possible_to_built_a_multillm/
295,1700835994.0,Design a neural network,"I need to design a neural network to solve the following problem: 
I have input data that is a string of characters, for example: 
```
train_data = [
    [""a"", ""x"", ""n""],
    [""f"" ""m"",""l"",""v""],
    ...
]
```
label is a vector of the form: 
```
label = [
    [
        [0.55,0.26,0.34],
        [0.12,0.15,0.45]
    ],
    [
        [-0.68,- 0.25,0.84],
        [0.14,0.52,0.46],
        [-0.64,-0.15,0.89],
        [0.15,0.96,0.24]
    ],
    ...
]
```
 with different vector sizes.",Ok-Lie1198,0,0.33,0,https://www.reddit.com/r/learnmachinelearning/comments/182t9h4/design_a_neural_network/
296,1700790595.0,Probabilistic Machine Learning: an Introduction by Murphy. Is it a good book?,"Hello everyone. I was wondering if anyone could point me in the right direction with this. I'm trying to learn the theory and math behind the algorithms of ML and DL, and I was really attracted towards the ""probabilistic view"" and thus thought I would give this book a go based on the reviews. However, I'm wondering if this is the right decision. I've been reading some parts of the book, and I'm not sure how well it explains the concepts, as it does feel a little ""encyclopedic"" some times. Is this the case? What would you recommend doing with my goal in mind? Any other books that are up to date? Thank you in advance",Intelligent-Notice66,8,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/182gn0y/probabilistic_machine_learning_an_introduction_by/
297,1700813464.0,Running EM algorithm on BN when I do know exactly some CPTs," Hi there, i'm sorry about this  question that may seem so dumb or obvious. I'm currently studying  bayesian networks after long time not touching books.

I  have a dataset with some features and i built a BN representing  dependencies. Suppose the BN is this in the photo. All the variables are  discrete. The latent variable not appearing in dataset is `_designer_taste`. Also, suppose that i do know cpts of `page_menu_or` and `page_ungrouped_multim`.

Now,  my goal is to obtain all the others cpts, including the cpt of the latent variable. Is this correct and achievable by running EM?

https://preview.redd.it/2o56l55k792c1.png?width=566&format=png&auto=webp&s=47084e3ebf767a7896db997463dc86bc1b795341",-NeutralE,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/182n9w1/running_em_algorithm_on_bn_when_i_do_know_exactly/
298,1700821950.0,Pytorch has a deprecated attribute despite being up to date,"I'm using pytorch 2.1.1 and fastai 2.7.13. Yet everytim I run my code I get the error that states that 
    'has_mps' 
has been deprecated and I'm to use
    'torch.backends.mps.is_built()' 
instead. Do I need to go back to an older version of fastai or Pytorch?",Aeiexgjhyoun_III,0,0.5,6,https://www.reddit.com/r/learnmachinelearning/comments/182p9kp/pytorch_has_a_deprecated_attribute_despite_being/
299,1700868731.0,I was today years old when I learned my hard drive could rot...,"Is this true? 

I understand drives can corrupt. However this is the first time I have ever read that time can also wear down the file quality.",Great_idea_fellow,0,0.13,3,https://photostructure.com/faq/how-do-i-safely-store-files/
300,1700813996.0,Validation images for facial recognition,"Can someone fully explain the purpose of validation images in a facial recognition project?

Is it just for the programmer to verify that the ML model is correctly identifying the person?",WannaChai,1,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/182nei0/validation_images_for_facial_recognition/
301,1700813767.0,Machine Learning PC Lower-Mid budget,"Was hoping to build a PC with a budget of around $3000 primarily for ML study. After doing a bit of research into GPU's I tried to get the price of the GPU to around $1000 or so which left me with an RTX 4070 or 3070 Ti.Should I be allocating more of the budget to a slightly better GPU?  
Any advice/reccomendations for the GPU and all other parts is appreciated (Don't need any peripherals).  
And yet another question. Should I go with Linux?

Edit: Living in Australia",Tritops_is_bis,0,0.5,2,https://www.reddit.com/r/learnmachinelearning/comments/182nchs/machine_learning_pc_lowermid_budget/
302,1700827305.0,"How I made a custom GPT | With web search, knowledge database and character personas",,Complex-Indication,0,0.33,1,https://www.redgifs.com/watch/substantialcurvyleafwing
303,1700798186.0,Logistic Regression Model,"Hi I'm learning Logistic Regression and tried to make a model based on the dataset here: [https://www.kaggle.com/datasets/devanshibavaria/water-potability-dataset-with-10-parameteres/data](https://www.kaggle.com/datasets/devanshibavaria/water-potability-dataset-with-10-parameteres/data), but my accuracy is terrible and I have no idea how to fix it. could anyone take a look?

here is the link to my colab:

[Colab](https://colab.research.google.com/drive/12WP_WbLIOo2VScur2FBDbxbWz8ux3frC?usp=sharing)",EducationalAd5827,2,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/182iz4k/logistic_regression_model/
304,1700796514.0,Training a model in Azure ML,"Hey

I recently made a multi-label classification data set using Python's sci-kit-learn model. I'm gonna train it in Azure ML with API call ( Let the computer train it by itself.) The precise definition of dataset looks like this: a sm

All input features, specifically less than five, offer three multiple binary output labels (Yes/No answers), which classify the inputs into distinct categories. 

There are the questions: 

Is this created dataset valid for training it? 

If it is not, what recommendation do you have? 

How many records do I need to include in order to train properly? 

or 

How many records do I need to include to train correctly? 

&#x200B;

Thanks!!!

&#x200B;",appearntlyhappy,2,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/182ih72/training_a_model_in_azure_ml/
305,1700735040.0,"Nonfiction authors sue OpenAI, Microsoft for copyright infringement",,anujtomar_17,40,0.84,34,https://newyorkverified.com/4324297-nonfiction-authors-sue-openai-microsoft-copyright-infringement/
306,1700764942.0,Cheap Cloud platforms for running heavy AI Models?,"I am about to buy a new laptop for Friday, and since I am a Data Scientist (who will start working more on Gen AI projects soon) initially I wanted to buy a gaming laptop since it has powerful GPU, Processor and RAM. But on more research (especially in this sub), I realized that cloud is always better than laptop for heavy AI work. Thus, I don't want buy a gaming laptop anymore since they are heavy and heat up so much. I am ok with something like a MacBook air, based on my budget of 1200$. 

My main question now is what's a good cloud service that can run my heavy AI Models? 1 option I found is Google Colab Pro, but is it good enough?",Snoo_72181,6,0.88,7,https://www.reddit.com/r/learnmachinelearning/comments/1827y2p/cheap_cloud_platforms_for_running_heavy_ai_models/
307,1700786135.0,Template Matching with OpenCV,"Template Matching with OpenCV

[https://debuggercafe.com/template-matching-with-opencv/](https://debuggercafe.com/template-matching-with-opencv/)

&#x200B;

https://preview.redd.it/dlji65ndy62c1.png?width=1000&format=png&auto=webp&s=3521475a323c1ddb35c7721dea84d0cbcdade247",sovit-123,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/182f8uq/template_matching_with_opencv/
308,1700766278.0,Black box problem of ML: Current advances? [D],"We all know that ML is widely a black box, I know about strategies such as Gradient visualisation, SHAP/LIME - but like what are some SoTA strats when it comes to transparency in models, specifically LLMs?",Ok_Reality2341,5,0.78,1,https://www.reddit.com/r/learnmachinelearning/comments/1828fj0/black_box_problem_of_ml_current_advances_d/
309,1700757780.0,User friendly digital audio signal processing,"Hello, the faculty of music at my university in Norway has been granted a lot of money to focus on the use of technology in music and music education. I have been accepted into a position focusing on AI in music. I am first and foremost a musician, so i am working on getting a fundamental grasp on machine learning.

I was wondering if you know of any website or software that can be used to train a signal processing model. The idea being that i can give an unprocessed signal and a processed signal and have mode learn the differences. Like a guitar playing without a distortion pedal and with one. Thank you very much. If there are any misconceptions in my question please help educate me.",Seb1234123,6,1.0,6,https://www.reddit.com/r/learnmachinelearning/comments/18259h0/user_friendly_digital_audio_signal_processing/
310,1700766902.0,"So Regression (Prediction) Models Rely on having a set of features inputted as X, then choosing the Target As Y?","New here, but just wondering how that is possible. from the top of my head, it's like you're shoving a bunch of variables into one big variable X, then all the variables do a decision tree within X and ""democratically vote"" on an output, then that output is Y? ",Nixtivo,3,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/1828n4z/so_regression_prediction_models_rely_on_having_a/
311,1700773620.0,XAUUSD machine learnkng,"Hey there, found this sub and thought I would ask about an idea I had.

I as thinking of compiling daily data for Gold where I include date, price change over 24/48/72 hours, volatility(atr) over 24/48/72 hours, RSI over 24/48/72 hours, Stop Losses, Take Profits, and then the predicted variable which would be a 0 if over the last 24 hours it profited from a short or 1 if it profited from a long. I doubt i will end up using all these features but want to see where there is confluence between them. At the end of the day I know markets are volatile and almost random, but since i am not predicting price and rather predicting a binary variable I thought I might be able to use random forest or an other algorithm and it would be able to predict a 0 or a 1 for the next 24 hours. Since this would still be not perfect I would most likely use this prediction to reinforce manual decisions. I wanted to propose this before I did anything because compiling the data manually will take me a while and wanted to see if there is a point.",MatthieuDurieux,2,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/182ay3k/xauusd_machine_learnkng/
312,1700770379.0,SVD vs CNN for object recognition,"CNNs has been mostly used for the tasks of object recognition, detection and classification (as far as I know).

I have been searching for some time, but I can't, for the life of me, find the comparison of Singular Value Decomposition and Convolutional Neural Network methods for computer vision.

Could anyone, please, provide links to some research papers where this issue is tackled or explain it with some sources?

Or am I just incorrect in my statement that CNNs are better for computer vision than SVD? Any help is appreciated",Pewluigi,2,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/1829u8g/svd_vs_cnn_for_object_recognition/
313,1700781906.0,"Best Mathematics books for Machine Learning, Data Science -",,Lakshmireddys,1,1.0,0,https://codingvidya.com/best-mathematics-books-for-machine-learning/
314,1700744983.0,"Has anyone read ""A Brief History of Artificial Intelligence""?","In this book the author [Michael Wooldridge](https://en.wikipedia.org/wiki/Michael_Wooldridge_(computer_scientist)) lists tasks *""at present we have no idea how to get computers to do""*. He states these tasks are **""nowhere near solved""** in the world of artificial intelligence

* Understanding a story and answering questions about it
* Human-level automated translation
* Interpreting what is going on in a photograph
* Writing interesting stories
* Interpreting a work of art
* Human level general intelligence

This book was written/published in 2021. ChatGPT has been out for almost two years now, a year after this book was published.

However doesn't ChatGPT do most of these things? And if not ChatGPT, other AI systems like DALL-E.

How is it possible AI achievements have grown so quickly to the point most of the things seen as ""nowhere near solved"" were ""solved"" almost a year or two later?",,6,0.72,8,https://www.reddit.com/r/learnmachinelearning/comments/1820v4w/has_anyone_read_a_brief_history_of_artificial/
315,1700764543.0,Imputation using median values,"I’m using pandas median to calculate the median of the values in a dataframe column and I see the values are not sorted, when I apply the .median() function assuming it automatically sorts the data then calculate the median, I notice it doesn’t .

Median in statistics is calculating middle value after sorting the data in ascending or descending order.

Does this not apply for imputation of missing values using median ? Or should I sort and then apply the median ?

Thanks!",tinkerpal,2,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/1827sy4/imputation_using_median_values/
316,1700753528.0,12 Best Online Courses for Machine Learning with Python- 2024,,Aqsa81,3,1.0,1,https://www.mltut.com/best-online-courses-for-machine-learning-with-python/
317,1700752331.0,Experienced Software Engineer/Data Engineer breaking into ML,"I have 10 years of experience doing backend software engineering and 4 of those being more closely aligned with being a data engineer. I currently work on a data platform that pulls data from multiple sources related to Payment information for my company.

Currently, the extent of my job is to build the E2E process of retrieving data from a few dozen sources, sanitizing it, applying some basic transformations, and putting it somewhere that our data users (data analysts and ML team) can easily access. We use Spark notebooks running in Databricks orchestrated in Azure ADF. We provide the data through an OLAP cube, Delta Lake tables, and raw parquet files.

All of the data I have is for successful payments made to the company across several different products, regions, etc. I was hoping to start to lean more into the side of analyzing the data instead of just providing the data to our users.

For example, a business use cases I thought of was to use ML to predict which processed payments have a high risk of being fraudulent. I work at a large enterprise tech company so the fraud team already catches a lot of this stuff and I can get the data that labels which payments we processed that turned out to be fraudulent. My thoughts were to train an ML model on data that indicates which payments were in fact fraudulent to predict what payments that aren't currently marked as fraudulent as potentially being fraudulent.

I am totally new to the ML space. I'm trying to focus on one specific use case for my learning instead of getting overwhelmed with all things ML/AI. What resources do you recommend I learn about to get up to speed to implement the model for learning/predicting fraudulent payments? ",xNRVNA,3,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/18239ot/experienced_software_engineerdata_engineer/
318,1700771721.0,Classification of shirt numbers [P],"Hi! 

I'm trying to create model that is able to recognise the shirt number of soccer players.

What I'm doing is: starting from a match video  extracting the frames and from the frames extracting the the bust of the players. 

I can do this because I have the players coordinate.

After, manually, I select the images ( I choose 45x65 pixel) where a clear number is present and I divided the different numbers in different folder. Each folder has the data of a class.

In each class I can have players with the shirt number that is white or black.

After this partition I created a .CSV and used random forest from scikit learn to create a model.

The accuracy I get is around 0.78. I also tried to use grey scale and negative mask to have the numbers of the same colour.

But the output is still not that high. And if I use the model to classify a image, when I get the right output the model shows the confidence pretty low, around 25%.

So do you have any advice? What could I do to Improve the model? 

Should I use a different approach? 

Thanks :)",TonyCartoon,1,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/182aa8n/classification_of_shirt_numbers_p/
319,1700759969.0,Distil-Whisper Explained - The most recent AI Voice-to-Text Technology!,,OnlyProggingForFun,1,0.6,1,https://youtu.be/SZtHEKyvuug
320,1700703019.0,Created a plastic object detection model using AWS technologies 🌍🤖,"[https://github.com/akkik04/GreenGuardian](https://github.com/akkik04/GreenGuardian)  


Leveraged AWS Sagemaker and associated cloud technologies to create 'Green Guardian', a deep learning object detection model achieving a mAP score of \~0.7, trained on images retrieved from Google's Open Images Dataset V7. Designed to contribute to a greener environment by accurately detecting and highlighting plastic objects within images.  


Let me know what y'all think! 👀",akkik1,11,0.87,1,https://www.reddit.com/r/learnmachinelearning/comments/181pk3c/created_a_plastic_object_detection_model_using/
321,1700701109.0,What's the best place to start for a seasoned software dev?,"So I have about 10 years experience in software development, frontend, backend and mobile. I would say I am fairly proficient. I've used Python pretty extensively, though haven't really used Pandas, Tensorflow, PyTorch or SciKit to a great extent.

I'm college-educated but in a non-STEM-y major, so I only took Calculus 1 and Statistics.

It's very apparent that ML/AI is going to be pretty transformational going forward.

What is the best path for me to learn how to do ML/AI?

I've looked into this a decent amount before, and have done a workshop in the past.

I assume I will need to learn Linear Algebra, Calculus III (and possibly II, in case III builds on any concepts in it).

Is there anything else that someone of my particular background should be aware of?",burritolittledonkey,12,0.88,12,https://www.reddit.com/r/learnmachinelearning/comments/181oxs0/whats_the_best_place_to_start_for_a_seasoned/
322,1700711207.0,Where to begin as an experienced web developer?,"I’m your average run of the mill dev and I’d like to learn the basics of ML. I’d like to train a model on NBA games/statistics and see if I can come close to Vegas odds at predicting outcomes.

My Ruby On Rails experiences leads me to believe I should model this “domain” with Player, Games, PlayerGame, Team, etc tables and then begin collecting data regarding games (I think I’m going to spin up a Django app and then scrape all this data)

Once I have data where should I go to learn how to build and train a model? Are there any gold standard tutorials for folks who know how to code but are relatively green when it comes to ML?",jaypeejay,5,0.86,4,https://www.reddit.com/r/learnmachinelearning/comments/181s59o/where_to_begin_as_an_experienced_web_developer/
323,1700741797.0,How is RadiusNeighborsClassifier better for imbalanced data compared to KNeighborsClassifier?,"I'm working my way through **Introduction to Machine Learning with Python** by *A. Muller*, and it's super fun. Going through the first chapter, I had a look at the User Guide for `KNeighborsClassifier`, linked [here](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification).   


I noticed that they have said the below:

>In cases where the data is not uniformly sampled, radius-based neighbors classification in RadiusNeighborsClassifier can be a better choice.

I do not understand how it's better. 

They are talking about imbalanced data. Imbalanced data is going to be imbalanced regardless of where you look (at least most of the time), right? 

* If we consider the nearest K number of neighbors of the input data, it will most probably be skewed as the whole dataset is imbalanced. 
* Same as the above, if I was going to consider all the data points within a radius, even then that sample is going to be imbalanced, speaking from common sense. 

In the end, we are simply going to choose the most frequent class from the above samples. So what difference does choosing either of those two methods make?

So how can you say that RadiusNeighborsClassifier is better for imbalanced data compared to KNeighborsClassifier?",lebanine,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/181zy59/how_is_radiusneighborsclassifier_better_for/
324,1700717112.0,Sklearn One hot encoder not removing string column,"&#x200B;

https://preview.redd.it/mt699qy3912c1.png?width=631&format=png&auto=webp&s=3ee0ee9474f0707200516cb9e46de92e0920f690

Shouldn't One hot encoder (OHE) get rid of that first column?

&#x200B;

I am working on the House Price Prediction dataset and I am getting a strange error with OHE, it keeps the original categorical variable, along with the encoded columns. Here is the code I used

&#x200B;

`train_df = pd.read_csv('train.csv')`

`x_df = pd.DataFrame(np.array(train_df['MSZoning']).reshape(-1, 1))`

`cols_mapper = dict()`

`cols_mapper[0] = 'MSZoning'`

`x_df = x_df.rename(columns=cols_mapper)`

&#x200B;

`ct = make_column_transformer(`

`(categorical_imputer, ['MSZoning']),`

`(OneHotEncoder(handle_unknown='ignore'), ['MSZoning']),`

`remainder='passthrough')`

&#x200B;

`enc_x = ct.fit_transform(x_df)`

`enc_x`

&#x200B;

&#x200B;",ng_guardian,3,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/181tt6v/sklearn_one_hot_encoder_not_removing_string_column/
325,1700679916.0,Made some promises. Now I'm desperately trying to figure out how to conduct very large scale pdf doc analysis.,"I have about a half million pdfs I need to summarize. Very wide range of types: invoices, diagrams, contracts, emails, letters, pictures, schedules, notices, data sheets, manuals, more. 

Which is... woof. Something else. I've been trying for many hours now to figure out a service/combination thereof that can get me there, but I'm seriously struggling. The *ideal* solution would be to throw the pdfs in and have it return a csv with dates and summaries, maybe parsed out email heading info.

I'm currently running these pdfs through Acrobat OCR now, which its own special hell.

I've tried myriad local and webhosted solutions. The BEST results in what is almost the perfect system for this I found on https://docalysis.com/. Good text results, works in batches, BUT I can only upload a single document at a time. They have a service to do batch processing and so I'm waiting to hear from them now. I imagine at the scale I need it's expensive.

I also got this solution working: https://github.com/mayooear/gpt4-pdf-chatbot-langchain. Seemed solid, I was able to upload a thousand pdfs in a single go, but it would keep returning information from only 2-3 documents. Upload 5? Results for 2-3. Upload a thousand? Results for 2-3. My uneducated guess is that it's hitting the OpenAI API token limit, but maybe not?

I know it's possible, just not whether it's feasible for an end user. Does anyone know a solution to accomplish this?",-rampant,14,0.94,11,https://www.reddit.com/r/learnmachinelearning/comments/181gxg0/made_some_promises_now_im_desperately_trying_to/
326,1700714685.0,Fast Llama 2 on CPUs With Sparse Fine-Tuning and DeepSparse,,mwitiderrick,3,0.81,0,https://neuralmagic.com/blog/fast-llama-2-on-cpus-with-sparse-fine-tuning-and-deepsparse/
327,1700703507.0,Created a plastic object detection model using AWS technologies 🌍🤖," [https://github.com/akkik04/GreenGuardian](https://github.com/akkik04/GreenGuardian)

Leveraged AWS Sagemaker and associated cloud technologies to create 'Green Guardian', a deep learning object detection model achieving a mAP score of \~0.7, trained on images retrieved from Google's Open Images Dataset V7. Designed to contribute to a greener environment by accurately detecting and highlighting plastic objects within images.  


Green Guardian is a deep learning object detection model achieving a mAP score of \~0.7, trained on images retrieved from Google's Open Images Dataset V7. Designed to contribute to a greener environment by accurately detecting and highlighting plastic objects within images. Leveraging optimal deep learning practices, data analysis techniques, and cloud-based infrastructure, this project aims to enable effective identification and monitoring of plastic presence, promoting environmental sustainability and conservation efforts.

## Key Features 📝

* **Deep Learning Object Detection**: Green Guardian employs advanced object detection techniques to accurately detect and locate plastic objects within images, providing valuable insights for environmental analysis.
* **Cloud Infrastructure**: Leveraging AWS cloud-based tools, Green Guardian ensures efficient processing, accessibility, and availability for users across different platforms. Also allows for scalability and cost-effectiveness with a main serverless architecture.
* **Batch Transformation Pipeline**: Green Guardian utilizes a batch transformation pipeline to process large quantities of images at once, ensuring efficiency and scalability. This pipeline is orchestrated by AWS Step Functions, which coordinates the execution of several serverless Lambda functions to ensure that the pipeline runs smoothly and efficiently.
* **Environmental Impact**: By highlighting and raising awareness about plastic presence, Green Guardian promotes conscious decision-making, waste reduction, recycling initiatives, and the preservation of ecosystems.

## Architecture 🏗️

The architecture of Green Guardian incorporates various cloud services to achieve efficiency and scalablity. Most of the services are managed by AWS, with the exception of Apache MXNet, which is an open-source deep learning framework (utilized for model training purposes). Overall, the architecture is designed to be serverless, allowing for cost-effectiveness and scalability.

* **AWS SageMaker**: Green Guardian utilizes SageMaker for model training, hyperparameter tuning, and inference. SageMaker provides a managed environment for developing and deploying machine learning models at scale, giving rise to efficient training and inference processes.
* **AWS Step Functions**: Step Functions is used to orchestrate the plastic detection pipeline. Gave me the opportunity to define a state machine that coordinates the execution of Lambda functions, ensuring that the pipeline runs smoothly and efficiently.
* **AWS EventBridge**: AWS EventBridge is utilized here to schedule and trigger the plastic detection pipeline at specific intervals using CRON jobs. Defined time schedules and events, ensuring that the detection pipeline runs at regular intervals to process newly submitted images.
* **AWS Lambda**: Lambda functions were used to asynchronously create/manage batch transform jobs for inference (and allow for interactions with AWS S3), allowing for a scalable and cost-effective inference process.
* **AWS S3**: S3 buckets were used to store all things data! From model artifacts to training data to modified batch outputs, S3 buckets were used to store and manage all data related to the project.
* **Apache MXNet**: Utilized this open-source deep learning framework to preprocess and create RecordIO files for training and inference. This RecordIO format is compatible with SageMaker's object detection tasks, allowing for efficient training and inference processes.

Let me know what y'all think! 👀",akkik1,3,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/181ppuq/created_a_plastic_object_detection_model_using/
328,1700702298.0,[P] An Open Source version of OpenAI Assistants API,,louis3195,3,0.8,0,https://twitter.com/louis030195/status/1727495156918861836
329,1700661010.0,CEO trying to get a certification in AI,"Hi, I’m looking for an online course with certification that would teach me what a CEO needs to know about AI. I have a background in engineering but haven’t coded in 20+ years. I am very interested (and even looking for) in the technical but also need a broad overview and don’t have very strong mathematical background.",Atomiumm,21,0.74,24,https://www.reddit.com/r/learnmachinelearning/comments/1819jy1/ceo_trying_to_get_a_certification_in_ai/
330,1700668179.0,Releasing Lightly Insights - Open Source dataset analysis,"Hey there, r/learnmachinelearning!

We're proud to present **Lightly Insights**, an easy-to-use Python package for in-depth analysis of ML datasets. This open-source package helps you to understand your image datasets, making analysis more intuitive and insightful. When working on various computer vision projects, we would often write our own data analysis scripts. We found that we would generate the same plots again and again for different datasets. So we decided to help everyone jumpstart and do a quick analysis.

**Highlights:**
- 💾 Compatible with major object detection label formats such as YOLO, COCO, KITTI, PascalVOC, Lightly and Labelbox.
- 📌 Detailed metrics: image, object, and class counts.
- 🧐 Uncover images without labels.
- 🔍 In-depth class analysis with size and location heatmaps.
- 📊 Generates a nice html report (check out our [example report](https://lightly-ai.github.io/lightly-insights-preview/))

**Installation & Usage:**

Get started with `pip install lightly-insights` and follow our [usage instructions](https://github.com/lightly-ai/lightly-insights#usage) for seamless integration.

Visit our [GitHub Repository](https://github.com/lightly-ai/lightly-insights) for more details and a live example. Lightly Insights is here to revolutionize your ML dataset analysis!

This is the very first release, and there is lots of room for improvement. We would love to hear your feedback and suggestions to improve the project!",igorsusmelj,11,0.93,0,https://www.reddit.com/r/learnmachinelearning/comments/181c7n8/releasing_lightly_insights_open_source_dataset/
331,1700713376.0,value iteration + bellman backup operator,hello! I am currently working with RL and I’m struggling to understand the derivation of the value iteration algorithm and what the bellman backup operator is and what is has to do with it. would appreciate any help/explanations with this,elaraxelara,1,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/181srrt/value_iteration_bellman_backup_operator/
332,1700698100.0,Best Way To Learn The Basics in 2 weeks?,"Trying to learn the very basics of ML or NLP to make a project out of it in 2 weeks. Project can be extremely simple--is there any ""Hello World"" type of project for ML or NLP? Also where to learn about ML and NLP for noobs?",Nixtivo,1,0.55,9,https://www.reddit.com/r/learnmachinelearning/comments/181nwxo/best_way_to_learn_the_basics_in_2_weeks/
333,1700683909.0,"Working on Soccer Database, getting awful results from feature engineering","I am working with this [database](https://www.kaggle.com/datasets/hugomathien/soccer/data). It contains ton of information about soccer matches, and related teams and players.  You can see the current repo of my project here: [https://github.com/alespool/Soccer\_matches\_predict/blob/main/data\_exploration\_selection.ipynb](https://github.com/alespool/Soccer_matches_predict/blob/main/data_exploration_selection.ipynb)

&#x200B;

**My data structure:**

I currently have some SQL queries that give me the data, this contains many info on who are the players, who are the teams, what their stats are like, and when was the match played. The data is selected only for England's Premier League and cleaned from NAs. The data has also been divided into train and test based on time, rather than simple splitting, as this will give me a chance to have a model learning from previous seasons (2008 to 2014) which predicts onto later seasons (2014 onwards).

This naturally lead me to believe I need to work with tons of features, and that these features then need to be selected from a few that give me the highest returns in terms of predictivity.

Here is the current data structure of my X columns before cleaning:

&#x200B;

https://preview.redd.it/uevqdb0sly1c1.png?width=469&format=png&auto=webp&s=1be551f9a47ce6b3fc3692b147fd1ed9fff47245

https://preview.redd.it/cl4u7ictly1c1.png?width=469&format=png&auto=webp&s=a74c43b60c5e97771dee0ab4e826cb9c71e367be

and after removing columns showing multicollinearity issues and/or that could give me data leakage and prediction issues (mainly stats that wouldn't be available before the end of the game)

https://preview.redd.it/hx2klcfjly1c1.png?width=469&format=png&auto=webp&s=6c2862368ef772a355b667f1b31c9f9ea6f92f46

So effectively, this last one is my X and the y is just the outcome for the matches:

\- 0 Home Team Loss

\- 1 Home Team Draw

\- 2 Home Team Win

**What I want to do:**

Predict who will be the winner team between home\_team and away\_team, using as many column as possible to help me. The Kaggle dataset homepage shows a ""Holy Grail"" of just 3 classes, which is also what I am aiming to achieve here, but the results are terrible.

In my first model, a logistic regression which is powered by a grid search of several parameters, I only get about 33% of accuracy, and awful results at ROC-AUC scores (either 0.5 or less for both 3 classes).

I use a SVM later, only with home team and away team info, and this alone gives me 45% ?? I am very confused, can someone please point out or give me some tips on how can I fix the data structures for prediction?

&#x200B;

I am open to any suggestion, please let me know if anything is not clear, I have removed some parts in the repository that are not interesting for the bare prediction, but might not make the notebook look clean.

&#x200B;

EDIT: added pictrures for more visibility over the dataset columns",cruise-boater,4,0.83,1,https://www.reddit.com/r/learnmachinelearning/comments/181ig9c/working_on_soccer_database_getting_awful_results/
334,1700656457.0,"The impossible forecast (daily time series). Does anyone know of a model or technique that could forecast this behaviour? The image shows predictions by the Autoformer, unsuccesfull.",,SeaResponsibility176,11,0.82,11,https://i.redd.it/d3d9hnjo8w1c1.png
335,1700695644.0,Graduate Programs for Natural Language Processing/Machine Learning,"I am an undergraduate at UCF majoring in computer engineering looking to pursue NLP with ML in the future. I have worked with sentiment analysis and summarization in the past and do research in CV with a research lab. I also do deep learning applications at lockheed martin as an intern.  I want to search for a good masters program with NLP and eventually become an ML engineer. Do you have any good colleges/programs in mind, what steps should I take to find the right program for me?",Material_Ad_2134,1,0.67,2,https://www.reddit.com/r/learnmachinelearning/comments/181n16s/graduate_programs_for_natural_language/
336,1700663708.0,I updated the original transformer with a bunch of the SOTA methods,"So I've been messing around with PyTorch for a while and decided to recreate the original transformer but with a twist. I integrated a bunch of the SOTA methods into the original architecture and found that it outperformed the original model on German to English translation by achieving a BLEU score of 28.1. I still intend to run further test on the model like comparing tasks on Q&A and such. If anyone is interested in recreating or to learn more about the model, here's the link to the repository!

[https://github.com/radia78/Transformer2/tree/main](https://github.com/radia78/Transformer2/tree/main)",Kitchen_Exam_1226,5,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/181ai96/i_updated_the_original_transformer_with_a_bunch/
337,1700668553.0,Building a Neural Network with PyTorch,,modelop,3,1.0,2,https://haydenjames.io/building-a-neural-network-with-pytorch/
338,1700646888.0,Math for machine learning roadmap ( Explanations + resources ) !!,"## Another generic post?

No fellow redditors, this is not your average post. I’m  **excited**  to announce the creation of a **Math for AI/ML  roadmap** meant to provide a **full guide** for anyone looking to get into AI/ML and want to understand the *mathematics* behind it.

**I want for all of us to come together to build the best roadmap possible that everyone will be able to use. I already set up the following**

* A [Discord server](https://discord.com/invite/kaxCNpQMKR) where we can communicate and organize ourselves
* A [Github repository](https://github.com/NavigoLearn/Math-for-ML-AI/tree/master) where you can submit pull requests and issues. You will also find there a contribution guideline

I already made a good chunk of the roadmap and I need feedback on it so make sure to check it out

## What to expect from this project?

* A full roadmap, as an ultimate guide to math for AI/ML, which pools all resources and ideas from the internet in one place, organizing and giving them a nice structure. The roadmap will contain
   * Courses, videos, tutorials
   * Exercises
   * Explanations
   * **A fully visual and interactive roadmap implemented in the tool** [**here**](https://navigolearn.com/explore)

## Why you should contribute?

* Learn more yourself !! The roadmap will help expose any gaps in your knowledge OR get started with mathematics and ML/AI together
* Recognition in the open source and ML/AI community
* Collaboration and Networking: Connect with like-minded individuals.

**You don't need to be an expert, only have the will to be part of something bigger. Everyone of us began with a small contribution**",DeadProgrammer8785,9,0.91,0,https://www.reddit.com/r/learnmachinelearning/comments/1815n4u/math_for_machine_learning_roadmap_explanations/
339,1700600294.0,Does your company let your engineers use AI tools like Copilot or ChatGPT?,"In light of what's been happening with Open AI, this blog we wrote is still relevant:

A few weeks ago, I was with a group of CTOs when someone asked: *does your company let your engineers use AI tools like Copilot or ChatGPT?*

I thought the question was strange. What do you mean *let*? They're going to use it no matter what you say. AI code generation tools offer engineers a huge productivity boost. The ability to autocomplete code in seconds or work through a problem with AI isn’t an opportunity developers will pass up.

When we drilled into why this group was reluctant to allow their engineers to use AI, it became apparent that their reservations centered primarily on one concern: the absence of a robust testing framework to give them confidence in the code generated by AI.

But this is still flawed reasoning. If you’re not confident in using AI, how can you be confident in hiring new grads? If you don’t have the tools to have confidence in your code, it doesn’t matter where that code comes from–you’ll always struggle with quality.

Read more [here](https://trunk.io/blog/enhancing-code-quality-and-security-in-the-ai-era?utm=reddit).",Psychological_March2,93,0.93,78,https://www.reddit.com/r/learnmachinelearning/comments/180r9tx/does_your_company_let_your_engineers_use_ai_tools/
340,1700647224.0,Recommending games without the Live ML model,"I am working in a health tech startup, which provides gamified exercises.

And they asked me to improve their game recommendations to increase interactions. But the catch is they can not put the ML model live so I am supposed to create some ballpark figures of user profiles that they can hardcode in their backend, compare it with new users, and recommend games( total 8 games) based on that. This is not supposed to be a highly accurate work but something better than no data science.

&#x200B;

The data I have is:

Id, Age, gender, App\_use\_reason, total\_time\_spent on various games, avg\_session length of each game, highest and lowest scores, number of wins and losses, etc...

( Age, gender, App\_use\_reason are highly significant)

&#x200B;

My approches:

First I tried clustering, but could not find any way to recommend the games based on user clusters.

Experimented with User based recommendation system(using KNN) and thought of giving the cosine similarity matrix to recommend but it does not provide recommendations outside the user base.

Now trying multiclass classification model, and use the equations directly. I am not sure if this will work or not.

&#x200B;

Asking for your help or suggestions.",Ajinkya1413,8,1.0,12,https://www.reddit.com/r/learnmachinelearning/comments/1815q00/recommending_games_without_the_live_ml_model/
341,1700671690.0,Bounding boxes problem,"I am using YOLOv8 along with BotSORT to detect only persons from my webcam and the tracker is giving them IDs as well. 

What I want to do is take user input, which will be a single number and only that person with ID equal to that number should be detected on the output screen(ie. Bounding boxes should appear)

for example, if there are two persons being detected through my webcam with IDs 1 and 2 and if I input 2 then only person 2 should have bounding boxes around him and no bounding boxes should appear for any other person which is not having ID = 2.

I use Ubuntu 22.04, and I git cloned the official github repository by ultralytics.  


This is the code that I run for normal webcam tracking using botsort:  


......................................................................................................................................................................

import os  
from ultralytics import YOLO  
\# Loads the model  
model = YOLO('yolov8m.pt')  
\# Set the class filter to 'person' (class index 0)  
results = model.track(source=0, show=True, tracker=""botsort.yaml"", classes=\[0\])  
.......................................................................................................................................................................  


  
Can someone please help me with how I should approach this problem... ",No-Exchange4187,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/181do19/bounding_boxes_problem/
342,1700667965.0,Personalized Search with Semantic Vector Embeddings at Scale: A Step-by-Step Guide,"We published a tutorial that tackles a common problem in search with ML: ordering large result sets. For instance, when a user searches for ""jacket"" on an e-commerce platform, how do we order the large number of results to show the most relevant products first? With recent advances in large-language models (LLMs), computers can now compute semantic similarities with high accuracy. This has opened up new possibilities for personalized search.

[https://www.datasqrl.com/blog/personalized-ai-search/](https://www.datasqrl.com/blog/personalized-ai-search/)

In this tutorial, we build a personalized shopping search with semantic vector embeddings, step-by-step. We use LLMs to compute the semantic context of past user interactions via vector embeddings, aggregate them into a semantic profile, and then use the semantic profile to order search results by their semantic similarity to a user’s profile.

We also discuss how to set up the necessary tools and data, an event-driven architecture for a scalable and robust solution, and the implementation process with DataSQRL, an open-source compiler for event-driven microservices.

You can apply these techniques whether you're working on event search, knowledge bases, content search, or any kind of search where a user can browse and search a collection of items.

We hope you find it helpful and informative. Feel free to share your thoughts and questions in the comments!",matthiasBcom,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/181c4j7/personalized_search_with_semantic_vector/
343,1700678954.0,"Time series data with high amount of NaNs (MNARs), need to use for modeling","&#x200B;

[I have time series data \(Each row is 1 day\) for multiple different people, who are very heterogenous. This is a heatmap with white being NaN values and black being usable data. As you can see most of the data \(about 80-90&#37;\) is nan, and most features are quanititative, not categorical. How do I know whether I can encode nan values as -1 or infinity without them affecting ML\/deep learning models?](https://preview.redd.it/3bvxh3rs2y1c1.png?width=751&format=png&auto=webp&s=5727e75a24e96aa296d25faf20f48866a7cf2a25)

&#x200B;",austinkunchn,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/181gjil/time_series_data_with_high_amount_of_nans_mnars/
344,1700678069.0,"Introduction to Machine Learning (L9, Linear Regression)"," Hello everyone!

This year I'm trying to record my ""Introduction to ML"" course in English. Maybe, it will be of any use for anyone.

[Lecture 9, Linear Regression & Regularization](https://www.youtube.com/watch?v=MIfdv6VFLbo)

[DEMO: Sum of Squared Errors](https://fbeilstein.github.io/machine_learning/lecture_09_linear_regression/demo_sse.html)

[DEMO: Linear Regression on Normally Distributed Points](https://fbeilstein.github.io/machine_learning/lecture_09_linear_regression/demo_point_cloud.html)

[DEMO: Regularization](https://fbeilstein.github.io/machine_learning/lecture_09_linear_regression/demo_regularization.html)

In previous lectures

Part 1 (Tools for ML): [Lecture 1, Introduction](https://www.youtube.com/watch?v=MxZULf38HRU), [Lecture 2, Python](https://www.youtube.com/watch?v=_IBdjLg-W6I), [Lecture 3, NumPy](https://www.youtube.com/watch?v=jJGiC_ccPg8), [Lecture 4, Pandas](https://www.youtube.com/watch?v=dKWPi5PfuEQ), [Lecture 5, MatPlotLib](https://www.youtube.com/watch?v=LkY3qyhq6Q8)

Part 2 (Survival Math): [Lecture 6, Mathematical Optimization](https://www.youtube.com/watch?v=HNrAjs6QqiY), [Lecture 7, Probability and Naïve Bayes](https://www.youtube.com/watch?v=46ev3LdbDZ4), [Lecture 8, Statistics](https://www.youtube.com/watch?v=ZVz-M-QwJsc)

All course materials: [GitHub](https://github.com/fbeilstein/machine_learning)

 ",fbeilstein,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/181g70p/introduction_to_machine_learning_l9_linear/
345,1700605667.0,How were activation and loss functions invented?,"I've been learning about ML stuff for data science for awhile now, the main thing I want to get is how and why we know to do certain computations and use certain formulas. With signoid/tanh activation functions for instance, who came up with those, and how/why do we know when to use them? And when choosing cost/loss functions to minimize, how were those invented and how did we know they were the best ways to descend the loss gradient? I know we still don't know a way to find absolute minima so these methods and the backprop algorithm are technically incomplete/imperfect at the moment. I'm sure sone of these answers will be quite technical/theoretical, and I actually want to know those tbh it sparks my curiosity even if I don't 100% understand the weeds of the answer at first. I'm considering studying optimization theory in grad school, I've taken an ODE course and an undergrad PDE course, so you can assume I'm familiar with those concepts, have also taken advanced linear algebra, and am familiar with how error is calculated with each epoch (I had to actually do a calculation for error across one epoch given a basic fully connected feedforward network to backpropagate during an exam, was a disgusting calculation with a gross summation but wasn't as bad as it can be ig)

Sorry for my English btw, it's my 3rd language and I don't use it every day",Traditional_Land3933,35,0.97,18,https://www.reddit.com/r/learnmachinelearning/comments/180tgmj/how_were_activation_and_loss_functions_invented/
346,1700672918.0,Classification of Active Parallel Pumps for the Highest Efficiency in a Parallel Pumping System,"I have data of the system efficiency at different flows and pressures for a parallel pumping system with either 1 or 2 active pumps. 

I have data of the efficiency for both 1 and 2 active pumps in the somewhat same flow/pressure area. To optimize the efficiency, my first thought was to remove the data point of the output label (number of active pumps) with the lowest efficiency when comparing it to the surrounding data points.

After removing the necessary data points, i'd train a neural network to output the optimal number of active pumps for a given pressure and flow.

I'm very new to Machine Learning, so i was wondering if there is another way where i don't have to sort the data this way myself, but rather let some sort of algorithm do it for me? Also, is this the same approach you'd use?",vision_dev,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/181e5a4/classification_of_active_parallel_pumps_for_the/
347,1700656021.0,Brush Annotation Tool: your must-have for Object Segmentation - Supervisely,,tdionis,2,1.0,1,https://supervisely.com/blog/brush/
348,1700668934.0,Tensorflow is returning unsupported object type tensorflow.python.framework.ops.EagerTensor,"I am using 3D images to fit a 3D CNN. I converted those images in Numpy 3D arrays. Then into tensors. Still, when I call the model.fit() command, an error saying ""ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor)"" is displayed.

Note that the numpy arrays are successfully converted into tensors as when I call the type command, the type of the arrays is returned as ""tensorflow.python.framework.ops.EagerTensor"".

I have tried tf.constant(), tf.variable(), tf.convert\_to\_tensor() to convert the np arrays into tensors, still the ValueError is returning at the model.fit() command. Please someone help me with this. Thank you!",DeepHiddenLayer,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/181ckly/tensorflow_is_returning_unsupported_object_type/
349,1700668911.0,Tensorflow is returning unsupported object type tensorflow.python.framework.ops.EagerTensor,"I am using 3D images to fit a 3D CNN. I converted those images in Numpy 3D arrays. Then into tensors. Still, when I call the model.fit() command, an error saying ""ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type tensorflow.python.framework.ops.EagerTensor)"" is displayed.

Note that the numpy arrays are successfully converted into tensors as when I call the type command, the type of the arrays is returned as ""tensorflow.python.framework.ops.EagerTensor"".

I have tried tf.constant(), tf.variable(), tf.convert\_to\_tensor() to convert the np arrays into tensors, still the ValueError is returning at the model.fit() command. Please someone help me with this. Thank you!",DeepHiddenLayer,0,0.5,4,https://www.reddit.com/r/learnmachinelearning/comments/181ck30/tensorflow_is_returning_unsupported_object_type/
350,1700668045.0,Personalized Search with Semantic Vector Embeddings: A Step-by-Step Guide,"We published a tutorial that tackles a common problem in search with ML: ordering large result sets. For instance, when a user searches for ""jacket"" on an e-commerce platform, how do we order the large number of results to show the most relevant products first? With recent advances in large-language models (LLMs), computers can now compute semantic similarities with high accuracy. This has opened up new possibilities for personalized search.

[https://www.datasqrl.com/blog/personalized-ai-search/](https://www.datasqrl.com/blog/personalized-ai-search/)

In this tutorial, we build a personalized shopping search with semantic vector embeddings, step-by-step. We use LLMs to compute the semantic context of past user interactions via vector embeddings, aggregate them into a semantic profile, and then use the semantic profile to order search results by their semantic similarity to a user’s profile.

We also discuss how to set up the necessary tools and data, an event-driven architecture for a scalable and robust solution, and the implementation process with DataSQRL, an open-source compiler for event-driven microservices.

You can apply these techniques whether you're working on event search, knowledge bases, content search, or any kind of search where a user can browse and search a collection of items.

We hope you find it helpful and informative. Feel free to share your thoughts and questions in the comments!",matthiasBcom,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/181c5pp/personalized_search_with_semantic_vector/
351,1700663677.0,Finetuning an object detection model,"Her r/learnmachinelearning,

I want to fine tune an object detection model on a large black and white dataset containing drawings associated with 25 different labels like house, hospital, car... (\~100,000 items per class).  
I've heard that YOLO's are good candidates for that, because they're light and fast (runing the model on a cellphone could be easier for my use case), but they seems difficult to finetune due to the need of labeled object boxes (and not handled by huggingface or pytorch), and I'm not sure that they can be finetuned on just labeled images with classes he never saw. Furthermore, because my dataset is in black and white, and the inference will be in black and white too, maybe using a yolo pretrained model is overkilled.   
Do you guys have any hint of the path I could take ? Feel free to ask any question if it's not clear enough.

Thanks!  
",Karamouche,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/181ahwi/finetuning_an_object_detection_model/
352,1700649049.0,Relation Extraction with Flair,"Hi everyone,

I'm new to ML and don't really where to ask elsewhere. 

I have about 30 texts with approximately 3000 words which I annotated with entities and annotated those entities with relations using label studio (this annotation process was gruesome). 

My goal was to train my model so it would learn to create relations on other text, but I have a recall value 1%. I suspect that this is due to a class imbalance problem, as  certain classes occur much more frequently than others (for example Person vs. medical issue).   


I use flair, but I don't know whether flair is able to annotate relations across  multple sentences (including when for example certain text sections have no entities at all).   


Could you help me and tell me whether flair can do this at all and how I  could approach this problem in general?

Best regards an amateur in nlp",Ok_Organization6140,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/181655q/relation_extraction_with_flair/
353,1700661304.0,M3 Chips and machine learning (FastAI compatibility),"Hi guys,  


Some of you know about the M3 Chips of apple ?   
I was running with my M1pro but i was not able to run some specific librairies for ML/AI like fastAI.  


Does this chips fixe it ?",RatioAltruistic9324,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/1819nli/m3_chips_and_machine_learning_fastai_compatibility/
354,1700641806.0,Better CPU or better GPU?,"I am attempting a build for the sake of image generation.  I do not know the most about proper system requirements for generating images quickly and/or with quality, hence my current predicament.  Given a limited budget, ought I buy a higher quality (and more expensive) CPU, i.e. one with more cores and/or a higher standard clock speed, or should I lean towards getting a decent CPU and throwing more of my money towards a higher quality GPU?

&#x200B;

Specifically, I am trying to decide if I ought get a newer Ryzen CPU with 32 cores or if I should save money on the CPU/motherboard setup to buy a high quality NVIDIA GPU, if that helps.

&#x200B;

Any input is appreciated.",Gamer-C,2,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/1814h9k/better_cpu_or_better_gpu/
355,1700623354.0,Where/How to start reading research papers,"Hello, I have been wanting to start reading research papers but to be honest I don’t really know where to start. I am interested mainly in deep learning and reinforcement learning, but when I look at past published papers the overwhelming quantity is discouraging. Would anyone have, essentially, a good “starting point” for reading research papers? I’m sorry if this post seems vague and I’m happy to provide any additional information.",Open-Ad2530,5,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/180zljt/wherehow_to_start_reading_research_papers/
356,1700590716.0,ML From Scratch,"I'm trying to find the best way for me to start learning ML from scratch. For context, I'm web dev who's quite bad at math, who wants not only to use popular ml libs, but to understand how this stuff works. I would like to know your opinions about the books I have picked so far, and some advices  


1. ""Introduction to Linear Algebra"" - Gilbert Strang
2. ""Calculus"" - James Stewart
3. ""Understanding Analysis"" - Stephen Abbott
4. “Introduction to Probability” - Joseph K. Blitzstein, Jessica Hwang
5. “Mathematics for Machine Learning” - Marc Deisenroth
6. ""An Introduction to Statistical Learning"" (Springer Series)
7. “Bayesian Data Analysis” - (Chapman & Hall/CRC Texts in Statistical Science)",Just-Curve-9326,26,1.0,12,https://www.reddit.com/r/learnmachinelearning/comments/180nihl/ml_from_scratch/
357,1700650789.0,Sub reddit suggestions,I find r/LocalLlama to be the best sub reddit rn imo. What are others that you follow? Is there a parallel CV community like it?,gillan_data,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/1816kej/sub_reddit_suggestions/
358,1700583195.0,"Hugging Face deprecated Auto Train, what should I use now?","I am kinda technical, but writing and tuning hyper parameters is hard to do well. 

When Hugging Face launched Auto Train it was amazing, the results I could get just by dropping in a dataset were awesome and insanely accurate. For (seemingly) no reason they deprecated this feature and only allow now support Advanced Auto Train WHICH IS A NIGHTMARE.

I can't get it to run. Bugs abound and when I reach out to support they just say ""make a github issue, I have a small keyboard and can't respond here"" -- whatever that means...  but when I look at the github issue page it has 130 opened github issues mainly (most comments are not answers just addition questions from community), and clearly this will do nothing besides waste my time. The docs are so minimal its a joke. And looking at their discord clearly a few other people have this issue but they are promptly ignored. So I tried reaching out to my local community and have had *multiple* people with +10 years in ML experience try to help and their answer was ""it's going to be easier to just do this manually"". 

Assuming HF isn't going to turn back on support for regular Auto Train, what do I do? Whats's the best path? 

For context, I was using HF to start because I working with domain specific text data and HF is AMAZING when it comes to finding domain specific LLMs to fine tune (overall excluding the issue above I really love HF) and automatically standing up an endpoint was very helpful. Specifically on the data front, I have many types of text datasets all single sentence text data but different labeling strategies depending on the text in question  (single category, multi-category, NER, binary...). I have roughly 60-70 datasets in all. They all update with some regular cadence (like every other month or every other quarter depending on the data). This is why AutoTrain was so valuable I just could drop in, refresh and be on my way. Manually managing these seems insanely difficult since the size of the dataset and balance of the data in the dataset can change regularly which means re-tuning the hyper parameters of the models... which given the amount of datasets I need up does not seem tenable. I'm a 'one man' team here and I can get one more person for 'non technical activity' (i.e. dragging and dropping data in a GUI). Very open to thoughts on how to handle this problem.

TLDR; Hugging Face's AutoTrain is deprecated, their 'new' product is an unusable dumpster-fire, their support/docs are worse... I have to many models to manually fine tune myself (love to hear if you think this is not the case) what should I look to use here?",OpenWeakness7421,19,0.92,3,https://www.reddit.com/r/learnmachinelearning/comments/180klx2/hugging_face_deprecated_auto_train_what_should_i/
359,1700600995.0,Want to learn about AI Inference and how AI Inference works?,,ramyaravi19,8,0.83,0,https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/training/inference-and-large-language-models.html
360,1700624004.0,how can i add a custom dataset to cnn tensorflow code,"im VERY new to ML. this is my graduation project and i am completely lost. i cannot figure out how i can add my custom dataset to the cnn code. our supervisor told us to use this code right here:[https://www.tensorflow.org/tutorials/images/cnn](https://www.tensorflow.org/tutorials/images/cnn)

the only changes to make is to add our custom dataset but i couldnt figure out how to do that. im beginning to think its impossible.

I WOULD APPRECIATE ANY KIND OF HELP PLEASE IM SO NEW TO THIS AND VERY LOST THANK YOU",hope25x,2,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/180zszm/how_can_i_add_a_custom_dataset_to_cnn_tensorflow/
361,1700593771.0,Which Linux workstation distro is considered good for data science and machine learning?,I am looking for Linux distro for my workstation. My daily job consist of different data science and machine learning tasks. Which Linux workstation distro is considered good for data science and machine learning? Is there any general consensus? What is your personal experience doing data science and machine learning on Linux workstation?,Alex_df_300,9,0.85,10,https://www.reddit.com/r/learnmachinelearning/comments/180ophb/which_linux_workstation_distro_is_considered_good/
362,1700601100.0,Want to learn about AI Inference and how AI Inference works?,,ramyaravi19,6,0.88,0,https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/training/inference-and-large-language-models.html
363,1700635513.0,4060TI 16GB or 4070 to pick up deep learning?,"Hi all, I am currently a undergrad and mainly do some general machine learning on a m1 macbook air, but would want to explore more about kaggle, deep learning and build a portfolio. 

Upgrading my desktop since i also play games and the gpu is old (960), but I do not really want to spend on a 4080 as I am still a student. 

Currently do not really have much of an inclination towards which domain i would want to research on, but would want to know if the 4gb vram is essential that i would want to get a 4060ti 16gb instead of 4070, or if i can get 2 8gb cards like 2 4060/3060ti. I have seen many recommending 4060ti 16gb for deep learning, and want to know the more about it since I do not know much about deep learning.

Thank You!",Dumbdevil1,1,0.6,4,https://www.reddit.com/r/learnmachinelearning/comments/1812zfr/4060ti_16gb_or_4070_to_pick_up_deep_learning/
364,1700634065.0,Fine-tuning an LLM for custom NER,"I am exploring using an LLM to be able to detect the merchant/company name in bank transactions from a bank statement.

e.g.

Input: “POS purchase McDonalds Restaurant NYC Nov20”

Output: “McDonalds”

I know I can take a pre-trained LLM and not do any fine-tuning, but instead just give a few examples of the task in the prompt and then ask it to do the same on a new transaction.

However, is there anyway I can fine-tune an LLM so that given a transaction it will output only the merchant name (and possibly “none” if there is no merchant in the transaction)?

I assume I could either fine-tune for custom NER where “MERCHANT” is the only entity possible. Maybe I can also fine-tune for text generation where given an input transaction, it will then continue the string by appending only the merchant name to the end, but I am not sure how this can be achieved.

Note: 
- The example I gave with “McDonald’s” is oversimplified, when in reality these transactions are extremely messy, contain a lot more noise of things such as long reference numbers, etc.
- Also the structure of the transactions varies wildly so the merchant name can appear anywhere in the string. 
- Lastly, the transactions I am working with are from the Middle East, so there are many less popular merchants, so I want the LLM to learn to predict the merchant name based on the structure of the transaction, rather then depending solely on the LLM having “memorised” popular merchants, such as “McDonald’s”.",JustinQueeber,1,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/1812m6y/finetuning_an_llm_for_custom_ner/
365,1700529086.0,🎉 Exciting News for Machine Learning Enthusiasts! 🚀,"We are **excited** to update the community about the 100 Days of Code ML Challenge.

**Who are we?**

-We are two graduate students specializing in machine learning and artificial intelligence, who are eager to delve deep into various ML topics and projects.

**What is the 100 Days of Code Challenge?**

-It’s a commitment to code for at least 1 hour for 100 days. But this isn’t just about coding – it’s about learning, experimenting, and applying machine learning in innovative ways.

**What Can You Expect?**

-Diverse Topics: From fundamental algorithms to cutting-edge techniques.

-Project-Based Learning: Hands-on projects to apply ML in real-world scenarios.

-Collaboration and Networking: An opportunity to connect with like-minded individuals.

**We WANT Your Input!**
This journey is not just ours – it's yours. 
We want to know:

-Topics of Interest: 

What specific ML topics are you most interested in?

-Applied Uses:

Are there specific industries or problems you think ML can significantly impact?

**How to Participate: Simply join the discussion, however you want.**

- Twitter: @100daysml
- Reddit: r/100daysml
- Discord: https://discord.com/invite/BVhwgeqy
- https://www.100daysofml.com

**Right now the tentative release date is January 1st, 2024.**
 
Let's code and learn together!

We are looking for a select few individuals to assist us. If you are interested please reach out to ml_w0lf.

- u/ml_w0lf
- u/vicethal",ml_w0lf,202,0.95,146,https://www.reddit.com/r/learnmachinelearning/comments/1804phy/exciting_news_for_machine_learning_enthusiasts/
366,1700595223.0,"Two Part Research Club on ""Mechanistic Interpretability"" of LLMs","Hey all,

We do a research club every Friday and just finished a two part series diving into the Anthropic paper: ""A Mathematical Framework for Transformer Circuits"" and thought I'd share the recap here for anyone who is interested.

[https://blog.oxen.ai/arxiv-dives-a-mathematical-framework-for-transformer-circuits-part-two/](https://blog.oxen.ai/arxiv-dives-a-mathematical-framework-for-transformer-circuits-part-two/)

Would love some suggestions for next topics! We are thinking of applying some of the learnings on Transformers in the natural language space to transformers applied to computer vision and then working our way into multi-modal models.

Any paper suggestions are welcome!

&#x200B;",FallMindless3563,5,0.86,4,https://www.reddit.com/r/learnmachinelearning/comments/180pa8k/two_part_research_club_on_mechanistic/
367,1700620215.0,[Q + D] SOTA Open Domain QA Models,"What are SOTA Open Domain QA models at the moment? I've been doing research on the field and am seeing so many cool approaches, since they're so many aspects of QA that need to be worked on, but I have no idea what's SOTA at the moment. My professor told me to look into RAG, and I am, but I feel like he might not be as up to date in this area, so I'm not sure where it stands? Also where do you guys look to find out what's the most popular models at the moment? I've been reading papers in popular journals and trying to just search stuff up ig but it's not really telling me what I want to know idk",Aggravating-Floor-38,0,0.5,2,https://www.reddit.com/r/learnmachinelearning/comments/180ykxx/q_d_sota_open_domain_qa_models/
368,1700602657.0,[D] How to find a campaign of like-minded people to study ML together,"A Couple of months ago I started learning statistics, python, pandas, matplotlib, seaborn and now I am learning ML and this is much more harder than what were before. I think if I join the group it will help me. So where to look for like-minded people?(sorry for my English🫠🫠💀💀)",ExplorerMost2308,2,0.75,3,https://www.reddit.com/r/learnmachinelearning/comments/180s8mv/d_how_to_find_a_campaign_of_likeminded_people_to/
369,1700612882.0,Are there existing tools to train chatbot to reference a live phone call?,"Looking for the tools to train a chatbot on a live phone call (whether it needs to be transcribed or can interpret audio) and then, following the call, can reference it as data and interpret certain aspects of the call and the information that was discussed in it. Anybody heard of anything like this?",Levinvest,1,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/180w4r8/are_there_existing_tools_to_train_chatbot_to/
370,1700598089.0,Is open classification or classification rejection a difficult problem in the field? Which classifiers (or ensembles) are capable of performing this?,"I have data that has been clustered and labeled and I have a simple classifier trained on the data but I'm needing a way to reject data that doesn't fit any of the labeled clustered classes. The expectation of the rejection would be new classes (or evolutions of existing ones) with a few anomalies/novelties. I can monitor rejections to know when it's time to remodel but I need the rejection capability first.

I have 2 approaches that I'm working on but I'm not satisfied with either. The first is to train an ensemble of OC-SVM--one for each cluster--and run each observation through. If all SVMs reject the observation, it's considered unknown. The problem is that some clusters are larger than others, so the SVMs for smaller cluster labels are considerably weaker than ones trained on the larger clusters. A proposed solution for this is to create new observations for smaller classes by randomly sampling a value in each variable within the class. So basically synthetic over-sampling using hot-decking imputation. If I had enough data, I'd resample directly from the empirical distribution using the inverse-transform method but I don't.

The other approach is more rule-based. For any observation, I can calculate the Euclidean distance to all cluster centroids, the distance to the closest cluster member (single linkage), and the distance to the furthest cluster member (complete linkage). Taking both intra-cluster and inter-cluster distances, I can make determinations on cluster membership on a new observarion (if appropriate) or if it doesn't belong to any known cluster. This works reasonably well but it feels too manual of a process. This is all part of a pipeline that will be used on hundreds of data streams, so I'm wanting it to be as resilient as possible with as little need for 1-offs as I can manage. Besides, this feels like I'm reinventing k-means or k-NN but with the ability to reject.

Am I going about this wrong? Is there a better approach to handle open-classification and rejection? Any thoughts or opinions?",WadeEffingWilson,2,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/180qel5/is_open_classification_or_classification/
371,1700596614.0,Help me find a paper explaining stochastic gradient descent algorithm math,"A few (4-5) years ago I came across a paper explaining the math of stochastic gradient descent for computer science grads. The paper is more like a notes from a TA or research grad, somewhat casual in language and the math is broken down into small sections. It is really a good read. Moving forward after few years I wanted to do a re-read of it and for the love of god I could not find the paper in my hard drive, old/new laptops, workplace laptop, google drive. I looked for it everywhere but no use. 

&#x200B;

The paper is/was pretty popular in the research/student community at that time. I found it somewhere online where they were talking how well the gradient descent method was explained. Can someone help me find it again if someone is able to relate what I am talking about. Thanks.",vkgade,2,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/180ptqp/help_me_find_a_paper_explaining_stochastic/
372,1700609936.0,IBM Machine Learning with Python Review: Student's Perspective -,,Lakshmireddys,1,1.0,2,https://codingvidya.com/ibm-machine-learning-with-python/
373,1700585918.0,Extract Table of Content from PDF/Docx,"So recently I have received multiple pdfs, which is governmental pdfs, from canada, US ...etc public ones ofc, and I was in the process of chunking them but there is a middle step I need for my chunks to be complete, which is to extract the table of content and map each header with their subheaders. I have made multiple scripts and algorithms even used SpaCy but I was not able to succeed in doing so, however I made a script utilizing the docx's inner XML file and with help of chatGPT was able to extract headers and sub-headers (only for PDFS I could convert to docx), so my question is, is there a straightforward method that I can automate this instead of matching case by case pdf with algorithm for each case? ",Weird_Plant7420,3,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/180lnld/extract_table_of_content_from_pdfdocx/
374,1700586768.0,covered all the math but unsure how to proceed further.,"Now that I am trying to develop a ml model for a livestock maintenance project. assuming that i am very clear about all the requirements of the project. when i set on a journey of learning aiml aiming to get started with the project, i am trying to cover up all the math part i am halfway there but i just wanted to know whether i can only get started with a unique ml model thats suitable just immediately after learning all the math or there is an order in which i need to cover all the machine learning models only one of those models is going to be exploited for my project,. i am confused right here. if my perception is worng please help me with the right approach to complete my project soon. for your knowledge in the road map of learning aiml i can all the math statistics pre requisites part and the coding fundamentals (python) and data preparation too i just wanted to clartify what is the route from here or if my understanding is right and i am very specifics to my project..",Ramkumar_from_nellai,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/180lzta/covered_all_the_math_but_unsure_how_to_proceed/
375,1700571272.0,Design to implement bot in tic-tac-toe?,"I'm currently working on the classic tic-tac-toe bot that many do when starting out. At the moment, I have written a working game, where a human can play vs. the computer, or the computer can play itself.

My question is, how should I go about the implementation of such a bot?

I have done some quick research and seems there are two main designs that are used for simple board games like this.

The first is reinforcement learning (likely using Q-learning) - implemented as seen [here](https://towardsdatascience.com/reinforcement-learning-implement-tictactoe-189582bea542).

The second is a neural network model - implemented like [this](https://www.kaggle.com/code/dhanushkishore/a-self-learning-tic-tac-toe-program).

Personally, it seems that reinforcement learning seems more simple to write the code for, so I am leaning to towards that side. I have already implemented a perfect minimax bot (which is impossible to beat) so my 'intelligent' bot would be able to practice against optimal play.

Are there any other designs that you would recommend I use? Would reinforcement learning make the most sense for me? Or would the other method actually be better? ",ZenyatasBalls96,3,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/180gbri/design_to_implement_bot_in_tictactoe/
376,1700592261.0,"I need to work on an image-to-image translation project, but I couldn't find a model that I can fine tune using data I have. Any leads?",,Snoo_72181,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/180o3pb/i_need_to_work_on_an_imagetoimage_translation/
377,1700570582.0,Understanding the Convolutional Filter operation in CNNs,"This article explains how the convolutional filter operation works:  
[https://medium.com/advanced-deep-learning/cnn-operation-with-2-kernels-resulting-in-2-feature-mapsunderstanding-the-convolutional-filter-c4aad26cf32](https://medium.com/advanced-deep-learning/cnn-operation-with-2-kernels-resulting-in-2-feature-mapsunderstanding-the-convolutional-filter-c4aad26cf32)

Understand why 2 Filters applied to an RGB Image with 3 channel result in 2 feature maps and not 3. 

Understand what is meant with receptive field. Understand how Relu is applied to the output matrices. 

&#x200B;

https://preview.redd.it/808hewhf5p1c1.png?width=1184&format=png&auto=webp&s=89023cf3cd0720a7bb10f5ca2850c36bc6ff4473",Junior_Syllabub_3037,3,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/180g3p9/understanding_the_convolutional_filter_operation/
378,1700585189.0,Task at hand. Any suggestions for how to approach this?,"Utilize frameworks and databases such as Ageitgey's, IMDB-WIKI, or Adience for detecting gender, or choose an alternative that fits the objectives of your project. Your task is to expand its capabilities and include feature enhancement through the use of computer vision. 

Detailed Feature Identification: Create a script to evaluate additional characteristics of the image's subject, which are crucial for the project's scope. Achieve at least a 50% success rate in this phase. The accuracy will be confirmed using our selected image dataset. 

Detection Elements: Conduct analysis of ethnicity, recognize body features (like Rack), and other specific attributes that will be revealed at this stage.",ninja_killed_baba,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/180ldgd/task_at_hand_any_suggestions_for_how_to_approach/
379,1700583454.0,Example of data labeling guidelines," I was looking for any real-world example of a rulebook for labeling data, but apart from general advice, I didn’t find anything. Have you seen publicly available guidelines for data markup that were used in practice to create datasets, especially for the task of object detection? ",ArcticPanda_,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/180kpak/example_of_data_labeling_guidelines/
380,1700573395.0,Beginner seeking guidance in choosing right start,"Hi everyone,

I was about to buy a course on Udemy but read that people recommend Andrew Ng's machine learning specialization course. So I'm new to this, but I have a high interest in learning about this field.  
What do you guys think, I should start out with, in order to really understand machine learning/data science?   


A lot of people say to start out with statistics, what are you guys saying about this? Should I do a statistics basic course first or is Andrew Ng's course a good way to jump into this?

  
",TheOceanIAm,1,0.67,2,https://www.reddit.com/r/learnmachinelearning/comments/180h06n/beginner_seeking_guidance_in_choosing_right_start/
381,1700573325.0,"Maximizing ChatGPT, AI Startups, Early days of Data science and more AI Insights with Ken Jee - What's AI Podcast Ep. 23",,OnlyProggingForFun,0,0.33,0,https://youtu.be/TOD9-WyWExs
382,1700551337.0,Extracting information from Tables,"I am working on a problem where I am supposed to extract information from different PDFs, the same information is present in different ways using different table headers. I have to create a generalized solution.

&#x200B;

The problem is that the tables are too complex, moreover the information related to the table can be present outside the table too. As of right now, I am using Camelot for getting the tables but that's about it. My team has experimented with converting tables to sentences and then using an NER, but that doesn't seem too promising to me. Since 2 table columns could have same datatypes and the lack of context might not be good enough for NER.

&#x200B;

Simply put:

Table, Page -> \[ Model \] -> Desired Information

Used LLMs too but... not scalable and they hallucinate a lot!

&#x200B;

Any help/suggestions would be extremely appreciated, Thank you.

&#x200B;

&#x200B;

Edit : Cannot use OCR since it's slow plus often misunderstand symbols.",atom1291,3,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/180bcvf/extracting_information_from_tables/
383,1700572787.0,Prediction Model: Encoding,"Hey, I'm a beginner and I'm building a prediction model atm. 

I 'm currently doing the encoding and was wondering if I also need to encode ordinal variables that already have numeric values.

Thanks for your help!",blaubarschbube27,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/180gsz3/prediction_model_encoding/
384,1700549721.0,What Should I Build Next? Looking for Ideas and Feedback!,"Hey fellow ML enthusiasts! 👋 I've been diving deep into the world of Machine Learning, Deep Learning, and Web Development, and I'm eager to showcase my skills by building something cool in public. Here's a quick rundown of what I bring to the table:

🤖 **Machine Learning & Deep Learning**

* Comfortable with creating and deploying ML models.

🌐 **Web Development Stack**

* Django
* Djangorestframework
* ReactJs
* NextJs

🐳 **Containerization**

* Docker

☁️ **Deployment Skills**

* Deploying ML models
* Deploying websites  


and other related skills to data science and machine learning.",Beginning-Scholar105,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/180ayld/what_should_i_build_next_looking_for_ideas_and/
385,1700548348.0,Non deterministic precision and accuracy (Random Forest),"I created  a model with 4 Random-Forest classifiers.I train it using KFold and a specific CSV and save it to a file via joblib (including random-seed, class\_weight, etc...).

&#x200B;

The random seed is fixed via the following **python** code:

`SEED = 14`

`os.environ['PYTHONHASHSEED'] = str(SEED)`

`random.seed(SEED)`

`np.random.seed(SEED)`

`torch.manual_seed(SEED)`

&#x200B;

When running the script to calculate the precision and accuracy I get different TP/FP/TN/FN counts (total always equals the data size).The results differ on run so basically also the accuracy and precision calculations.

Whenever I use a loop (inside it I load the model and the same CSV) I get consistent results.  
The only random actions are the ones inside the ML libraries, and I always pass them the same random\_state even the to each loaded forest.

&#x200B;

Do you have an idea what can cause this non deterministic behavior?",SonixDream,2,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/180am2p/non_deterministic_precision_and_accuracy_random/
386,1700554331.0,I'm on my Career Break | Need Suggestions,"I have a background in Statistics and experience as a freelance data analyst, primarily using Excel, SPSS, Tableau, and R. To enhance my skills, I've learned Power BI, SQL, and Python, and have completed several in-depth projects. I'm currently expanding my expertise into Data Science and am undertaking the Machine Learning Specialization on Coursera. While I'm familiar with the concepts taught by Andrew NG, transitioning from R to Python has been an insightful experience. 

**I'm seeking advice from experts on my next steps after completing this specialization. What additional learning or experiences would help me transition effectively into a Data Scientist role? I'm grateful for any constructive advice or suggestions. Thank you.**",MindGlobal,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/180c3s3/im_on_my_career_break_need_suggestions/
387,1700553752.0,ML vs DL,What are the key differences between CreateML and deep learning frameworks in terms of ease of use and application scope?,Independent_Ask6586,1,0.67,0,https://www.reddit.com/r/learnmachinelearning/comments/180bysm/ml_vs_dl/
388,1700516202.0,LSTM from scratch - Automatic text generator,"## Inspiration:

I am learning Machine Learning and NLP, and found that there were few clear and ready-to-use implementations of **LSTMs**. This repo is simple to use and can generate text replicating the style of any document in **\~15 mins**. I tried my best to make it **super-well documented**, so I hope it can be useful, and I would love any feedback!

## Running it Yourself:

You will have to clone the repository with:

>git clone [https://github.com/eduardoleao052/LSTM-from-scratch.git](https://github.com/eduardoleao052/LSTM-from-scratch.git)

Then, simply follow the instructions on the `README.md` file. Model configurations are in `config.py`.",suspicious_beam,6,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17zzqlb/lstm_from_scratch_automatic_text_generator/
389,1700510738.0,What is a use case of fuzzy clustering?,"This was Week 10 of my ML module in college, and I never got around to it so only know about it’s existence 

Can someone share some insights how this is used in practice? 

Any info on Fuzzy Clustering would be appreciated",Ok_Reality2341,3,0.8,4,https://www.reddit.com/r/learnmachinelearning/comments/17zxjml/what_is_a_use_case_of_fuzzy_clustering/
390,1700486257.0,Kalman Filter for Time Series Forecasting in Python,,ledmmaster,10,0.86,0,https://forecastegy.com/posts/kalman-filter-for-time-series-forecasting-in-python/
391,1700515654.0,Thesis or non thesis masters,"This may be obvious, but I wanted to ask anyways. Currently I'm considering my grad school options, mainly so I can work as an ML Engineer afterwards. A lot of the schools I'm looking at have professional/non thesis options. I was wondering, would a non thesis masters hurt my chances of working in the ML field if I didn't really want to get a phd afterwards?",Ultra_Amp,2,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17zzib1/thesis_or_non_thesis_masters/
392,1700523571.0,Prof. Chris Manning on building your AI career,,Stanford_Online,1,0.67,0,/r/u_Stanford_Online/comments/17ukafg/prof_chris_manning_on_building_your_ai_career/
393,1700506912.0,Usage of vocabulary in countvectorizer,"Hi, I'm working on a classification project and it uses countvectorizer before fitting data to randomforestclassifier. 

I noticed that countvectorizer has an optional vocabulary parameter. The official definition for this parameter is:

 **vocabulary*****Mapping or iterable, default=None***

Either a Mapping (e.g., a dict) where keys are terms and values are indices in the feature matrix, or an iterable over terms. If not given, a vocabulary is determined from the input documents. Indices in the mapping should not be repeated and should not have any gap between 0 and the largest index.

[https://scikit-learn.org/stable/modules/generated/sklearn.feature\_extraction.text.CountVectorizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)

I got better results using vocabulary with a list of keywords that, in my opinion, are critical for the classification. But I'd like to better understand how countvectorizer use this ""custom"" vocabulary and what it does when I don't set this parameter. 

Code:

`from sklearn.pipeline import Pipeline`  
`from sklearn.feature_extraction.text import TfidfTransformer`  
`from sklearn.feature_extraction.text import CountVectorizer`  
`voc = ['defiro','indefiro','defiro em parte','concedo','não-concedo','concessão','não-concessão','determino','parcialmente','defiro parcialmente','aplico']`  
`from sklearn.ensemble import RandomForestClassifier`  
`text_clf = Pipeline([`  
`('vect', CountVectorizer(lowercase=False,stop_words=sw,vocabulary=voc)),`  
`('tfidf', TfidfTransformer(smooth_idf=True)),`  
`('clf', RandomForestClassifier(class_weight={'11423':0.2,`  
 `'11424': 0.99,`  
 `'11425': 0.97,`  
`}, n_estimators=10000, oob_score=True)),`  
`])`    
",ImpressiveReading223,2,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/17zw0ra/usage_of_vocabulary_in_countvectorizer/
394,1700488639.0,State of OCR,"I am beginner in ml,how do I get myself updated with current state of OCR.
If I want to get better results than Tesseract or EasyOCR ,what path should I follow.i basically want near 100% accuracy in identifying typed/digital characters and their location in image.
Is this solved ??
Any guidance would be helpful 🙏🙏",spacejunk1995,4,0.84,5,https://www.reddit.com/r/learnmachinelearning/comments/17zp3jt/state_of_ocr/
395,1700517985.0,Need help with reading a CNC Drawing (apprentice),"Need help with reading a drawing (1st year apprenticeship)

I am an apprentice (M, 16) as a Polymechanic (year 1) and i just started with CNC Machining (ISO) and i missed the introduction because i was sick, anyway, i got thrown into cold water and am supposed to learn all of this, i just dont understand how to calculate P3, if anyone would be kind enough to explain how to calculate the points, i managed to figure P1 and P2 out. I just dont understand P3 and have been studying it for hours now (sorry if english was bad, not my first language) thank you very much.",Interested_Machinist,0,0.47,8,https://i.redd.it/p18ewwf1tk1c1.jpg
396,1700515254.0,[P] hair style recommendation,"Hi all, 

I have some experience in machine learning and I had an idea of an computer vision application.

I think whether you 'suit' a haircut depends a lot on face-shape, hair colour, thickness etc. I thought it would be useful to have some way of having an app give you realistic haircuts/styles which would suit you. I know some applications allow you to see how you would look in a particular hair cut however they are not always 'realistic' to what you can grow.

Any ideas on how this could be acheived/what data could be used/other related ideas,

Cheers!",No_Range3026,1,0.67,1,https://www.reddit.com/r/learnmachinelearning/comments/17zzcde/p_hair_style_recommendation/
397,1700498727.0,Experience with UCSD Machine Learning Bootcamp?,"Hey folks,

I'm considering the [program above](https://career-bootcamp.extension.ucsd.edu/programs/machine-learning-engineering/) to jumpstart my ML learning journey, hoping to eventually land an ML engineering role. I'm a mid-level back-end software engineer, though I don't have much exposure to the data science or ML side of things.

Has anyone gone through it or know people who have? The curriculum looks interesting enough, but for the cost (about $8800), I'm wondering if it'd make more sense to do something like OMSA or CU Boulder's MS-CS with a focus on machine learning. There are also programs like UMGlobal for Data Science (partnered with Springboard, which also does the UCSD one) that I've been told to consider - just not sure how much of the material is relevant if I want to build the proper foundations.

I've made a learning checklist as an alternative, one that entails Coursera specializations combined with Manning books like ""Machine Learning Bookcamp."" I'm not sure how viable that is if I'm diligent enough to work on the material consistently on my own time. Part of the appeal of this route is I can see if I genuinely like it for a fraction of the cost, considering work pays for my Coursera Plus subscription.

Thanks in advance for any input!",reporter_any_many,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17zsscm/experience_with_ucsd_machine_learning_bootcamp/
398,1700511177.0,Multicollinearity in model,"I’m converting an R poisson glm into Python. The R model doesn’t output a coefficient for the one level that is explained via another variable.

The same predictive model in Python gives me a coefficient. Im assuming there’s some statistical transformation to show that the two models are the same (input data is the same). Variables that are affected are strings. Below is a hypothetical example:

Gender 
State 
Pet (dog, cat, bird)

Let’s assume all bird owners in the dataset are males. This would produce multicollinearity and R wouldn’t output a coefficient for pet:bird. However, the same model in Python would give you a coefficient.",pestiky,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/17zxq15/multicollinearity_in_model/
399,1700509634.0,Help to figure out what maximum input size to use for our BI-LSTM model.,"  
So our BI-LSTM model is trained on an emotion classification dataset, in which the data are sentence based. This model will be used to classify the emotions from a book/novel's chapters texts and we don't know what maximum input size we should put in our model. Please help us and Thank you in advance. ",biboyboy,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17zx3ri/help_to_figure_out_what_maximum_input_size_to_use/
400,1700507152.0,How to stop Rendering during training.,"Just wanted to ask a quick question, when i run my training it shows me the training like I'm doing a env.render() but in all the tutorials I see the training is done in the background with no render and faster. Im using stable-retro and Stable\_Baselines3 with the code provided bellow.

import retro  
from stable\_baselines3 import PPO  
env = retro.make('SuperMarioWorld-Snes', state='YoshiIsland2')  
model = PPO(""CnnPolicy"", env, verbose=1)  
model.learn(total\_timesteps=1\_000\_000)  
model.save(""SuperMarioWorld-A2C"")",AdrianR956,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17zw48u/how_to_stop_rendering_during_training/
401,1700471816.0,Arima models and algorithms,"Hi all, I'm pretty new to time series analysis but I want to delve into the topic by looking at the numerical methods used to estimate ARIMA parameters.  

Do you have any useful or valuable sources of information?",erik-bias,5,0.78,1,https://www.reddit.com/r/learnmachinelearning/comments/17zkjwt/arima_models_and_algorithms/
402,1700504194.0,Need feedback on my web app.,"
https://heart-disease-prediction-app.streamlit.app/


I have developed a ML model which detect heart diseases. Using Streamlit library I have deployed the model on web. This is my first time, so don't know much about it.
Any suggestions?",infinity_bit,1,1.0,0,https://heart-disease-prediction-app.streamlit.app/
403,1700502907.0,Training process of a conditional GAN,"I'm trying to figure out the training process of a conditional GAN.

For example, consider a dataset like MNIST. I give the conditional vector to produce only the number 7 for both the generator and discriminator. In the following scenarios, the discriminator will classify which one is fake and which one is real:

1. The generator produces realistic numbers other than 7, such as a realistic number 9 ?
2. The samples from the MNIST dataset that are not the number 7 (i.e., other numbers) ?

Thanks for your help!",Electronic_Ant2706,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17zug32/training_process_of_a_conditional_gan/
404,1700460593.0,Suggest me resources to learn mathematics for ML,"I did do maths during high school and under graduation but I haven’t touch much of it got about 5 years now 
Restarting my touring again with ML 
Thanks in advance for your help !!!",whereartthoukehwa,8,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/17zhxuw/suggest_me_resources_to_learn_mathematics_for_ml/
405,1700466127.0,Building my first ML model,"

Hey guys! I’ve an assignment coming up and this is my first time building models. We are supposed to build different models and then select the best model for the problem. Could you please give me some good pointers so that I build a good model, my coding skills are not every good so I would be really grateful for your advice",ObjectiveShower9133,6,1.0,8,https://www.reddit.com/r/learnmachinelearning/comments/17zj9b0/building_my_first_ml_model/
406,1700489533.0,Got STUCK IN CS229,"

I started the course before 15 days. As of now I have completed one assignment and one ps. Now in the 6th(SVM) and 7th(KERNAL) I am unable to understand the lectures. So I watched different yt videos got basic knowledge about these topic but not full. Is it okay to not deep dive into these concepts? Or should I take time to review these video again again until I totally get the concept.



Edit:-
Playlist:- https://youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&feature=shared

SVM:-https://youtu.be/lDwow4aOrtg?feature=shared
Kernels:- https://youtu.be/8NYoQiRANpg?feature=shared",infinity_bit,1,0.6,16,https://www.reddit.com/r/learnmachinelearning/comments/17zpepd/got_stuck_in_cs229/
407,1700475080.0,Beware column ordering,"Combined vent and word of warning for anyone else who finds themselves facing something similar - I thought I was getting pretty good at systematically checking everything is consistent but I just spent a bunch of time debugging why;
- First my model was giving non-dererministic AUC scores even with everything heavily seeded
- Even with an identical model, I was producing different outputs when I run a prediction if I start from a cold boot.

Turns out Pyspark (which I was doing this project to learn) doesn't always order columns the same way, even with identical instructions. Plus Pyspark's VectorAssembler doesn't pay any attention to column names. 

So not only can you get inconsistent models/predictions, the model for the predictions is basically randomised because your training set and test set can end up with different column orderings.

Kicking myself for not checking column ordering more thoroughly before now but it's a good learning.",dr_flint_lockwood,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17zlc6k/beware_column_ordering/
408,1700483382.0,What is semantic search and how does it compare to keyword search?,,davidmezzetti,1,1.0,0,https://medium.com/neuml/getting-started-with-semantic-search-a9fd9d8a48cf
409,1700482527.0,Successful Career Transition Of A Mechanical Engineer to Data Analysis!,,Reginald_Martin,0,0.5,0,https://hubs.la/Q029qlvs0
410,1700399215.0,"The background needed to understand ""Attention is All You Need"" Paper","Hi, 

My background is that I am by education a Mechanical Engineer and was in Grad school for quite a few years too. In my opinion the Attention is all you need paper is one of the most important papers for understanding how LLM are built and work. 

However, my background is woefully inadequate to understand the mathematics of it. What are some books and papers that I should read to be able to grok the paper, especially attention, and k,q,v matrices and how it is all operating? I like to think that I have fairly good mathematical maturity so don't hesitate to throw standard and difficult references at me, I don't want to read a common language explainer, I want to be able to write my own LLM, even though I might never have the budget to actually train it. ",Soc13In,54,0.94,22,https://www.reddit.com/r/learnmachinelearning/comments/17ywtkd/the_background_needed_to_understand_attention_is/
411,1700403175.0,What is a intuitive description of F1 score?,"Having a hard time making sense what this number represents, I “know” the equation but it still seems very abstract to me

Edit: a single sentence describing the F1 score’s intuition ",Ok_Reality2341,41,0.9,9,https://www.reddit.com/r/learnmachinelearning/comments/17yy1si/what_is_a_intuitive_description_of_f1_score/
412,1700404312.0,Naruto Justu Detection Using Machine Learning (Tensorflow.js & Mediapipe...,,Ben-Tiki,26,0.91,0,https://youtu.be/WIdbFbkq71k?si=6Ha9Hgjxm24PpF-S
413,1700464228.0,NLP vs Diffusion Model for Sentiment Analysis.,"Hello r/learnmachinelearning community,

I'm currently working on a research project that aims to explore the application of diffusion models (experiment) and NLP in sentiment analysis. I'm relatively new to these concepts and could really use some guidance and resources to steer me in the right direction.

1. **Project Overview**: My goal is to compare the effectiveness of diffusion models and traditional NLP models in analyzing sentiments and emotions in text data.
2. **Current Progress**: I have a basic understanding of NLP and diffusion models. However, applying these to sentiment analysis is where I'm seeking help.
3. **Specific Questions**:

* Are there any notable papers or studies that focus on using diffusion models for sentiment analysis in text base?
* Can anyone suggest open-source projects or source code examples where diffusion models have been applied to NLP tasks?  


Thank you guys.",AhmedHailane,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/17zitkc/nlp_vs_diffusion_model_for_sentiment_analysis/
414,1700463606.0,Advice for a user who wants to be more skilled,"I am doing my PhD using ML and applying certain deep learning methods to complex biological datasets in a way that is novel to my field but I have a nagging sense that I don't really understand what I'm doing, although I functionally get a lot of things. I want to be more than someone that just uses PyTorch libraries and the like. For my use case are there any resources that you might recommend? A book? A course? In undergrad I did math through ODE but it's been a while so I wouldn't mind a math refresher. Eventually I'd like to be skilled enough to test/implement my own algorithms since I think it would be helpful to my objectives.

Thank you so much for your time and consideration!",perhapsascientist,1,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/17zio1t/advice_for_a_user_who_wants_to_be_more_skilled/
415,1700448897.0,Is it possible to train models that can do inference on data of different dimensions than it's training data?,"TLDR; you can ignore a lot of the specifics, but essentially is it possible to train a model on training data of one size (A features, B columns, maybe even C subjects) and test it on data of a different size (eg D features, E columns, and F subjects). 

\- I don't see how it would be possible (although I have read some RNNs can work with variable sequence lengths, so changing numbers of columns, but I would like a model to be able to accommodate different numbers of features and subjects as well), but it seems like this should be a common problem. For instance, with medical data or other experiments, it most be a common that the training data is a huge number of patients but then you are testing the model on just one patient at a time, right? What do people do about this?

I am working a model with time series data coming from 256-channel recordings. Thus, the dataset (for each monkey) is 256x100\_000, where 100\_000 is the sequence length (how many time points are in the actual time series, essentially how many hours the trial goes on for and what frequency we are recording at, 100\_000 is obviously a very low bound). One big issue is that this 256 channel input is reduced to 9 ""channel"" output (dong regression to estimate the 9 axes of what an IMU would read based on the neural signals as the monkey completes a sorting task). And then our training data is M monkeys whereas we will only test the model on one monkey at a time...

Right now, I am losing my mind trying to get this to work such that I can have a training dataset of (14x256) x 100\_000 and then do inference/testing on data for a single monkey (eg 256x100\_000). Ideally, this model should also generalize to other hardware (for instance, if some of the channels breaks or are removed and we have 218 channels or whatever, I would expect the model to still work as the underlying data hasn't changed, only the way it is fed to the model. You can imagine that if we have 256 channels recording, a good number of them are redundant anyways. I could do dimensionality reduction on the channels, but can't do dimensionality reduction on the number of subjects/monkeys...). 

Is this possible? What do other people do? It seems like there must be a better solution to this problem...",Amun-Aion,2,1.0,6,https://www.reddit.com/r/learnmachinelearning/comments/17zejjv/is_it_possible_to_train_models_that_can_do/
416,1700426077.0,Bias-variance tradeoff in real example,"I'm taking a (not very good) course on machine learning. Throughout the course, and in many other sources I have seen online, they talk about a tradeoff between the square bias and the variance of a model's predictions, and how the total error is the sum of the two. This explanation is accompanied by a graph in which we see variance as a monotonically increasing (or decreasing) function of some measure of complexity, and bias as a monotonically decreasing (or increasing) function.

Now, we get to do some work. We get a data set (the superconduct dataset from OpenML), and are asked to measure the square of the bias, the variance, and overall error of estimations using different complexities of different models. However, when I plot the graphs, I don't see anything nearly as nice as what I was originally shown. In fact, sometimes I even see bias and variance changing in the same way. I feel I am doing something wrong, but I haven't found any obvious mistakes. Am I always expected to see such a clear tendency?",_between3-20,4,0.83,0,https://www.reddit.com/r/learnmachinelearning/comments/17z68sc/biasvariance_tradeoff_in_real_example/
417,1700453066.0,Books for Machine Learning Math,"I’ve had a hard time finding good resources to learn math for Machine Learning. Some are too simple and others too complicated. I’ve tried courses, but I think that’s not my thing.

Can you please recommend books that are not exactly for beginners, but begin with the basics and scale up to advance topics?

My background is in electrical engineering, so calculus is not a problem.",__academic__,1,0.67,0,https://www.reddit.com/r/learnmachinelearning/comments/17zfule/books_for_machine_learning_math/
418,1700427612.0,Fundamental papers to read when approaching ML,"I've just began my journey in studying Machine Learning at university. For months I've been looking forward to study and deepen the subject, so I was wondering which were the most important papers to read at this stage.
Hope you can give me good reccomendations.",BlurredByGauss,4,0.83,0,https://www.reddit.com/r/learnmachinelearning/comments/17z6t0l/fundamental_papers_to_read_when_approaching_ml/
419,1700462039.0,Understanding which laptop will be suitable for my ML needs,"I have to buy a macbook for machine learning. My budget is $2k. It has to be a mac.

My requirements:

I want to run and train ML and AI models. Maybe run open source LLMs like LLAMA. I guess im okay if the training and all is a bit slow, I care more about the results ( and laptop shouldn't be slow during other tasks )

Side question : will cloud services be a better option than training and running LLMs and other models on my mac ? If yes then please guide me.",abillionasians,0,0.33,17,https://www.reddit.com/r/learnmachinelearning/comments/17ziams/understanding_which_laptop_will_be_suitable_for/
420,1700429165.0,Test accuracy greater than training accuracy?,Is this possible? I presented my results to my professor and he said that it was odd and now I'm trying to find an explanation for this. My test loss is also less than my training loss. I currently have dropout in my classification layer but I don't know if that would be the cause of this.,tomcat_96,2,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/17z7ff1/test_accuracy_greater_than_training_accuracy/
421,1700442527.0,Classification interpretation and evaluation questions.,"I am following a blog post that performs sound classification. 

**How should I interpret my current results?**

I would like to know which filter is having better results (accuracy). However, the accuracy is always 100 on both models in Epoch stages,

 ( Epoch 1/100 29/29 \[==============================\] - 3s 57ms/step - loss: 0.3438 - accuracy: 0.8882 - val\_loss: 0.1285 - val\_accuracy: 0.9646 Epoch 2/100 29/29 \[==============================\] - 1s 45ms/step - loss: 0.0528 - accuracy: 0.9823 - val\_loss: 0.0320 - val\_accuracy: 0.9867 Epoch 3/100 29/29 \[==============================\] - 1s 46ms/step - loss: 0.0136 - accuracy: 0.9967 - val\_loss: 0.0291 - val\_accuracy: 0.9867 Epoch 4/100 29/29 \[==============================\] - 1s 45ms/step - loss: 0.0060 - accuracy: 0.9978 - val\_loss: 0.0156 - val\_accuracy: 0.9956 Epoch 5/100 29/29 \[==============================\] - 1s 45ms/step - loss: 0.0036 - accuracy: 1.0000 - val\_loss: 0.0204 - val\_accuracy: 0.9956 Epoch 6/100 29/29 \[==============================\] - 1s 45ms/step - loss: 0.0028 - accuracy: 1.0000 - val\_loss: 0.0183 - val\_accuracy: 0.9912 Epoch 7/100 

and Both does get the job done of classifying ocrrectly since it is such a simple model. I read that if the result is like the graphs below, it isn't the accuracte representation of the model or the model is weak (possibly with small dataset, 4 classifications with 200 data each). 

[filter 1](https://preview.redd.it/pvajru22je1c1.png?width=1320&format=png&auto=webp&s=d8afbc61816d20cbbc86ff13682c043b8d831b05)

[filter 2](https://preview.redd.it/v5z58yx6je1c1.png?width=1320&format=png&auto=webp&s=22dfffbbb1d4a82498e0df0fc7a30aee717d1607)

**How can I numerically get the evlaution of the models?**

I saw a function that does this

 

model.evaluate(test\_spectrograms, return\_dict=True)

&#x200B;

But it is returning 0s. 

&#x200B;

8/8 \[==============================\] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 

{'loss': 0.0, 'accuracy': 0.0}

&#x200B;

Is this the right function to use? From my understanidng, Tensorflow official example evlauted creating a evluation data before trainign and used comparison, but I am not sure if this is soemthing I can use and couldn't understand how it could be implemented.

&#x200B;

Any help would be appreciated! Thank you",Koolsam_301,1,0.67,1,https://www.reddit.com/r/learnmachinelearning/comments/17zcfcd/classification_interpretation_and_evaluation/
422,1700441699.0,2 A100 or 4 RTX 4090,Would like some input on my new build ASUS ESC8000 G3 all input is welcome,Soggy-Welder2265,0,0.5,7,https://www.reddit.com/r/learnmachinelearning/comments/17zc4p9/2_a100_or_4_rtx_4090/
423,1700419145.0,Best approach for a fine-tuning project,"In my spare time I'd like to fine-tune a model to act as my business analyst. I'd like to be able to give it text representing proprietary business data: mental models of certain business processes, research summaries, and various heuristics. The goal would be for it to respond to queries about current business conditions while being able to reference not just the original training data but all of my custom training. 

Is this possible for someone to do on a limited budget? Say <$5000. If so, how would you approach it. I've done some basic fine-tuning using pytorch and am willing to invest in better hardware or fine-tune on openai or elsewhere. Not sure what the state of the art for a small player is here.

&#x200B;

Thanks!",four_red_stars,3,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17z3on2/best_approach_for_a_finetuning_project/
424,1700471684.0,Ivy league schools worth it?," Is it worth it for a high school student to try really really hard to get into an ivy league college or is it more worth it for them to get an undergrad from a average college with a good understanding of maths,stats and practical ML? Also will the job market (in like 10 years) be responsive or prefer one or the other candidate for a particular job?

&#x200B;

For more context: I am in high school and wondering if I should learn more ML based stuff or get really good at acing school.",LabOpposite3248,0,0.33,15,https://www.reddit.com/r/learnmachinelearning/comments/17zkis6/ivy_league_schools_worth_it/
425,1700425902.0,installed ubuntu stuck,"Miniconda3-latest-Linux-x86\_64.sh: line 1: syntax error near unexpected token \`newline'

Miniconda3-latest-Linux-x86\_64.sh: line 1: \`<html>'

Hi I keep entering  bash Miniconda3-latest-Linux-x86\_64.sh  after enterting  curl [https://repo.anaconda.com/miniconda/M...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbXUxN0x2OWZUZGh6d0lVTFVHV0NOeEZhM0J2QXxBQ3Jtc0tuM2xwbTVjRjRhUlltNVgxQTQ1MTdqRUd0bFJsbWtKUkJXeWNMUDBSMUl6NXdTbnNlNEpNNHlxQXk4SjJYMmNhazhaV21lcnQ2Qmp4Y1d1TU9mMm5MM0VpYTlvUXJILW53N3J4VndXWDd2MlkyR1M5RQ&q=https%3A%2F%2Frepo.anaconda.com%2Fminiconda%2FMiniconda3-latest-Linux-x86_64.sh&v=gGog0djyTOc) \\      -o Miniconda3-latest-Linux-x86\_64.sh  in ubuntu. I can't seem to find an answer. I'm trying to get tensorflow working on my amd gpu.

I would very much appreciate it if you helped me.",Glittering-Target-87,2,1.0,6,https://www.reddit.com/r/learnmachinelearning/comments/17z66fx/installed_ubuntu_stuck/
426,1700436941.0,Help needed for converting .json files to a yolov8 .txt format, Hey! Does anyone know how to or have prewritten code and is willing to share about converting .json files to the yolov8 .txt format? I could do it by hand but that takes a stupidly large amount of time and the code that I tried so far hasn't worked out. I don't know what to do at this point. The .json file format I use is the labelme save format and I'm trying to convert it into the central x and y coordinate and width and height format in the 1x1 box used by yolov8 (ultralytics). Could anyone help? Thanks! ,6ct_gold,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17zafi4/help_needed_for_converting_json_files_to_a_yolov8/
427,1700412515.0,More classes for different kinds of activities or just the ones I'm interested in,"If I'm doing human activity detection, and I'm only interested in detecting one thing. For example say I want to detect going down stairs or not going down stairs. Also assume I have a dataset that has labeled accelerometer data for walking, driving, riding a bike, running, going upstairs, going down stairs and sleeping. Would I be better off training my CNN with 2 outputs: going down stairs and not going down stairs, or would I be better off training with all 8 output classes?

On one hand it seems like more output classes makes for a more complex model so I should just do the 2 I care about. On the other hand each class has distinct patterns and if I want to train on a balanced dataset I'll need to throw away a lot of my not going down stairs data.

Thanks",drulingtoad,3,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17z1a6i/more_classes_for_different_kinds_of_activities_or/
428,1700409083.0,I need advice for my final thesis in Graph Neural Networks.,"Hi,  I am preparing my final thesis in computer engineering. I currently planning out the work. My idea is to compare traditional approaches to building recommender systems to Graph Neural Network based approaches. The plan so far is to use the *Movie Lens 100k* dataset, which contains data on users, movies, and user-movie ratings. The task of the recommender system would be to predict the missing ratings for user A and recommend movies based on that (say top 5 highest predictions). I would present three approaches to this task:  


* Traditional content-based filtering approach
* Traditional collaborative filtering based approach
* Graph Neural Network 

Given this very general outline, would you guys say that this seems like a good project idea? ",Emergency-Light9519,3,0.8,4,https://www.reddit.com/r/learnmachinelearning/comments/17z01y4/i_need_advice_for_my_final_thesis_in_graph_neural/
429,1700409027.0,Object Detection with PyTorch Mobile,"🚀 Dive into \`Object Detection with PyTorch Mobile\` 📱🔍 Learn how to optimize YOLOv5 for mobile apps using PyTorch Mobile. Check it out! 

&#x200B;

Read here: [https://journal.hexmos.com/pytorch-mobile/](https://journal.hexmos.com/pytorch-mobile/)",djang_odude,3,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17z0182/object_detection_with_pytorch_mobile/
430,1700429558.0,An accessible and intuitive explanation of what Neural Attention really achieves,,AvvYaa,1,0.67,0,https://youtu.be/frosrL1CEhw?si=NKTqmRTieVkfCNlb
431,1700441508.0,Best IBM Certification courses for ML and Data Science,,Lakshmireddys,0,0.38,0,https://codingvidya.com/ibm-certification-courses/
432,1700427593.0,Has anyone worked with SMPLify-X library?,,doctor-squidward,1,1.0,0,/r/computervision/comments/17ye1t1/has_anyone_worked_with_smplifyx_library/
433,1700422610.0,Decision tree question,"I'm making a decision tree on data with two categorical classes and I'm trying to predict if observations come from class a or class b.  If a split in the tree leads to a terminal node that gives me a 60% probability of class a Is there a way to test whether this is by luck or statistically significant? In other words, is there a way to calculate the p-value of a split for a terminal node in a decision tree?",Traditional_Soil5753,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17z4yxp/decision_tree_question/
434,1700404838.0,What academic papers/textbooks do you recommend to learn about the ReLU activation function?,"CHAT GPT recommends the paper ""Rectified Linear Units Improve Restricted Boltzmann Machines"" by Vinod Nair and Geoffrey E. Hinton as it is one of the foundational papers introducing and exploring the benefits of ReLUs in neural networks. It also says it is a good starting point to learn about ReLUs and their advantages in machine learning models.

But, from your experience do you have any other papers or textbooks or even videos that you would recommend to someone learning about it? I don't mind if they're math heavy, as I do have a Bsc Honours in App Math.

Thanks!",fouried96,2,0.75,2,https://www.reddit.com/r/learnmachinelearning/comments/17yyluw/what_academic_paperstextbooks_do_you_recommend_to/
435,1700354965.0,Machine learning linear regression is driving me insane,"&#x200B;

https://preview.redd.it/khmi4jetd71c1.png?width=713&format=png&auto=webp&s=03552d17dc467b4f721f236d4e46953877577726

**\*\* I editted the coding part cuz it was not showing right I attached the pictures instead. please read again if you skipped the posting because the code looked like a mess**

**so for our company project,**

**I used the built in machine learning model through the Scikit learn and it worked wonderfully. I was able to get the trendline with the code above.**

**However, I wanted to build the linear regression from the scratch so I watched a lot of youtube videos including Professor Andrew at Stanford. I used some youtube videos and copy pasted the codes but also changed a few things however, this code does not work. The formula looks right but it never gets the trendline right.**

**the trend line is supposed to be around at -11. but the m just never gets there. also y intercept supposed to be around at 79000, and it never goes there. not even close.**

**Can someone help what's wrong with the codes below? Should I just be satisfied that I was able to get the right number by using the built-in function?**

&#x200B;

https://preview.redd.it/a4v43ao1e71c1.png?width=794&format=png&auto=webp&s=754f13f9813aa5a85dfe87714e1809ce1f132d6d

https://preview.redd.it/9sahk3h9e71c1.png?width=903&format=png&auto=webp&s=44dc83ae01f7b4e473dd3261fee4928c1a14647f

**It's really frustrating. Please help**",Money_Working_9702,17,0.85,7,https://www.reddit.com/r/learnmachinelearning/comments/17ykvon/machine_learning_linear_regression_is_driving_me/
436,1700409716.0,Need help diagnosing issue,"Hi, my training completely plateaus at a fairly high loss and I not too sure what's going on.

At the deeper end of my network, the parameters are creating a sort of horse shoe shape.

&#x200B;

Does anyone recognise what might be going on here?

My initial guess is maybe not enough training or poor gradient flow?

&#x200B;

https://preview.redd.it/3gwnnxmntb1c1.png?width=1812&format=png&auto=webp&s=b765f825965deea3754d3c0628c33bdc1a5e099c

https://preview.redd.it/od1cjftotb1c1.png?width=1807&format=png&auto=webp&s=939c586ca1ad8c55ec0f7504af3042778752bb65",NaOH2175,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17z0a50/need_help_diagnosing_issue/
437,1700368355.0,Diffusion Models | Math Explained in 29 minutes and 7 Questions,,tusharkumar91,7,0.9,0,https://youtube.com/watch?v=H45lF4sUgiE&si=nwmsUIaz9EBfzu8c
438,1700392679.0,TokenLearner: How to Reduce the Number of Tokens in Transformer,,SouvikMandal,2,1.0,1,https://medium.com/itnext/tokenlearner-60bf14248611
439,1700404620.0,I wanna create a ML project that can Change voice. Like an AI voice changer. How should i start and where can i get the datasets,,Spare_Fail_1731,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/17yyj3i/i_wanna_create_a_ml_project_that_can_change_voice/
440,1700404501.0,How should i start learning and implementing machine learning,,Spare_Fail_1731,0,0.33,0,https://www.reddit.com/r/learnmachinelearning/comments/17yyhjq/how_should_i_start_learning_and_implementing/
441,1700403679.0,Proportion and regression equation,Hi everyone! I am using RStudio to conduct a regression model and I noticed the difference in proportion I calculated using percentages from the Cross Table is the same as the estimated coefficient. Could anyone help me understand why is that?,Top_Pianist1841,1,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/17yy7r5/proportion_and_regression_equation/
442,1700399544.0,Learning with Logical Constraints,,Neurosymbolic,1,0.67,0,https://youtube.com/watch?v=10gERXLjzYU&si=7jORnnoqCMnysEIJ
443,1700398686.0,Implementing AI in real world problems,"Hello everyone, i participated in a hackathon this weekend and i wanted to implement a ML model to solve the given problem. I faced a problem while collecting datasets, i didnt really find any helpful datasets in Kaggle or Hugging Face so i dropped the idea from the MVP solution. I wanna know how can implement ai models to solve some specific real world problems in the future like the one they gave us and thank you.",Ready_Seesaw8408,0,0.5,3,https://www.reddit.com/r/learnmachinelearning/comments/17ywnmm/implementing_ai_in_real_world_problems/
444,1700398032.0,"How to learn to understand, use ML models?","I am a javascript/MERN stack developer. I've been trying to developing apps that utilize open source ML models (especially  LLMs). But only a few can be used directly in javascript. 

I just want to learn how to understand, use ML models (not create them from scratch). I would guess i need to learn some library like tensorflow/pytorch, and how to host models on google colab etc.

(currently i only know basic python) 

I would appreciate a step by step roadmap (i can give around 2 months to this) ",shashj546,1,0.6,3,https://www.reddit.com/r/learnmachinelearning/comments/17ywh7o/how_to_learn_to_understand_use_ml_models/
445,1700356554.0,Developing Image Classification API,"I already have a trained image classifier, but I do not have experience deploying machine learning models.  


What am planning to do:

1.- Create a simple API with FastAPI that receives the image, and return the prediction  
2.- Containerized  
3.- Uploaded to a lambda service in AWS  


This is a broad overview  


Is this the correct way to do it? Any recommendations?",AfraidAd4094,9,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/17yleis/developing_image_classification_api/
446,1700326160.0,Advice for beginner who is weak at math,"I am not very good at math. I have basic understanding of linear algebra, probability, random variables, etc but not very good at solving questions.

What are the recommended resource I should start from ? does fast.ai require a lot of math ? 

And resources for math are highly appreciated too.",user655362024,31,0.83,17,https://www.reddit.com/r/learnmachinelearning/comments/17yaj1v/advice_for_beginner_who_is_weak_at_math/
447,1700362655.0,I need a model that can detect the front of cars [P],"

Hey everyone I’m new to Ai and dataset training but I’m on a bit of a time crunch and don’t have time to train a model that can detect the front of cars is there a retrained model that anyone knows of that I can use? It’ll be helpful.",Mylesallsmiles,3,0.67,3,https://www.reddit.com/r/learnmachinelearning/comments/17yncr7/i_need_a_model_that_can_detect_the_front_of_cars_p/
448,1700365935.0,Federated Learning resources,"Specifically, I'm interested in:

What are some beginner-friendly resources to get a solid foundation in federated learning?


What tools or frameworks are best for implementing federated learning models?",Ok_Reality2341,3,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17yocr6/federated_learning_resources/
449,1700373128.0,Can Reinforcement Learning Be Used for Structural Design?,"We all know the classical situation of the RL Agent iteratively improving to maximize the reward received in relation to some objective in an environment.

But what if we're more interested in improving our environment in relation to an agent that remains unchanging?

For example, suppose our environment is a ventilation duct and our agent is molecule(s) of air?

In RL we've all seen the use of physics engines involving kinematics, but what if we're only interested in statics (ie. the branch of physics dealing with static loads, as used in architecture)?

Instead of only using RL to generate a better Policy, can we use it to generate better structures (ie. static structures)? Can a policy translate into a structure?

Any answers or feedback would be greatly appreciated, including even URL links.",san__man,0,0.5,1,https://www.reddit.com/r/learnmachinelearning/comments/17yqag1/can_reinforcement_learning_be_used_for_structural/
450,1700358709.0,How is open-world classification implemented?,,WadeEffingWilson,2,1.0,0,/r/datascience/comments/17ykajp/how_is_openworld_classification_implemented/
451,1700342325.0,Feature Engineering for Predicting Repurchase - using days since last purchase,"Hi guys! I want to predict if a person who has bought one consumable on an app will repurchase within the next month or not - so a binary problem. 

One of the features I wanted to use was days since first purchase. But I feel like if I go down that route, a person can appear multiple times in the training set. For example, if it’s been 3 days since their first purchase, they will appear 3 times in the training set, with the outcome variable being 0 each time. 

If, on the other hand, I were to use each person only once in the training set, I wouldn’t know how to implement something like days since last purchase, which I feel is an important feature. 

I’m wondering what to do here, because I am quite stuck. How did you guys approach this problem, or something similar?",ShayBae23EEE,2,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/17ygbhz/feature_engineering_for_predicting_repurchase/
452,1700350830.0,Regression problem driving me insane,"Working on a simple regression model but I'm running to key errors that don't make sense:

    numeric_transformer = Pipeline(steps=[(""scaler"", StandardScaler())])
    
    categorical_transformer = Pipeline(steps=[(""encoder"", OneHotEncoder(handle_unknown=""ignore""))])
    
    # Define features
    numeric_features = [""Sales"",""Resale"",""Price_in_thousands"",""Engine_size"",""Horsepower"",""Width"",""Length"",""Curb_weight"",""Fuel_capacity"",""Fuel_efficiency"",""Power_perf_factor""]
    
    categorical_features = [""Manufacturer"",""Model"",""Vehicle_type""]
    
    # Create ColumnTransformer
    preprocessor = ColumnTransformer(
        transformers=[
            (""num"", numeric_transformer, numeric_features),
            (""cat"", categorical_transformer, categorical_features)
        ]
    )
    
    clf = Pipeline(
        steps=[(""preprocessor"", preprocessor), 
               (""regression"", LinearRegression())
        ]
    )
    
    X = df[[""Resale"",""Price_in_thousands"",""Engine_size"",""Horsepower"",""Width"",""Length"",""Curb_weight"",""Fuel_capacity"",""Fuel_efficiency"",""Power_perf_factor"",
          ""Manufacturer"",""Model"",""Vehicle_type""]]
    y = df['Sales']
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    
    clf.fit(X_train, y_train)

Error: "" **KeyError**: 'Sales'  
But ""Sales"" is present in y. 

I ought the issue might be that y is a series, so I tried: y = y.to\_frame(). Same error. What am I missing?

&#x200B;

Data source: [https://www.kaggle.com/datasets/gagandeep16/car-sales](https://www.kaggle.com/datasets/gagandeep16/car-sales)",Tyron_Slothrop,0,0.5,7,https://www.reddit.com/r/learnmachinelearning/comments/17yjgca/regression_problem_driving_me_insane/
453,1700337130.0,How to fine-tune LLMs using LoRA - Explained,"Hi there,

I've created a video [here](https://youtu.be/CNmsM6JGJz0) where I explain how you can fine-tune large language models using low-rank adaptation (LoRA).

I hope it may be of use to some of you out there. Feedback is more than welcomed! :)",Personal-Trainer-541,2,0.75,0,https://www.reddit.com/r/learnmachinelearning/comments/17yefo2/how_to_finetune_llms_using_lora_explained/
454,1700323062.0,Grad school focusing on CS or Mathematical Statistics best suited for my research interest?,"Hi,

Sorry that this is a repeated question in this sub but I wanted to take your intake for my specific situation. 

I'm a data analyst with 1 year of industry experience. I'm fed up with the boring, daily grind of industry work and I've always loved research. I'm contemplating further education in machine learning, specifically a research-oriented masters and/or PhD, but I'm a bit torn between CS and Mathematical Statistics. I'm not that much interested in popular ML topics like language models, image/video generation. I like working with structured data. My research interests lie in developing fast, scalable ML algorithms (think ensembled algorithms like LightGBM, CatBoost), time series analysis, and causal inference from observational data.

My background is in applied statistics, and I also know ml-related CS fundamentals like data structures & algorithms, computational complexity. However, I've noticed that much of the work in areas like algorithms such as LightGBM, CatBoost, modern time series analysis tools (LSTM, GRU, FB Prophet, Amazon DeepAR), and various time series classification and clustering algorithms has been predominantly led by folks in CS (with the exception being causal inference).

This observation leads me to question the necessity of deep, grad school-level mathematics knowledge typically covered in Stat graduate programs, such as advanced real analysis, measure theory, functional analysis, etc., for these fields. It seems like the required statistical knowledge can be acquired as needed.

So, here's my big question for the community: Given my research interests, should I be pursuing a graduate degree in CS or in Statistics? I would love to hear your thoughts, especially if you've navigated a similar path.

Appreciate any insights or advice you can offer!

PS: Please excuse me for any grammatical/sentence structure errors. I'm not a native English speaker.",No-Emphasis-4541,4,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17y9gbh/grad_school_focusing_on_cs_or_mathematical/
455,1700345792.0,Statistical analysis on dataset- learning resources required,"I am looking for online resources to learn statistical analysis techniques on datasets, like p-values, z-scores, measure feature importance etc.

Any help and guidance in this regard will be helpful. Thanks.",Daskoh_vi,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17yhm83/statistical_analysis_on_dataset_learning/
456,1700294914.0,The 5 Best Vector Databases You Must Try in 2024,,kingabzpro,6,0.75,5,https://www.kdnuggets.com/the-5-best-vector-databases-you-must-try-in-2024
457,1700311812.0,"[P] I built SRec.ai, a Steam video game recommender",,ilos-vigil,2,1.0,1,https://srec.ai/
458,1700322291.0,"Best Machine Learning Courses on Udemy beginners, advanced -",,Lakshmireddys,1,0.67,0,https://codingvidya.com/best-machine-learning-courses-on-udemy/
459,1700320837.0,Matrices: [inputs x outputs] or [outputs x inputs]?,"Consider a layer with M neurons, and thus M outputs. Let the layer have N inputs and be fully connected (every inputs is connected to every neuron).

Then this layer will have NM weights. Let these weights be represented by a matrix . What is the common practice in research: to use a matrix of N rows and M columns, or to use M columns and N rows?

The following is not part of the question, so let it not influence you in case I am wrong. What I understand at the moment is that a matrix is denoted as 'Rows x Cols' in this field, and (according to \*cough\*ChatGPT4\*cough\*) it is 'outputs x inputs', so the answer would be that the weights matrix W is an M x N matrix. This also means that if X is an input column-vector, we need to multiply WX to get the output: after all, when we see X as a matrix of N rows and 1 column (N x 1), the number of columns of the first matrix must equal the number of rows of the second matrix: \[M x N\]\[N x 1\] = \[M x 1\], thus the result is a column-vector of M elements.

The reason I ask is because ChatGPT confused me by giving an inconsistent example that used inputs \* weights (XW) using a 2x1 tensor for the weights (2 inputs, 1 output: this was a single neuon). The result is still the same, but it is inconsistent with the notion that 'outputs x inputs' is common.",CarloWood,1,0.67,8,https://www.reddit.com/r/learnmachinelearning/comments/17y8ofr/matrices_inputs_x_outputs_or_outputs_x_inputs/
460,1700288668.0,How are educative.io ML courses?," I am a software engineer looking to review machine learning and learn the practical tasks required for machine learning in real-world applications. I've noticed that educative.io has quite a few relevant courses that seem interesting ([https://www.educative.io/module/ml-for-software-engineers](https://www.educative.io/module/ml-for-software-engineers) is one course I am looking into). I'd like to know more about the ML courses on this site. If this site is not recommended, please suggest other good courses or platforms.

I am ",czechrepublic,5,1.0,4,https://www.reddit.com/r/learnmachinelearning/comments/17y09jk/how_are_educativeio_ml_courses/
461,1700319411.0,Programming and mechanical engineering,I am a mechanical engineering student I am very interested and fascinated by machine learning. I have chosen python as it is very user friendly. But I am having a hard time doing programming things like CAD and CAE are very hands on but learning programming is not at least for me. Any tips for that. Also every other course I find is just bull crap any good hands on course on YouTube for mechanical engineers learning machine learning. Please help.,AromaticEconomics113,1,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/17y86qu/programming_and_mechanical_engineering/
462,1700300428.0,Where should I start in order to create recommendation system?,"I'm developing a website for my graduation project for my undergraduate degree, and I would like to add a book recommendations system to the website.

I have found Goodreads data set, which I will also be using to poupulate my database with, and I'm planning to use that to train any model I might create.

Although I have taken tutorials ML and some courses on AI, I'm not skilled or experienced in it at all. I believe I have enough time to study and create the model for the system. However, I'm not sure where to start.

So do you have any advice for me on how to approach this?",Ok_Perspective599,2,0.75,1,https://www.reddit.com/r/learnmachinelearning/comments/17y2zzo/where_should_i_start_in_order_to_create/
463,1700231998.0,I know machine learning but I don't,"Ok so hear me out. I am fairly decent in all of python, knwoing some machine learning algorithms' workings (I can probably learn ones I am not good at). I also knw, in general, what feature engineering and data wrangling are about.   


Now what I miss out on is all the more practical nuances like how do you know if your features are good, how to detect what is causing low accuracy, what approach algorithm to use in a given situation (How can you decide which one). the reflexes that distinguish the craftsman who is good from the guy who kinda knows a bit about this stuff. 

&#x200B;

So what are sources I can learn that from in a way that reiterates what I already know the least? I do not mind videos but I prefer books. Thanks in advance",NightPast9276,45,0.88,40,https://www.reddit.com/r/learnmachinelearning/comments/17xginj/i_know_machine_learning_but_i_dont/
464,1700285963.0,Stable_Baseline3 render is being Glitchy.," I recently installed Ubuntu 20.04 on my Windows 10 system. I created a virtual environment using Python 3.8.10 and installed SB3 by its guidelines ""pip install stable-baselines3\[extra\]"" When I ran the example of how to train and run A2C on a CartPole environment on the SB3 documentation the training went fine but the rendering is glitchy and framey as shows with the photo. Any help and advice will be greatly appreciated. 

https://preview.redd.it/kd8vfxf3n11c1.png?width=668&format=png&auto=webp&s=c443b26f7bd11adc1633ff99d8700fcaab99641a",AdrianR956,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17xzke5/stable_baseline3_render_is_being_glitchy/
465,1700297801.0,Steps to learn Machine Learning for interviews.,"I wanna relearn Machine Learning concepts to clear interviews. I am able to do projects on my own using the internet. I can usually learn whatever I need for the project on the go and build it. However, I need to know the other surrounding information to better my knowledge. What route should I take to learn the theoretical concepts and how to practice them for interviews?  


&#x200B;",tondlilover,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17y2e3j/steps_to_learn_machine_learning_for_interviews/
466,1700297800.0,Steps to learn Machine Learning for interviews.,"I wanna relearn Machine Learning concepts to clear interviews. I am able to do projects on my own using the internet. I can usually learn whatever I need for the project on the go and build it. However, I need to know the other surrounding information to better my knowledge. What route should I take to learn the theoretical concepts and how to practice them for interviews?  


&#x200B;",tondlilover,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17y2e3a/steps_to_learn_machine_learning_for_interviews/
467,1700294246.0,Predicting gearbox breakdown in wind turbine,"In my master thesis I want to predict when a gearbox is going to brake in an offshore wind turbine.

I have SCADA data for 10 years of operation and I have one gearbox breakdown occuring I this period.

Due to the sarce number of breakdowns I am doing a normal behavior model e.g. to train the model on healthy data and then to test it on the data with the breakdown to hopefully see an increase in residuals.

Currently I am able to predict the output variable (gearbox oil temperature) with and R^2 of 81% however I do not see and increase in residuals when testing.

Does anyone have any advice?",No_Seaworthiness5468,1,0.67,2,https://www.reddit.com/r/learnmachinelearning/comments/17y1l84/predicting_gearbox_breakdown_in_wind_turbine/
468,1700255912.0,CPU training 10x slower than expected?,"Hi - please forgive the incredibly noob question. I'm an experienced python coder but this is my first foray into model training.

I'm following this example:[https://www.youtube.com/watch?v=yuUnBjQclkA](https://www.youtube.com/watch?v=yuUnBjQclkA)

He's training a simple model on his cpu, and gets 3 it/s. I'm running on a i7-8700 CPU @ 3.20GHz and getting 0.27/s. Why is mine so much slower? I know that cpu is not optimal, but I'm wondering if this is indicative of me doing something very wrong.

Here is the code which I copied exactly. Running clean python 3.11 venv in pycharm/jupyter.

    model_name = 'distilgpt2'
    device = 'cpu'
    
    from transformers import AutoTokenizer, AutoModelForCausalLM
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    tokenizer.pad_token = tokenizer.eos_token
    
    model = AutoModelForCausalLM.from_pretrained(model_name)
    
    
    import pandas as pd
    
    df = pd.read_csv(r""D:\Downloads\archive\wiki_movie_plots_deduped.csv"")
    
    
    df = df[:1000]
    
    from datasets import Dataset
    
    def map_dataset(batch):
        return tokenizer(
            batch['Plot'],
            truncation=True,
            max_length=128,
            return_overflowing_tokens=True
        )
    
    dataset = Dataset.from_pandas(df)
    dataset = dataset.map(
        map_dataset,
        batched=True,
        batch_size=8,
        remove_columns=list(df.columns)
    )
    
    dataset = dataset.remove_columns(['overflow_to_sample_mapping'])
    
    dataset = dataset.train_test_split(test_size=0.2)
    
    
    from transformers import DataCollatorForLanguageModeling
    
    data_collator = DataCollatorForLanguageModeling(
        tokenizer=tokenizer,
        mlm=False
    )
    
    
    from transformers import TrainingArguments, Trainer
    from tqdm.notebook import tqdm
    
    training_args = TrainingArguments(
        output_dir = ""./output/model"",
        evaluation_strategy='epoch',
        learning_rate=2e-5,
        weight_decay=0.01,
        num_train_epochs=10
    )
    Trainer.tqdm = tqdm
    trainer=Trainer(
        model=model,
        train_dataset=dataset['train'],
        eval_dataset=dataset['test'],
        args=training_args,
        data_collator=data_collator
    )
    
    trainer.train()

&#x200B;

&#x200B;

&#x200B;",four_red_stars,5,0.7,2,https://www.reddit.com/r/learnmachinelearning/comments/17xpcwq/cpu_training_10x_slower_than_expected/
469,1700273564.0,Seeking Guidance: Running ML Applications on Ray Clusters with Jupyter Notebook,"Hey Redditors,

I'm currently exploring the possibilities of running machine learning (ML) applications on Ray clusters using Jupyter Notebook. I've been reading up on the topic and came across the blog post ""Scaling AI and Machine Learning Workloads with Ray on AWS"" that discusses the integration of Ray with AWS services for efficient scaling and deployment.

However, I'm still in the early stages of understanding how to set up and configure the environment properly. I would greatly appreciate some guidance and advice from the experienced members of this community who have experience working with Ray and Jupyter Notebook.

Specifically, I'm interested in running ML applications on Ray: 

1) Setup integration of Jupyter Notebook and ray cluster

2) Running ML applications on the Ray cluster. 

How do you compose a jupyter notebook to deploy ML app to ray cluster? Are there any specific libraries or frameworks that work well with Ray for ML tasks? 

If you have any experience or knowledge in these areas, I would be grateful for any guidance, resources, or tips you can provide. 

Thank you in advance for your support and expertise! Looking forward to your responses and discussions!",confusedndfrustrated,2,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17xvuam/seeking_guidance_running_ml_applications_on_ray/
470,1700255578.0,Perceptron 2?,"This is merely philosophical. I read parts of an old early machine learning book today and I have some questions (Artificial Intelligence by Luger, 4th ed.) 

Why does a model from 1958 make up the majority of networks? The percepton. Is it possible with current computing power to add more weights (or maybe better, pairs of weight and a bias) to a ""neuron"" that closer models how real-life synapses work? Would this allow non-linear models in a single cell? Would it mean smaller networks would be needed? Could one 'neuron' fire repeatedly when activated, sending a 'pulse' of inputs for just one input? Maybe the network could figure out the best 'neuron type' e.g. single pulse on activation, repeated pulses (or variable lengths), or no-op. 

Can networks create/extend themselves instead of being created at the start of training? That is, to add extra groups of neurons to form a network of mini-networks as necessary (if it finds a new feature / pattern) and to figure out how to connect to it by allowing some of the existing network/s to e.g. connect to the top-most layer, whilst other parts may connect in the middle and bypass certain 'layers'. 

Would this be some form of transfer learning?

What would all of this be called as I guess it goes against current mathematical research built on the simplistic perceptron.",Mean_Actuator3911,3,0.6,1,https://www.reddit.com/r/learnmachinelearning/comments/17xp8al/perceptron_2/
471,1700267341.0,How do I implement custom error functions for ML libraries?,"I don't want to rewrite the entire MLP, regression, etc. algorithms in sklearn just to implement my custom cost function and relevant derivative.  Is there a way for me to define a function any classifier can use to override the default?  This is an example of what I'm looking for:


```

def myCustomError(y_preds,y_actuals):

    #algorith

    return #not MSE


from sklearn import #Classifier


c = #Classifier(loss=myCustomError)


```

To be more specific, my error is one-sided (like a price is right scenario).",chilltutor,2,1.0,6,https://www.reddit.com/r/learnmachinelearning/comments/17xtoq6/how_do_i_implement_custom_error_functions_for_ml/
472,1700221641.0,Dataset containing both categorical and numerical features.,"I have a dataset containing details of old cars and their prices. Based on this data I have to build a model for predicting the price of a car. Features are mix of categorical and numerical. Categorical data includes car manufacturer, fuel type, number of ex owners, seller type, and no. Of seats. Numerical continuous data includes engine capacity, maximum power, mileage and distance driven. How do I do feature selection and which model will be best to try out for such kind of data ? 

I know I can find correlation in the case of numerical data but what to do about categorical data? 

I'm very new to ML.",AccidentHour1068,10,0.92,12,https://www.reddit.com/r/learnmachinelearning/comments/17xdb34/dataset_containing_both_categorical_and_numerical/
473,1700222416.0,"AI Portal Gun: A Comprehensive Open Source Guide to Free AI Resources for Mastering Artificial Intelligence – Books, Courses, Articles, Research Papers, Codes, Projects and More.",,Jiraiya27s,8,0.91,0,https://www.portalgunai.org/
474,1700261645.0,Data science and machine learning books for interviews,"Hello thread. I am going to graduate in may 24 and wanted to get some great resources to refer to for interview prep. I have been following Statquest and whoever stumbles upon this thread in the future, start from there.

I just wanted to gather some of the resources that are freely available to a student like me who cannot afford costly books.",tony_stark_9000,1,0.67,0,https://www.reddit.com/r/learnmachinelearning/comments/17xrl3s/data_science_and_machine_learning_books_for/
475,1700291036.0,predicting irregular heartbeat (when next beat will be)?,"this is not based on human or animal heartbeat and serves as an exercise only.


if using xgboost, we were to try and predict two things: when next heartbeat will be (assuming time elapsed per heartbeat in seconds is irregular), and if next heartbeat will be the last, how do we achieve this in xgboost?


so I have data like:

3 seconds, alive beat

8 seconds, alive beat

:

:

7 seconds, alive beat

9 seconds, dead beat



how to use xgboost to predict both seconds until next beat, and if alive or dead beat? classification would only let me predict alive or dead beat, and regression would only let me predict seconds until next beat and not if alive or dead beat.


thank you.",oniongarlic88,0,0.33,2,https://www.reddit.com/r/learnmachinelearning/comments/17y0uc4/predicting_irregular_heartbeat_when_next_beat/
476,1700220943.0,"Training outlier detection on a dataset without outliers. Or, I'm on the right track?","I'm experimenting with outlier detections. I have a dataset on a domain problem I know well (taxes), with real data and tried to apply the isolation forest algorithm on it. After some model tunning, manual dataset inspection and learning more about the algorithm I came to the conclusion that there are no outliers on this dataset.

My question is: what can I do on the training step so that I can use this dataset to detect outliers on new data? Does it makes sense to ""inject"" outliers using random data using the proportion of the contamination parameter? Like if I set the contamination=0.1 then inject 10% of random fake outliers.

Or for these cases it makes more sense to use the Novelty Detection approach?",detinho_,3,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17xd4qe/training_outlier_detection_on_a_dataset_without/
477,1700235728.0,Augmenting pre-trained segmentation model with new classe,"I'm sorry if what i'm asking is stupid, but i'm really confused and not sure if i'm even approaching this correctly.

&#x200B;

**What I'm trying to do:**

Take an existing pre-trained model (for example YOLOv8 trained on COCO) and use it as the starting point in the model i'm trying to build that needs to segment two classes (crop vs weed), though adding a third 'background/soil' class would be nice too.

**What data i have:**

I have 100 crop images consisting of crop, weeds and background. No fourth object is present in the dataset. I also have the vegetation masks separating weeds + crop from background and also another set of 100 masks that separate weeds from crop and from background in the same image (two different intensities for vegetation and black for background).

**How I think this should be approached:**

As i would ideally separate crop from weeds and backgrounds, i think i need to take the mask that contains the two classes and the original images, convert them to the format used by coco, take the pretrained model and use it to train again on my new data. Also dropping the default 91 classes and adding a new output layer with just my three classes. Am i too far off? Do i need to separate the masks with the two combined classes into two separate sets (meaning 100 images + 100 mask1 + 100 mask2) ?",SammathNaur,0,0.5,0,https://www.reddit.com/r/learnmachinelearning/comments/17xhv0o/augmenting_pretrained_segmentation_model_with_new/
478,1700227562.0,From zero to hero with LLMs. Start with Large Language Models in 2023,,OnlyProggingForFun,0,0.5,0,https://youtu.be/58XmJxb1x_o
479,1700226580.0,AI vs. Machine Learning vs. Deep Learning: Know the Differences,,Emily-joe,0,0.5,0,https://www.artiba.org/blog/ai-vs-machine-learning-vs-deep-learning-know-the-differences
480,1700220041.0,How to choose weights for VotingRegressor?,"I have multiple models that are used in VotingRegressor i have used defaults weights like \[1,1,2,1\] is there any method, that gives optimal/best weights for each models? ",_Killua_04,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17xcwgd/how_to_choose_weights_for_votingregressor/
481,1700188447.0,The Ultimate Self-Attention Guide: The reason it is a Game-Changer for AI,,AvvYaa,3,0.8,0,https://youtu.be/4naXLhVfeho
482,1700170460.0,AI/LLM starter kit in open source repo,"Share a Github repository to quickly build and start a local application to chat with private documents. The stack used is python,  [\#LangChainAI](https://www.linkedin.com/feed/hashtag/?keywords=langchainai&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7130952995793489920) , [\#qdrant\_engine](https://www.linkedin.com/feed/hashtag/?keywords=qdrant_engine&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7130952995793489920) [\#Ollama\_ai](https://www.linkedin.com/feed/hashtag/?keywords=ollama_ai&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7130952995793489920) and [\#FastAPI](https://www.linkedin.com/feed/hashtag/?keywords=fastapi&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7130952995793489920)  
)  
[https://github.com/mallahyari/ai-starter-kit](https://github.com/mallahyari/ai-starter-kit)   
",linamagr,7,0.82,6,https://www.reddit.com/r/learnmachinelearning/comments/17wy4aw/aillm_starter_kit_in_open_source_repo/
483,1700208040.0,Change clothes,Change clothes,AdOtherwise5785,0,0.5,2,https://www.reddit.com/r/learnmachinelearning/comments/17xa5yk/change_clothes/
484,1700206284.0,Educative.io subscription to share,"I have 10 months educative.io subscription and I am looking to sell it as I am interested in UI/UX Design where educative.io doesn’t help. If anyone is interested, ping me in the DM. I am also interested to share for 4 people ( 3k per person)",Accomplished-Club172,1,1.0,3,https://www.reddit.com/r/learnmachinelearning/comments/17x9rtb/educativeio_subscription_to_share/
485,1700203394.0,Data Science Roadmap 2024 - Everything You Should Know!,,Reginald_Martin,1,0.6,0,https://hubs.la/Q029d0Q_0
486,1700147613.0,Matrices in real life ML,"I am a ML beginner. I have seen most courses on math for machine learning give a strong emphasis on matrices. But they rarely give examples on how this is used in a real ML project. 

The only scenario I can think of for using a matrix computation is in an inner layer for a neural network having to do some matrix multiplication to apply weights. What else are matrices used for? And, is that scenario I gave even an intuitive one? Any help is appreciated.",tronybot,17,0.87,23,https://www.reddit.com/r/learnmachinelearning/comments/17wp8h0/matrices_in_real_life_ml/
487,1700202410.0,Machine Learning for Social Network Analysis,Does anyone know any books or resources on applying machine learning to social network analysis? Something like node/link prediction or clustering of nodes.,,1,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17x8uvf/machine_learning_for_social_network_analysis/
488,1700182343.0,Need help with creating a conversational AI chatbot that is only trained on business data.,"I'm not sure where to ask this, but I need help looking for a solution to create and host a conversational customer service representative that would reply to customer questions and needs based on data that it was trained on. I am very undereducated on this and trying to learn as I go. Can someone point me in the right direction of what I need to learn and understand to make this happen?

Is something like this in the right direction? https://www.youtube.com/watch?v=Rv9Jz68dRUI",ooAlias,2,0.75,5,https://www.reddit.com/r/learnmachinelearning/comments/17x2oau/need_help_with_creating_a_conversational_ai/
489,1700194208.0,Reduce Color Noise in Pixel Art Model?,"So recently I have been trying to program a Tensorflow and Keras based model that can animate pixel art characters. I use a Variation Auto Encoder with Convolutions, Dense Layers and Upsampling 2d layers. One of the major problems that I have been facing is that the generated images tend to be very noisy and complex when it comes to color selection. Normally this would be fine for more realistic images but I'm aiming for more of a pixel art and voxel look. Does anyone know of an optimizer, loss function, special layer or some other trick to potentially limit or disencourage the model from using a lot of different types of colors.

TLDR: I want to punish my Variatonal Autoencoder image generation model more for using a lot of different colors or reward the model for using less colors while still letting it make creative decisions.

[Target Image](https://preview.redd.it/bspyjxnl2u0c1.png?width=806&format=png&auto=webp&s=1eeb42f2e5581ec85fdf25813bc9f1e139a7f3f0)

[Generated Image](https://preview.redd.it/l8syhskn2u0c1.png?width=798&format=png&auto=webp&s=3d240cf6a0d49c25c397aa67b016dab275082912)

&#x200B;

&#x200B;",Embarrassed-List-209,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17x6mp9/reduce_color_noise_in_pixel_art_model/
490,1700162135.0,What are some machine learning problems that could be best solved without using any machine learning?,"For example, intelligent traffic system for traffic congestion could be solved by **not allowing so many cars on the road** ([r/fuckcars](https://www.reddit.com/r/fuckcars/)) as opposed to modelling the reward function of all drivers and pedestrains during all times of the day and then constructing optimal traffic light cycle using A3C on a TPU cluster.",fromnighttilldawn,5,0.63,15,https://www.reddit.com/r/learnmachinelearning/comments/17wux04/what_are_some_machine_learning_problems_that/
491,1700192779.0,Tips for starting a Machine Learning proyect from scratch? (I need to predict future data),"I have a really large dataset and the output needs to be really precise. 
I'm trying to figure out what should i use
-Model
-Languages
-Tensorflow or Pythorch
-Etc

Any help would be greatly appreciated!",Matnaranjo,0,0.46,19,https://www.reddit.com/r/learnmachinelearning/comments/17x6815/tips_for_starting_a_machine_learning_proyect_from/
492,1700147120.0,Training an LLM to have my friends personality,"Im a Software Engineer looking to learn a bit about ML, and decided a fun first project would be to train an LLM that has my friend's personality.

I have about 22,000 discord messages from my friend, stored in json format. I could get maybe a few thousand more.

So far, I've been able to get the model to use my friends (lets call him Dylan) words and generally have his personality, but it still isn't forming coherent responses. For example, to the question ""What's your opinion on Steve?"" Dypan's LLM might respond ""Steve has the skill to be a good player, but isn't quite there yet. He has the potential to be a pro"". But to the question ""What's your favorite game?"" It would respond ""it's a good game and I had fun playing it, but I don't know if it's a good game"". Pretty nonsensical.

My LLM is fine tuned using GPT2. I trained it for roughly 9.5 hours overnight on a 3080, with a batch size of 32 and gradient accumulation steps at 32. The training resulted in a loss of 4.09. From what I understand, this loss is extremely high.

I think it would be better if I included messages from other people - essentially giving the LLM context (this is how Dylan responds to these words). Can any provide guidance on how to do this? I've done research but can't seem to find anything helpful.

Thank you in advance!",travy_burr,11,0.87,16,https://www.reddit.com/r/learnmachinelearning/comments/17wp1p7/training_an_llm_to_have_my_friends_personality/
493,1700148750.0,How to cut tree in a agglomerative hierarchical clustering?,I want to understand how number of clusters are decided in hierarchical clustering. The part I do not understand is that SciPy package offers cut tree method which asks for number of clusters or height. So how do we decide that?,DayEducational4347,9,1.0,11,https://www.reddit.com/r/learnmachinelearning/comments/17wpome/how_to_cut_tree_in_a_agglomerative_hierarchical/
494,1700164049.0,Which Kind of Machine Learning should be used for Parallel Pumping Energy Efficiency Optimization?," Hello everyone

I'm about to start writing my bachelor in Mechatronics and for this project I want to work with some kind of machine learning. The system I work with is a parallel pumping system for a cooling system. I have 2 years of data sampled every 10 minutes available of the power, pressure, flow and other necessary variables.

I've seen some other papers implementing neural networks. Is that the only solution to this kind of problem?

I'm not that knowledgeable about machine learning, so I was hoping some of you bright minds might help enlighten me in which direction I should go :)

Thank you for taking the time to read!",vision_dev,3,1.0,2,https://www.reddit.com/r/learnmachinelearning/comments/17wvn3c/which_kind_of_machine_learning_should_be_used_for/
495,1700184288.0,OpenAI completions api timeout help,"I’ve got an angular/.NET website that is utilizing OpenAI’s completions API and I’m running into a timeout issue. My site has various limitations that basically cause my endpoint to timeout after 60 seconds. Is anyone aware of a way I can store the id of my request and check in on it rather than waiting for it? I’m slightly new to C# and am not sure how I can prevent this timeout without streaming client-side, which I don’t want to do since it’ll expose my API key. Any links, information, tutorials appreciated!",Artistic_Slip_8679,1,1.0,0,https://www.reddit.com/r/learnmachinelearning/comments/17x3d20/openai_completions_api_timeout_help/
496,1700160163.0,Training for my own handwriting,"Hello,

I'm a noob in Machine Learning but I have a special need for that.

I want to handwrite all my notes at work and having an efficient OCR for that.

&#x200B;

It is possible to use Tensorflow and train with sample of my handwriting ?

I think this need a lot of training , but with time, this can be good.

Have you some ideas/info for this type of stuff ?

&#x200B;

Thank you a lot !",xinyo,3,1.0,8,https://www.reddit.com/r/learnmachinelearning/comments/17wu67s/training_for_my_own_handwriting/
497,1700151529.0,How would one make a Nepali-English translator?," 

I want to make a Nepali-to-English text converter. We already have Devanagari (देवनागरी) to an English translator. I want to translate Nepali written in English to English.  
For example,  
Nepali: “Hello, kata jadai ho?”  
English: “Hello, where are you going?”.

I have beginner/intermediate-level ideas about Deep Learning, NLP, and Transformers. I’m assuming the biggest roadblock is going to be the Dataset which is going to be absolutely minimal even if we find it. Would love some pointers with that too.",jo_josh,4,1.0,5,https://www.reddit.com/r/learnmachinelearning/comments/17wqty8/how_would_one_make_a_nepalienglish_translator/
498,1700164237.0,"Given red-color-filled and empty squares, find which squares should get colored on an image with all empty squares."," I have a dataset that contains images of squares, some filled with red. I have added an example image. These red squares are chosen with some logic behind them. I am trying to train a model that only takes these colored images and, given a non-color image, find which squares should be colored. I have a good amount of knowledge of image processing, but I needed help figuring out how to go about this problem. 

This is roughly how the colored images would look like

[https://imgur.com/WG1s4Rp](https://imgur.com/WG1s4Rp)",Fearless_Ad_4159,2,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17wvpni/given_redcolorfilled_and_empty_squares_find_which/
499,1700157749.0,Is it mandatory to maintain Kaggle profile for MLOPS aim?,"Hey folks!!

I have intermediate level expertise in ML. I have observed one pattern of maintaining Kaggle profile, if one wants to shape his career in this field. Is it really necessary to have a fancy kaggle profile if one wants to get job in reputed organisation as an ML engineer. ? Or is it exaggerated to have decent Kaggle profile (same as Leetcode for SDE) ?

My ultimate goal is MLOPS.",JordaarAce,2,1.0,1,https://www.reddit.com/r/learnmachinelearning/comments/17wt91c/is_it_mandatory_to_maintain_kaggle_profile_for/
